{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b51ae24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8515b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array([1,2,3,4,5])\n",
    "y=np.array([2.1,2.9,4.2,4.8,5.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9f21d9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m=0.5\n",
    "c=0.5\n",
    "alpha=0.01\n",
    "n=len(x)\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "26018f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.3420000000000005\n",
      "-13.68\n"
     ]
    }
   ],
   "source": [
    "y1=m*x+c\n",
    "\n",
    "result=(y-y1)**2\n",
    "total=sum(result)\n",
    "loss1=total/n\n",
    "print(loss1)\n",
    "loss2=loss1\n",
    "loss1=0\n",
    "\n",
    "print(sum(-2*(y-y1)*x/n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fb94bce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.55368848\n",
      "error:-1.7883115200000006\n"
     ]
    }
   ],
   "source": [
    "while(loss2-loss1>=0.00001):\n",
    "    slope_gradient=sum(-2*(y-y1)*x/n)\n",
    "#   print(slope_gradient)\n",
    "    \n",
    "    gradient=sum(-2*(y-y1)/n) \n",
    "#     print(gradient)\n",
    "    mnew=m-alpha*slope_gradient\n",
    "#     print(mnew)\n",
    "    \n",
    "    c_new=c-alpha*gradient\n",
    "#     print(c_new)\n",
    " \n",
    "    loss1=loss2\n",
    "    y1=mnew*x+c_new\n",
    "    result=sum((y-y1)**2)\n",
    "    m=mnew\n",
    "    c=c_new\n",
    "  \n",
    "    \n",
    "    loss2=result/n\n",
    "    print(loss2)\n",
    "    \n",
    "    print(f\"error:{loss2-loss1}\")\n",
    "  \n",
    "   \n",
    "  \n",
    "   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "441d2dd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss2-loss1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2aa70d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9543967248534877"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mnew\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51d4dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1141264282056682"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c90c5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=mnew*x+c_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84547d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e118217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c71a5ce50>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABI6ElEQVR4nO3deVyVZf7/8ddhVwRUZHPHXUABsRLTNkvLsppsUatplq/fsdzKnMyayZyaqGkZNfpqljO/zFHLzNLRzBahcjQXcF9TUkQQcTkgygHOuX9/+JVvKCiH7eYc3s/H4zwenZvr5nyuLuu8va/rvm6LYRgGIiIiIibxMLsAERERadwURkRERMRUCiMiIiJiKoURERERMZXCiIiIiJhKYURERERMpTAiIiIiplIYEREREVN5mV1AVTgcDo4dO0ZAQAAWi8XsckRERKQKDMOgoKCA1q1b4+FR+fUPlwgjx44do127dmaXISIiItWQmZlJ27ZtK/25S4SRgIAA4EJnAgMDTa5GREREqiI/P5927dqVfY9XxiXCyMWpmcDAQIURERERF3O1JRZawCoiIiKmcjqMZGVl8cgjjxAcHEzTpk2Ji4tjy5YtVzwnNTWVhIQE/Pz86NSpE3PmzKl2wSIiIuJenJqmOX36NNdffz0333wzX3zxBaGhoRw8eJDmzZtXek5GRgZDhw5l9OjRLFiwgHXr1vHEE08QEhLC8OHDa1q/iIiIuDiLYRhGVRs/++yzrFu3ju+//77KHzBlyhSWL1/Onj17yo6NGTOGbdu2sX79+ir9jvz8fIKCgrBarVozIiIi4iKq+v3t1DTN8uXL6du3Lw888AChoaHEx8fz3nvvXfGc9evXM3jw4HLHhgwZwubNmykpKanwHJvNRn5+frmXiIiIuCenwsihQ4eYPXs2Xbt25csvv2TMmDFMmDCB+fPnV3pOTk4OYWFh5Y6FhYVRWlpKXl5eheckJSURFBRU9tIeIyIiIu7LqTDicDjo06cPr7zyCvHx8fzhD39g9OjRzJ49+4rnXXpLz8WZocpu9Zk6dSpWq7XslZmZ6UyZIiIi4kKcCiMRERFERUWVO9azZ0+OHDlS6Tnh4eHk5OSUO5abm4uXlxfBwcEVnuPr61u2p4j2FhEREXFvTt1Nc/3117Nv375yx/bv30+HDh0qPScxMZEVK1aUO7ZmzRr69u2Lt7e3Mx8vIiIitcjuMNiYcYrcgiJCA/y4NrIlnh71/ww4p8LIU089Rf/+/XnllVd48MEH2bhxI3PnzmXu3LllbaZOnUpWVlbZOpIxY8aQnJzMpEmTGD16NOvXr2fevHksWrSodnsiIiIiVbZ6ZzbTV+wm21pUdiwiyI9pw6K4PSaiXmtxaprmmmuuYdmyZSxatIiYmBheeuklZsyYwcMPP1zWJjs7u9y0TWRkJKtWrSIlJYW4uDheeuklZs2apT1GRERETLJ6ZzaPL0grF0QAcqxFPL4gjdU7s+u1Hqf2GTGL9hkRERGpHXaHwYDXvr0siFxkAcKD/Phhyi01nrKpk31GRERExLVtzDhVaRABMIBsaxEbM07VW00KIyIiIo1IbkHlQaQ67WqDwoiIiEgjEhrgV6vtaoPCiIiISCNybWRLwgN9K/25hQt31Vwb2bLealIYERERaURy8oto6lvxzh4Xl6tOGxZVr/uNOLXPiIiIiLiur3YfZ/KSbVjPl+Dn7YGftydnzv3fQ2vDTdpnRGFERETEzRWXOnht9V7m/ZABQGzbIN4e2Yc2LZq43g6sIiIi4lqOnDzHuEVpbD9qBeD3AyKZcnsPfLwurNRI7Fzxc+Lqk8KIiIiIm1q5PZtnl26nwFZKUBNv3nggltuiwswu6zIKIyIiIm6mqMTOyyt3s2DDhcezJHRowayR8bRp3sTkyiqmMCIiIuJGDp44y9h/pbE3pwCAJ27qzFO3dcPbs+HeQKswIiIi4iaWpR/l+WU7OVdsJ9jfh7ceiuPGbiFml3VVCiMiIiIu7lxxKdM+38WSLUcBSOwUzMwRcYQG1t8uqjWhMCIiIuLC9uUUMHZhGj/lnsXDAhMHdWPcLV1MuUW3uhRGREREXJBhGHy0KZNpy3dhK3UQGuDLzBHxDeJWXWcpjIiIiLiYs7ZSnl+2g8+3HgPgxm4hvPlgLK2aVf7MmYZMYURERMSF7MyyMm5hGj+fPIenh4U/DunOfw/shIcLTctcSmFERETEBRiGwYcbDvPyv/dQbHfQOsiPt0fFk9Ch/p6uW1cURkRERBo46/kSpnyyndW7cgC4tWcYbzzQm+ZNfUyurHYojIiIiDRg6UdOM35ROkdPn8fb08LUO3ry2+s7YrG47rTMpRRGREREGiCHw2DeDxm8tnovpQ6D9i2bkjwqnt5tm5tdWq1TGBEREWlgThUWM3nJNr7dmwvAnb0jSLqvF4F+3iZXVjcURkRERBqQjRmnmLAonZz8Iny8PJg2LIpR17Z3q2mZSymMiIiINAB2h8HslJ9466v9OAzoFOJP8sg+RLUONLu0OqcwIiIiYrITBTae+mgrP/yUB8B98W146d4Y/H0bx9d04+iliIhIA7XupzwmLt5K3lkbTbw9eeneGO5PaGt2WfVKYURERMQEpXYHs745wNtrf8IwoHtYAO88HE+X0ACzS6t3CiMiIiL1LMdaxITF6WzMOAXAyGvbMW1YNH7eniZXZg6FERERkXq0dm8ukz7eyulzJfj7ePLKfb24J66N2WWZSmFERESkHpTYHbzx5T7e/e4QANGtA0ke1YfIVv4mV2Y+hREREZE6lnnqHBMWp5N+5AwAv+nfkalDe+Dr1TinZS6lMCIiIlKHVu/M4ZlPtpFfVEqgnxd/uz+W22PCzS6rQfFwpvGLL76IxWIp9woPr/xfaEpKymXtLRYLe/furXHhIiIiDZmt1M6Ly3cxZsEW8otKiWvXnJUTBiqIVMDpKyPR0dF8/fXXZe89Pa9+iWnfvn0EBv7fDnIhISHOfqyIiIjL+DmvkHGL0tiZlQ/AH27oxOQh3fH2dOoaQKPhdBjx8vK64tWQioSGhtK8eXNnP0pERMTlLN92jOc+3cFZWyktmnrz1oNx3Nwj1OyyGjSnI9qBAwdo3bo1kZGRjBgxgkOHDl31nPj4eCIiIhg0aBBr166tVqEiIiINWVGJnamf7mDConTO2kq5tmNLVk0cqCBSBU5dGbnuuuuYP38+3bp14/jx47z88sv079+fXbt2ERwcfFn7iIgI5s6dS0JCAjabjQ8//JBBgwaRkpLCDTfcUOnn2Gw2bDZb2fv8/HxnyhQREalXP+UWMPZf6ew7XoDFAuNv7sKEQV3x0rRMlVgMwzCqe3JhYSGdO3fmmWeeYdKkSVU6Z9iwYVgsFpYvX15pmxdffJHp06dfdtxqtZZbeyIiImK2T7Yc5c+f7eR8iZ1WzXyZ8VAcA7q2MrusBiE/P5+goKCrfn/XKLL5+/vTq1cvDhw4UOVz+vXrd9X2U6dOxWq1lr0yMzNrUqaIiEitK7SVMumjrUxeso3zJXau7xLMqokDFESqoUb7jNhsNvbs2cPAgQOrfE56ejoRERFXbOPr64uvr29NShMREakze7LzGbswjUMnCvGwwKTbuvH4TV3w9LCYXZpLciqMTJ48mWHDhtG+fXtyc3N5+eWXyc/P57HHHgMuXNHIyspi/vz5AMyYMYOOHTsSHR1NcXExCxYsYOnSpSxdurT2eyIiIlLHDMNg4cYjTF+xm+JSB+GBfswaGc+1kS3NLs2lORVGjh49ysiRI8nLyyMkJIR+/fqxYcMGOnToAEB2djZHjhwpa19cXMzkyZPJysqiSZMmREdHs3LlSoYOHVq7vRAREalj+UUlTP10Byu3ZwNwS49Q3ngglpb+PiZX5vpqtIC1vlR1AYyIiEhd2H70DOMWpnPk1Dm8PCxMub0Hvx8QiYemZa6oqt/fejaNiIhIJQzD4J/rfibpiz2U2A3aNG9C8qh44tu3MLs0t6IwIiIiUoEz54qZvGQ7X+85DsDt0eG8Nrw3QU29Ta7M/SiMiIiIXGLL4dNMWJRO1pnz+Hh68Ke7evJovw5YLJqWqQsKIyIiIv/L4TB497tDvLFmH3aHQcfgpiSP6kNMmyCzS3NrCiMiIiJA3lkbkz7exnf7TwBwd2xrXrmvF8189VVZ1/RvWEREGr31B08ycXE6uQU2fL08mH53NA9d007TMvVEYURERBotu8Pg7W8PMOubAzgM6BLajHdG9aF7eIDZpTUqCiMiItIo5eYXMXHxVtYfOgnAAwltmX5PNE199NVY3/RvXEREGp3v9p/gqY+2crKwmKY+nvz1VzH8Kr6t2WU1WgojIiLSaJTaHbz11X7+J+UgAD3CA3jn4T50DmlmcmWNm8KIiIg0CsfOnGfConQ2Hz4NwCP92vOnO6Pw8/Y0uTJRGBEREbf39e7jTP5kG2fOlRDg68Wrw3tzZ+8Is8uS/6UwIiIibqu41MFrq/cy74cMAHq3DSJ5ZB/aBzc1uTL5JYURERFxS0dOnmP8ojS2HbUC8LvrI3n2jh74eHmYXJlcSmFERETczqod2Uz5ZDsFtlKCmnjzxgOx3BYVZnZZUgmFERERcRtFJXZeXrmbBRuOAJDQoQWzRsbTpnkTkyuTK1EYERERt3DoxFnGLkxnT3Y+AI/f1JlJt3XD21PTMg2dwoiIiLi8z9KzeG7ZDs4V2wn29+Gth+K4sVuI2WVJFSmMiIiIyzpXXMqLy3fx8eajAPTr1JKZI+IJC/QzuTJxhsKIiIi4pP3HCxj7rzQO5J7FYoGJg7oy/paueHroSbuuRmFERERcimEYfLw5k2nLd1FU4iA0wJcZI+Lo37mV2aVJNSmMiIiIyzhrK+X5ZTv4fOsxAG7oFsJbD8bSqpmvyZVJTSiMiIiIS9iZZWX8onQy8grx9LAweXB3/nBDJzw0LePyFEZERKRBMwyDDzcc5uV/76HY7qB1kB9vj4onoUNLs0uTWqIwIiIiDZb1fAlTPtnO6l05ANzaM5TX74+lhb+PyZVJbVIYERGRBin9yGnGL0rn6OnzeHtaePaOnvzu+o5YLJqWcTcKIyIi0qAYhsH732fw2uq9lDoM2rdsSvKoeHq3bW52aVJHFEZERKTBOF1YzOQl2/hmby4Ad/aKIGl4LwL9vE2uTOqSwoiIiDQIm34+xYRF6WRbi/Dx8uCFu6J4+Lr2mpZpBBRGRETEVA6HwezUg7z11X7sDoNOrfxJHtWHqNaBZpcm9URhRERETHOiwMakj7fy/YE8AH4V34aX743B31dfT42JRltEREyx7qc8nvxoKycKbDTx9uQv90Rzf0JbTcs0QgojIiJSr0rtDmZ9c4C31/6EYUD3sACSR8XTNSzA7NLEJB7ONH7xxRexWCzlXuHh4Vc8JzU1lYSEBPz8/OjUqRNz5sypUcEiIuK6cqxFjHr/R2Z9eyGIjLimHZ+NvV5BpJFz+spIdHQ0X3/9ddl7T0/PSttmZGQwdOhQRo8ezYIFC1i3bh1PPPEEISEhDB8+vHoVi4iIS1q7N5enl2zjVGEx/j6evHJfL+6Ja2N2WdIAOB1GvLy8rno15KI5c+bQvn17ZsyYAUDPnj3ZvHkzb7zxhsKIiEgjUWJ38MaX+3j3u0MARLcOJHlUHyJb+ZtcmTQUTk3TABw4cIDWrVsTGRnJiBEjOHToUKVt169fz+DBg8sdGzJkCJs3b6akpKTS82w2G/n5+eVeIiLieo6ePseD764vCyK/6d+RT5/oryAi5TgVRq677jrmz5/Pl19+yXvvvUdOTg79+/fn5MmTFbbPyckhLCys3LGwsDBKS0vJy8ur9HOSkpIICgoqe7Vr186ZMkVEpAH4clcOQ2d+T/qRMwT6eTHnkT68eHc0vl6VT+9L4+RUGLnjjjsYPnw4vXr14tZbb2XlypUAfPDBB5Wec+ktWoZhVHj8l6ZOnYrVai17ZWZmOlOmiIiYyFZq58Xlu/jDh1vILyoltl1zVk4YyO0xEWaXJg1UjW7t9ff3p1evXhw4cKDCn4eHh5OTk1PuWG5uLl5eXgQHB1f6e319ffH19a1JaSIiYoKf8woZtyiNnVkXptf/+4ZOTB7cHR8vp1cFSCNSozBis9nYs2cPAwcOrPDniYmJrFixotyxNWvW0LdvX7y99dAjERF3smLbMaZ+uoOztlJaNPXmzQdjuaVH2NVPlEbPqag6efJkUlNTycjI4Mcff+T+++8nPz+fxx57DLgwvfLrX/+6rP2YMWM4fPgwkyZNYs+ePfzjH/9g3rx5TJ48uXZ7ISIipikqsTP10x2MX5TOWVsp13ZsyaqJAxVEpMqcujJy9OhRRo4cSV5eHiEhIfTr148NGzbQoUMHALKzszly5EhZ+8jISFatWsVTTz3FO++8Q+vWrZk1a5Zu6xURcRM/5Z5l3MI09uYUYLHAuJu7MHFQV7w8NS0jVWcxLq4obcDy8/MJCgrCarUSGKinOIqINASfbDnKnz/byfkSO62a+TLjoTgGdG1ldlnSgFT1+1vPphEREacU2kr58+c7+TQtC4DruwTz94fiCA3wM7kycVUKIyIiUmV7svMZtzCNgycK8bDApNu68fhNXfD00JN2pfoURkRE5KoMw2DRxkymr9iFrdRBeKAfM0fEcV2nyrdpEKkqhREREbmigqISpn66g39vzwbg5u4hvPlgHC39fUyuTNyFwoiIiFRqx1Er4xalcfjkObw8LDxze3f+a0AnPDQtI7VIYURERC5jGAb/7z8/88qqPZTYDdo0b8Lbo+Lp076F2aWJG1IYERGRcs6cK+aPn2znq93HARgSHcbfhscS1PTynbPtDoONGafILSgiNMCPayNbajGrOE1hREREymw5fJoJi9LJOnMeH08Pnr+zJ79O7FDhw01X78xm+ordZFuLyo5FBPkxbViUHoonTtEWeSIigsNhMCf1IA++u56sM+fpGNyUT5/oz2P9O1YaRB5fkFYuiADkWIt4fEEaq3dm11fp4gZ0ZUREpJE7edbGpI+3kbr/BADDYlvzyq9iCPCr+IGmdofB9BW7qWj7bgOwANNX7Oa2qHBN2UiVKIyIiDRiGw6dZOLidI7n2/D18mD63dE8dE27Cq+GXLQx49RlV0R+yQCyrUVszDhFYmftQyJXpzAiItII2R0Gyd/+xMxv9uMwoEtoM5JHxdMj/OrP/8otqDyIVKediMKIiEgjk5tfxJMfbeU/B08C8EBCW6bfE01Tn6p9JVT1GTR6Vo1UlcKIiEgj8v2BEzz10VbyzhbT1MeTl++N4b4+bZ36HddGtiQiyI8ca1GF60YsQHjQhdt8RapCd9OIiDQCpXYHr3+5l1//YyN5Z4vpER7A8nEDnA4iAJ4eFqYNiwIuBI9fuvh+2rAoLV6VKlMYERFxc8fOnGfE3A28s/YghgEPX9eez8ZeT5fQZtX+nbfHRDD7kT6EB5WfigkP8mP2I320z4g4RdM0IiJu7Js9x3l6yTbOnCshwNeLpOG9uKt361r53bfHRHBbVLh2YJUaUxgREXFDxaUO/rZ6L+//kAFArzZBJI+Kp0Owf61+jqeHRbfvSo0pjIiIuJnMU+cYtzCNbUetAPzu+kim3NEdXy9PkysTqZjCiIiIG1m1I5spS7dTUFRKUBNv3nggltuiwswuS+SKFEZERNxAUYmdv67cw4cbDgPQp31z3h7VhzbNm5hcmcjVKYyIiLi4QyfOMnZhOnuy8wF4/KbOTLqtG96eumFSXIPCiIiIC/t8axbPfbqDwmI7wf4+vPlgLDd1DzW7LBGnKIyIiLig88V2Xly+i482ZwLQr1NLZo6IJyxQW7CL61EYERFxMfuPFzD2X2kcyD2LxQITbunKhEFdtb+HuCyFERERF2EYBks2H+WF5TspKnEQEuDLzIfi6N+lldmlidSIwoiIiAs4ayvlT8t28NnWYwAM7NqKvz8UR6tmviZXJlJzCiMiIg3crmNWxi1MJyOvEE8PC08P7saYGzrjoWkZcRMKIyIiDZRhGCzYcJiXVu6huNRB6yA/Zo2Mp2/HlmaXJlKrFEZERBog6/kSnl26nS925gBwa89QXr8/lhb+PiZXJlL7FEZERBqYrZlnGLcwjaOnz+PtaeHZO3ryu+s7YrFoWkbck8KIiEgDYRgG837I4NUv9lLqMGjXsgnJI/sQ26652aWJ1CmFERGRBuB0YTGTl2zjm725AAztFc6rw3sT6OdtcmUida9GDy5ISkrCYrHw5JNPVtomJSUFi8Vy2Wvv3r01+WgREbex6edTDJ31Pd/szcXHy4OX743hnVF9FESk0aj2lZFNmzYxd+5cevfuXaX2+/btIzAwsOx9SEhIdT9aRMQtOBwGs1MP8tZX+7E7DDq18id5VB+iWgde/WQRN1KtMHL27Fkefvhh3nvvPV5++eUqnRMaGkrz5s2r83EiIm7nRIGNSR9v5fsDeQDcG9eal3/Vi2a+mj2Xxqda0zRjx47lzjvv5NZbb63yOfHx8URERDBo0CDWrl17xbY2m438/PxyLxERd/Gfn/IYOut7vj+Qh5+3B3+7vzd/fyhOQUQaLaf/5C9evJi0tDQ2bdpUpfYRERHMnTuXhIQEbDYbH374IYMGDSIlJYUbbrihwnOSkpKYPn26s6WJiDRodofBzG8O8Pa3BzAM6BbWjHdG9aFrWIDZpYmYymIYhlHVxpmZmfTt25c1a9YQGxsLwE033URcXBwzZsyo8ocOGzYMi8XC8uXLK/y5zWbDZrOVvc/Pz6ddu3ZYrdZy605ERFxFjrWIiYvT+THjFAAjrmnHtGHRNPHxNLkykbqTn59PUFDQVb+/nboysmXLFnJzc0lISCg7Zrfb+e6770hOTsZms+HpefX/sPr168eCBQsq/bmvry++vnr4k4i4h7X7cnn6422cKizG38eTV+7rxT1xbcwuS6TBcCqMDBo0iB07dpQ79tvf/pYePXowZcqUKgURgPT0dCIiIpz5aBERl1Nid/DGmn28m3oIgKiIQN55uA+RrfxNrkykYXEqjAQEBBATE1PumL+/P8HBwWXHp06dSlZWFvPnzwdgxowZdOzYkejoaIqLi1mwYAFLly5l6dKltdQFEZGG5+jpc4xflE76kTMAPJbYgalDe+LnrWkZkUvV+tLt7Oxsjhw5Uva+uLiYyZMnk5WVRZMmTYiOjmblypUMHTq0tj9aRKRBWLMrhz9+sh3r+RIC/Lx4/f7e3B6jq8EilXFqAatZqroARkTETLZSO69+sZd/rvsZgNh2zUkeGU+7lk3NLUzEJHWygFVERCr2c14h4xalsTPrwr5IowdG8schPfDxqtFTN0QaBYUREZEaWrHtGFM/3cFZWynNm3rz5gOxDOoZZnZZIi5DYUREpJqKSuxMX7GbRRsvrJO7pmMLZo2MJyKoicmVibgWhRERkWr4Kfcs4xamsTenAIsFxt7UhSdv7YqXp6ZlRJylMCIi4qSlW47yp892cr7ETqtmPvz9oTgGdtWTyEWqS2FERKSKCm2lvPD5LpamHQWgf+dgZoyIIzTAz+TKRFybwoiISBXsyc5n3MI0Dp4oxMMCT93ajSdu7oKnh8Xs0kRcnsKIiMgVGIbBoo2ZTF+xC1upg7BAX2aNiOe6TsFmlybiNhRGREQqUVBUwnPLdrJi2zEAbuoewpsPxBLcTA/yFKlNCiMiIhXYcdTKuEVpHD55Di8PC38c0p3RAzvhoWkZkVqnMCIi8guGYfD//vMzr6zaQ4ndoE3zJswaGU9ChxZmlybithRGRET+15lzxTzzyXbW7D4OwOCoMF6/P5agpt4mVybi3hRGRESAtCOnGb8wnawz5/Hx9OC5oT14rH9HLBZNy4jUNYUREWnUHA6D974/xOtf7qPUYdAhuCnJI/vQq22Q2aWJNBoKIyLSaJ08a+PpJdtI2XcCgLt6R5B0Xy8C/DQtI1KfFEZExDR2h8HGjFPkFhQRGuDHtZEt620TsQ2HTjJxcTrH8234ennw4t3RjLimnaZlREygMCIipli9M5vpK3aTbS0qOxYR5Me0YVHcHhNRZ59rdxi8s/YnZny9H4cBnUP8eefhPvQID6yzzxSRK9PjJUWk3q3emc3jC9LKBRGAHGsRjy9IY/XO7Dr53NyCIh6d9yNvfXUhiNyf0JYV4wcoiIiYTFdGRKRe2R0G01fsxqjgZwZgAaav2M1tUeG1OmXz/YETPPXRVvLOFtPUx5OX7olheELbWvv9IlJ9CiMiUq82Zpy67IrILxlAtrWIjRmnSOxc8+e/lNod/P3r/fxPykEMA3qEB5A8qg9dQpvV+HeLSO1QGBGRepVbUHkQqU67Kzl25jwTF6ez6efTAIy6rj0v3BWFn7dnjX+3iNQehRERqVehAX612q4y3+w5ztNLtnHmXAnNfL1Iuq8Xw2Jb1+h3ikjdUBgRkXp1bWRLIoL8yLEWVbhuxAKEB124zbc6iksd/G31Xt7/IQOAXm2CSB4VT4dg/+oXLSJ1SnfTiEi98vSwMG1YFHAhePzSxffThkVVa/Fq5qlzPPDu+rIg8rvrI/nk8UQFEZEGTmFEROrd7TERzH6kD+FB5adiwoP8mP1In2rtM/LFjmyGzvqebZlnCPTzYu6jCbwwLApfL60PEWnoNE0jIqa4PSaC26LCa7wDa1GJnVdW7WH++sMA9GnfnFkj42nbomldlC0idUBhRERM4+lhqdHtu4dOnGXcwnR2Z+cDMObGzjw9uBvenrroK+JKFEZExCV9vjWL5z7dQWGxnZb+Prz1YCw3dQ81uywRqQaFERFxKeeL7by4fBcfbc4E4LrIlswaGU9YYM1uBRYR8yiMiIjL2H+8gHEL09h//CwWC4y/pSsTB3Wttyf9ikjdUBgRkQbPMAyWbD7KC8t3UlTiICTAl5kPxdG/SyuzSxORWqAwIiIN2llbKX9atoPPth4DYGDXVrz1YBwhAb4mVyYitUVhREQarF3HrIxfmM6hvEI8PSw8PbgbY27ojIemZUTcSo3uf0tKSsJisfDkk09esV1qaioJCQn4+fnRqVMn5syZU5OPFRE3ZxgGH244zK/+5z8cyiskIsiPj/67H0/c1EVBRMQNVfvKyKZNm5g7dy69e/e+YruMjAyGDh3K6NGjWbBgAevWreOJJ54gJCSE4cOHV/fjRcRNWc+XMPXT7azakQPAoB6hvPFALC38fUyuTETqSrXCyNmzZ3n44Yd57733ePnll6/Yds6cObRv354ZM2YA0LNnTzZv3swbb7yhMCIi5WzLPMO4RWlknjqPt6eFKbf34PcDIrFYdDVExJ1Va5pm7Nix3Hnnndx6661Xbbt+/XoGDx5c7tiQIUPYvHkzJSUlFZ5js9nIz88v9xIR92UYBu9/f4j75/yHzFPnadeyCUvG9Oe/BnZSEBFpBJy+MrJ48WLS0tLYtGlTldrn5OQQFhZW7lhYWBilpaXk5eUREXH5A7GSkpKYPn26s6WJiAs6XVjM5CXb+GZvLgBDe4WTdF9vgpp4m1yZiNQXp66MZGZmMnHiRBYsWICfX9V3O7z0bzaGYVR4/KKpU6ditVrLXpmZmc6UKSIuYvPPp7hz1vd8szcXHy8PXro3hndG9VEQEWlknLoysmXLFnJzc0lISCg7Zrfb+e6770hOTsZms+HpWf5x3eHh4eTk5JQ7lpubi5eXF8HBFT8gy9fXF19f7SEg4q4cDoPZqQd566v92B0Gka38SR4VT3TrILNLExETOBVGBg0axI4dO8od++1vf0uPHj2YMmXKZUEEIDExkRUrVpQ7tmbNGvr27Yu3t/72I9LYnCiwMenjrXx/IA+Ae+Na8/KvetHMV9seiTRWTv3XHxAQQExMTLlj/v7+BAcHlx2fOnUqWVlZzJ8/H4AxY8aQnJzMpEmTGD16NOvXr2fevHksWrSolrogIq7iPz/lMfGjrZwosOHn7cFf7onhgYS2WqQq0sjV+l9FsrOzOXLkSNn7yMhIVq1axVNPPcU777xD69atmTVrlm7rFWlE7A6DWd8cYNa3BzAM6BbWjORRfegWFmB2aSLSAFiMi6tJG7D8/HyCgoKwWq0EBgaaXY6IOOF4fhETF6ez4dApAEZc045pw6Jp4nP5tK6IuJeqfn9rklZE6kzKvlwmfbyNU4XF+Pt48sp9vbgnro3ZZYlIA6MwIiK1rsTu4M01+5mTehCAqIhAkkfF0ymkmcmViUhDpDAiIrUq68x5xi9MI+3IGQB+ndiB54b2xM9b0zIiUjGFERGpNWt25fDHT7ZjPV9CgJ8Xfxvemzt6Xb7LsojILymMiEiN2UrtvPrFXv657mcAYts1J3lkPO1aNjW3MBFxCQojIlIjh08WMm5hOjuyrACMHhjJH4f0wMerWs/hFJFGSGFERKrt39uP8ezSHZy1ldK8qTdvPhDLoJ5hVz9RROQXFEZExGlFJXb+8u/dLPzxwgaH13RswcwR8bRu3sTkykTEFSmMiIhTfso9y7iFaezNKcBigbE3deHJW7vi5alpGRGpHoUREamyT9OO8qfPdnKu2E6rZj78/aE4BnYNMbssEXFxCiMiclXnikt54fNdfLLlKAD9Owcz46E4QgP9TK5MRNyBwoiIXNHenHzG/iuNgycK8bDAk7d2Y+zNXfD00JN2RaR2KIyISIUMw2DxpkxeXL4LW6mDsEBfZo6Ip1+nYLNLExE3ozAiIpcpKCrhuWU7WbHtGAA3dQ/hzQdiCW7ma3JlIuKOFEZEpJydWVbGLkzj8MlzeHlY+OOQ7owe2AkPTcuISB1RGBER4MK0zAf/+ZlXVu2l2O6gTfMmzBoZT0KHFmaXJiJuTmFERLCeK+GPn2xjze7jAAyOCuNv9/emeVMfkysTkcZAYUSkkUs7cprxC9PJOnMeH08Pnhvag8f6d8Ri0bSMiNQPhRGRRsrhMHj/h0P8bfU+Sh0GHYKbkjyyD73aBpldmog0MgojIo3QqcJinv54K2v3nQDgrt4RJN3XiwA/b5MrE5HGSGFEpJH58dBJJixO53i+DV8vD6YNi2bkte00LSMiplEYEWkk7A6D/1n7E3//ej8OAzqH+JM8qg89IwLNLk1EGjmFEZFGILegiKc+2sq6n04CMLxPW/5yTzT+vvpfgIiYT/8nEnFzPxzI48mP0sk7W0wTb09eujeG+xPaml2WiEgZhRERN1VqdzDj6wO8k/IThgE9wgNIHtWHLqHNzC5NRKQchRERN5RtPc+ERels+vk0AKOua88Ld0Xh5+1pcmUiIpdTGBFxM9/uPc7TH2/j9LkSmvl6kXRfL4bFtja7LBGRSimMiLiJ4lIHr3+5l/e+zwCgV5sg3h4ZT8dW/iZXJiJyZQojIm4g89Q5xi9KZ2vmGQB+e31Hnr2jB75empYRkYZPYUTExa3emc0fP9lOQVEpgX5evP5ALEOiw80uS0SkyhRGRFxUUYmdpFV7+GD9YQDi2zfn7ZHxtG3R1OTKREScozAi4oIy8goZtzCNXcfyAfjDjZ2YPLg73p4eJlcmIuI8hRERF/P51iye+3QHhcV2Wvr78OaDsdzcPdTsskREqs2pv0bNnj2b3r17ExgYSGBgIImJiXzxxReVtk9JScFisVz22rt3b40LF2lszhfbeXbpdiYu3kphsZ1rI1uyasJABRERcXlOXRlp27Ytr776Kl26dAHggw8+4J577iE9PZ3o6OhKz9u3bx+Bgf/3MK6QkJBqlivSOB04XsDYhWnsP34WiwXG39KVCbd0wUvTMiLiBpwKI8OGDSv3/q9//SuzZ89mw4YNVwwjoaGhNG/evFoFijRmhmGwZMtRXvh8J0UlDkICfJn5UBz9u7QyuzQRkVpT7TUjdrudJUuWUFhYSGJi4hXbxsfHU1RURFRUFH/605+4+eabr9jeZrNhs9nK3ufn51e3TBGXddZWyp8/28my9CwABnZtxVsPxhES4GtyZSIitcvpMLJjxw4SExMpKiqiWbNmLFu2jKioqArbRkREMHfuXBISErDZbHz44YcMGjSIlJQUbrjhhko/IykpienTpztbmojb2H0sn3EL0ziUV4inh4VJt3Xj8Rs74+FhMbs0EZFaZzEMw3DmhOLiYo4cOcKZM2dYunQp77//PqmpqZUGkksNGzYMi8XC8uXLK21T0ZWRdu3aYbVay609EXE3hmHwrx+P8Jd/76a41EFEkB+zRsZzTceWZpcmIuK0/Px8goKCrvr97fSVER8fn7IFrH379mXTpk3MnDmTd999t0rn9+vXjwULFlyxja+vL76+uhQtjUt+UQlTl+5g5Y5sAAb1COWNB2Jp4e9jcmUiInWrxvuMGIZR7irG1aSnpxMREVHTjxVxK9syzzBuURqZp87j5WHh2Tt68PsBkVgsmpYREffnVBh57rnnuOOOO2jXrh0FBQUsXryYlJQUVq9eDcDUqVPJyspi/vz5AMyYMYOOHTsSHR1NcXExCxYsYOnSpSxdurT2eyLiggzDYN4PGby2ei8ldoO2LZqQPKoPce2am12aiEi9cSqMHD9+nEcffZTs7GyCgoLo3bs3q1ev5rbbbgMgOzubI0eOlLUvLi5m8uTJZGVl0aRJE6Kjo1m5ciVDhw6t3V6IuKAz54qZvGQbX+/JBeCOmHBeHd6boCbeJlcmIlK/nF7AaoaqLoARcRWbfz7FhEXpHLMW4ePpwZ/v6skj/TpoWkZE3EqdLWAVkepzOAzmfHeQN9fsx+4wiGzlT/KoeKJbB5ldmoiIaRRGROpJ3lkbT320le8P5AFwT1xr/vqrXjTz1X+GItK46f+CIvXgPwfzmLh4KycKbPh5e/CXu2N4oG9bTcuIiKAwIlKn7A6DWd8cYNa3BzAM6BrajHce7kO3sACzSxMRaTAURkTqyPH8IiYuTmfDoVMAPNS3HS/eHU0TH0+TKxMRaVgURkTqQOr+E0z6aCsnC4vx9/Hkr7/qxb3xbcwuS0SkQVIYEalFJXYHb67Zz5zUgwD0jAjknVHxdAppZnJlIiINl8KISC3JOnOe8QvTSDtyBoBH+3Xg+Tt74uetaRkRkStRGBGpBV/tPs7kJduwni8hwNeL1+7vzdBeegaTiEhVKIyI1EBxqYNXv9jLP9ZlABDbNoi3R/ahfXBTkysTEXEdCiMi1XT4ZCHjF6Wz/agVgP8aEMkzt/fAx8vD5MpERFyLwohINfx7+zGmLt1Bga2U5k29eeP+WG6NCjO7LBERl6QwIuKEohI7L/17N//68cLTqft2aMGskfG0bt7E5MpERFyXwohIFR08cZax/0pjb04BFgs8cVNnnrq1G16empYREakJhRGRKvg07Sh/+mwn54rttGrmw1sPxnFDtxCzyxIRcQsKIyJXcK64lBc+38UnW44C0L9zMDMeiiM00M/kykRE3IfCiEgl9ubkM25hOj/lnsXDAhMHdWPcLV3w9NCTdkVEapPCiMglDMNg8aZMXly+C1upg9AAX2aOiCexc7DZpYmIuCWFEZFfKCgq4bllO1mx7RgAN3YL4a0HYwlu5mtyZSIi7kthROR/7cyyMm5hGj+fPIenh4U/DunOfw/shIemZURE6pTCiDR6hmEwf/1h/rpyD8V2B22aN2HWyHgSOrQwuzQRkUZBYUQaNeu5Ep5Zuo0vdx0H4LaoMF6/vzfNm/qYXJmISOOhMCKNVtqR04xfmE7WmfN4e1p4bmhPftO/IxaLpmVEROqTwog0Og6Hwfs/HOJvq/dR6jBo37IpyaPi6d22udmliYg0Sgoj0qicKizm6Y+3snbfCQDu7B1B0n29CPTzNrkyEZHGS2FEGo0fD51k4uKt5OQX4evlwbRh0Yy8tp2mZURETKYwIm7P7jD4n7U/8fev9+MwoFOIP++M6kPPiECzSxMRERRGxM3lFhTx1EdbWffTSQDu69OGl+6Jwd9Xf/RFRBoK/R9Z3NYPB/J48qOt5J210cTbk5fujeH+hLZmlyUiIpdQGBG3U2p3MPObAySv/QnDgB7hASSPiqdLaIDZpYmISAUURsStZFvPM3HRVjb+fAqAUde154W7ovDz9jS5MhERqYzCiLiNb/ce5+mPt3H6XAnNfL145b5e3B3b2uyyRETkKhRGxOUVlzp4Y80+5n53CICYNoEkj+xDx1b+JlcmIiJV4eFM49mzZ9O7d28CAwMJDAwkMTGRL7744ornpKamkpCQgJ+fH506dWLOnDk1KljklzJPnePBd9eXBZHf9O/I0sf7K4iIiLgQp66MtG3blldffZUuXboA8MEHH3DPPfeQnp5OdHT0Ze0zMjIYOnQoo0ePZsGCBaxbt44nnniCkJAQhg8fXjs9kEZr9c5snvlkO/lFpQT6efH6A7EMiQ43uywREXGSxTAMoya/oGXLlrz++uv8/ve/v+xnU6ZMYfny5ezZs6fs2JgxY9i2bRvr16+v8mfk5+cTFBSE1WolMFAbVTV2RSV2klbt4YP1hwGIa9ec5FHxtG3R1OTKRETkl6r6/V3tNSN2u50lS5ZQWFhIYmJihW3Wr1/P4MGDyx0bMmQI8+bNo6SkBG/vip8HYrPZsNlsZe/z8/OrW6a4mYy8QsYtTGPXsQt/Jv5wQycmD+mOt6dTM44iItKAOB1GduzYQWJiIkVFRTRr1oxly5YRFRVVYducnBzCwsLKHQsLC6O0tJS8vDwiIiIqPC8pKYnp06c7W5q4uc+3ZvHcpzsoLLbT0t+HNx+M5ebuoWaXJSIiNeT0Xye7d+/O1q1b2bBhA48//jiPPfYYu3fvrrT9pQ8huzgrdKWHk02dOhWr1Vr2yszMdLZMcSPni+08u3Q7ExdvpbDYzrWRLVk1YaCCiIiIm3D6yoiPj0/ZAta+ffuyadMmZs6cybvvvntZ2/DwcHJycsody83NxcvLi+Dg4Eo/w9fXF19fX2dLEzd04HgB4xams+94ARYLjL+lKxNu6YKXpmVERNxGjfcZMQyj3PqOX0pMTGTFihXljq1Zs4a+fftWul5EBC78ufpky1Fe+HwX50vshAT4MuOhOK7v0srs0kREpJY5FUaee+457rjjDtq1a0dBQQGLFy8mJSWF1atXAxemV7Kyspg/fz5w4c6Z5ORkJk2axOjRo1m/fj3z5s1j0aJFtd8TcRuFtlL+/NlOPk3PAmBAl1b8/aE4QgLKXy2zOww2Zpwit6CI0AA/ro1siadH5dN/IiLSMDkVRo4fP86jjz5KdnY2QUFB9O7dm9WrV3PbbbcBkJ2dzZEjR8raR0ZGsmrVKp566ineeecdWrduzaxZs7THiFRq97F8xi1M41BeIR4WeHpwdx6/sTMel4SM1Tuzmb5iN9nWorJjEUF+TBsWxe0xFS+MFhGRhqnG+4zUB+0z4v4Mw+BfPx7hL//eTXGpg/BAP2aNjOfayJaXtV29M5vHF6Rx6R/ci3Fl9iN9FEhERBqAOt9nRKS25BeVMHXpDlbuyAbglh6hvPFALC39fS5ra3cYTF+x+7IgAmBwIZBMX7Gb26LCNWUjIuIiFEbEVNsyzzB+UTpHTp3Dy8PCs3f04PcDIiu99XtjxqlyUzOXMoBsaxEbM06R2LnyO7ZERKThUBgRUxiGwT/W/cyrX+yhxG7QtkUTkkf1Ia5d8yuel1tQeRCpTjsRETGfwojUuzPnipm8ZDtf7zkOwO3R4bx2f2+Cmlz9du/QAL8qfUZV24mIiPkURqRebTl8ivEL0zlmLcLH04M/39WTR/p1uOKOvL90bWRLIoL8yLEWVbhuxAKEB/lVuPBVREQaJm1jKfXC4TCYnXKQB9/dwDFrEZGt/Pn0if48mtixykEEwNPDwrRhF56FdOlZF99PGxalxasiIi5EYUTqXN5ZG7/5f5t4bfVe7A6De+Jas2L8AGLaBFXr990eE8HsR/oQHlR+KiY8yE+39YqIuCBN00idWn/wJBMXp5NbYMPP24Ppd0fzYN92Tl0NqcjtMRHcFhWuHVhFRNyAwojUCbvD4O1vDzDrmwM4DOga2ozkUX3oHh5Qa5/h6WHR7bsiIm5AYURq3fH8IiYuTmfDoVMAPNi3LS/eHU1TH/1xExGRy+nbQWpV6v4TTPpoKycLi2nq48lffxXDr+Lbml2WiIg0YAojUitK7A7e+mo/s1MOAtAzIpB3RsXTKaSZyZWJiEhDpzAiNZZ15jwTFqWz5fBpAB7t14Hn7+yJn7enyZWJiIgrUBiRGvlq93EmL9mG9XwJAb5evHZ/b4b20q21IiJSdQojUi3FpQ5e/WIv/1iXAUBs2yDeHtmH9sFNTa5MRERcjcKIOO3IyXOMW5TG9qNWAP5rQCTP3N4DHy/toSciIs5TGBGnrNyezbNLt1NgK6V5U2/euD+WW6PCzC5LRERcmMKIVElRiZ2XV+5mwYYjAPTt0IJZI+Np3byJyZWJiIirUxiRqzp44ixj/5XG3pwCAJ64qTOTbuuGl6emZUREpOYURuSKPk07yp8+28m5YjvB/j689VAcN3YLMbssERFxIwojUqFzxaW88PkuPtlyFIDETsHMHBFHaKDfVc4UERFxjsKIXGZfTgFjF6bxU+5ZPCwwcVA3xt3SRU/EFRGROqEwImUMw+CjTZlMW74LW6mD0ABfZo6I15NxRUSkTimMCAAFRSU8v2wny7cdA+DGbiG89WAswc18Ta5MRETcncKIsDPLyriFafx88hyeHhb+OKQ7/z2wEx6alhERkXqgMNKIGYbB/PWH+evKPRTbHbRp3oRZI+NI6NDS7NJERKQRURhppKznS5jyyXZW78oB4LaoMF6/vzfNm/qYXJmIiDQ2CiONUPqR04xflM7R0+fx9rTw3NCe/KZ/RywWTcuIiEj9UxhpRBwOg/d/OMTfVu+j1GHQvmVTkkfF07ttc7NLExGRRkxhpJE4VVjM0x9vZe2+EwDc2TuCpPt6EejnbXJlIiLS2CmMNAIbM04xYVE6OflF+Hh5MG1YFKOuba9pGRERaRAURtyY3WEwO+Un3vpqPw4DOoX4886oPvSMCDS7NBERkTJOPXY1KSmJa665hoCAAEJDQ7n33nvZt2/fFc9JSUnBYrFc9tq7d2+NCpcryy0o4rF/bOSNNReCyH192rBi3AAFERERaXCcujKSmprK2LFjueaaaygtLeX5559n8ODB7N69G39//yueu2/fPgID/++LMCRET36tKz8cyOPJj7aSd9ZGE29PXro3hvsT2ppdloiISIWcCiOrV68u9/6f//wnoaGhbNmyhRtuuOGK54aGhtK8eXOnC5SqK7U7mPnNAZLX/oRhQPewAN55OJ4uoQFmlyYiIlIpp6ZpLmW1WgFo2fLqO3bGx8cTERHBoEGDWLt2bU0+ViqQbT3PqPd+5O1vLwSRkde25/Nx1yuIiIhIg1ftBayGYTBp0iQGDBhATExMpe0iIiKYO3cuCQkJ2Gw2PvzwQwYNGkRKSkqlV1NsNhs2m63sfX5+fnXLbBTW7s1l0sdbOX2uhGa+XrxyXy/ujm1tdlkiIiJVYjEMw6jOiWPHjmXlypX88MMPtG3r3HqEYcOGYbFYWL58eYU/f/HFF5k+ffplx61Wa7l1J41did3B61/uY+53hwCIaRNI8sg+dGx15fU7IiIi9SE/P5+goKCrfn9Xa5pm/PjxLF++nLVr1zodRAD69evHgQMHKv351KlTsVqtZa/MzMzqlOnWMk+d44E568uCyG/6d2Tp4/0VRERExOU4NU1jGAbjx49n2bJlpKSkEBkZWa0PTU9PJyIiotKf+/r64uvrW63f3Ris3pnNM59sJ7+olEA/L/52fyy3x4SbXZaIiEi1OBVGxo4dy8KFC/n8888JCAggJ+fCE1+DgoJo0qQJcOGqRlZWFvPnzwdgxowZdOzYkejoaIqLi1mwYAFLly5l6dKltdwV91dUYidp1R4+WH8YgLh2zXl7ZDztWjY1uTIREZHqcyqMzJ49G4Cbbrqp3PF//vOf/OY3vwEgOzubI0eOlP2suLiYyZMnk5WVRZMmTYiOjmblypUMHTq0ZpU3Mj/nFTJ2YRq7jl1YzPuHGzoxeUh3vD1rdEOUiIiI6aq9gLU+VXUBjLtavu0Yz326g7O2Ulr6+/Dmg7Hc3D3U7LJERESuqKrf33o2TQN2vtjOX/69i0UbLyzgvTayJbNGxBMe5GdyZSIiIrVHYaSBOnC8gHEL09l3vACLBcbf3IUJg7ripWkZERFxMwojDYxhGHyy5SgvfL6L8yV2WjXzZeaIOK7v0srs0kREROqEwkgDUmgr5c+f7eTT9CwABnRpxd8fiiMkQLc5i4iI+1IYaSB2H8tn3KI0Dp0oxMMCTw/uzuM3dsbDw2J2aSIiInVKYcRkhmHwrx+P8Jd/76a41EF4oB+zRsZzbeTVHz4oIiLiDhRGTJRfVMLUpTtYuSMbgFt6hPLGA7G09PcxuTIREZH6ozBikm2ZZxi/KJ0jp87h5WFhyu09+P2ASE3LiIhIo6MwUs8Mw+Af637m1S/2UGI3aNuiCW+PjCe+fQuzSxMRETGFwkg9OnOumMlLtvP1nuMA3B4dzmv39yaoibfJlYmIiJhHYaSebDl8ivEL0zlmLcLH04M/39WTR/p1wGLRtIyIiDRuCiN1zOEwePe7Q7yxZh92h0HH4KYkj+pDTJsgs0sTERFpEBRG6lDeWRuTPt7Gd/tPAHB3bGteua8XzXz1r11EROQifSvWkfUHTzJxcTq5BTb8vD2Yfnc0D/Ztp2kZERGRSyiM1DK7w+Dtbw8w65sDOAzoGtqM5FF96B4eYHZpIiIiDZLCSC06nl/Ek4u3sv7QSQAe7NuWF++OpqmP/jWLiIhURt+StSR1/wkmfbSVk4XFNPXx5K+/iuFX8W3NLktERKTBUxipoRK7g7e+2s/slIMA9IwIJHlUPJ1DmplcmYiIiGtQGKmBrDPnmbAonS2HTwPwaL8OPH9nT/y8PU2uTERExHUojFTTV7uPM3nJNqznSwjw9eK1+3sztFeE2WWJiIi4HIURJxWXOnht9V7m/ZABQGzbIN4e2Yf2wU1NrkxERMQ1KYw44cjJc4xblMb2o1YA/mtAJM/c3gMfLw+TKxMREXFdCiNVtHJ7Ns8u3U6BrZSgJt68+UAst0aFmV2WiIiIy1MYuYqiEjsvr9zNgg1HAEjo0IJZI+Np07yJyZWJiIi4h0YbRuwOg40Zp8gtKCI0wI9rI1vi6VF+q/aDJ84y9l9p7M0pAOCJmzrz1G3d8PbUtIyIiEhtaZRhZPXObKav2E22tajsWESQH9OGRXF7zIU7YpalH+X5ZTs5V2wn2N+Htx6K48ZuIWaVLCIi4rYaXRhZvTObxxekYVxyPMdaxOML0pgxIpYfDpxkyZajACR2CmbmiDhCA/3qv1gREZFGoFGFEbvDYPqK3ZcFEaDs2NMfb6fUYeBhgYmDujHuli6XTd+IiIhI7WlUYWRjxqlyUzMVKXUYNG/qzeyHE0jsHFxPlYmIiDRejWolZm7BlYPIRZMHd1MQERERqSeNKoyEBlRt3UfnkIA6rkREREQualRh5NrIlkQE+VHZChALF+6quTayZX2WJSIi0qg1qjDi6WFh2rAogMsCycX304ZFacGqiIhIPXIqjCQlJXHNNdcQEBBAaGgo9957L/v27bvqeampqSQkJODn50enTp2YM2dOtQuuqdtjIpj9SB/Cg8pP2YQH+TH7kT5l+4yIiIhI/XDqbprU1FTGjh3LNddcQ2lpKc8//zyDBw9m9+7d+Pv7V3hORkYGQ4cOZfTo0SxYsIB169bxxBNPEBISwvDhw2ulE866PSaC26LCr7oDq4iIiNQ9i2EYFW27USUnTpwgNDSU1NRUbrjhhgrbTJkyheXLl7Nnz56yY2PGjGHbtm2sX7++Sp+Tn59PUFAQVquVwMDA6pYrIiIi9aiq3981WjNitVoBaNmy8gWf69evZ/DgweWODRkyhM2bN1NSUlLhOTabjfz8/HIvERERcU/VDiOGYTBp0iQGDBhATExMpe1ycnIICwsrdywsLIzS0lLy8vIqPCcpKYmgoKCyV7t27apbpoiIiDRw1Q4j48aNY/v27SxatOiqbS2W8msxLs4MXXr8oqlTp2K1WstemZmZ1S1TREREGrhqbQc/fvx4li9fznfffUfbtm2v2DY8PJycnJxyx3Jzc/Hy8iI4uOJdTn19ffH19a1OaSIiIuJinLoyYhgG48aN49NPP+Xbb78lMjLyquckJiby1VdflTu2Zs0a+vbti7e3t3PVioiIiNtxKoyMHTuWBQsWsHDhQgICAsjJySEnJ4fz58+XtZk6dSq//vWvy96PGTOGw4cPM2nSJPbs2cM//vEP5s2bx+TJk2uvFyIiIuKynAojs2fPxmq1ctNNNxEREVH2+uijj8raZGdnc+TIkbL3kZGRrFq1ipSUFOLi4njppZeYNWuWaXuMiIiISMNSo31G6ov2GREREXE99bLPiIiIiEhNKYyIiIiIqRRGRERExFTV2mekvl1c1qJt4UVERFzHxe/tqy1PdYkwUlBQAKBt4UVERFxQQUEBQUFBlf7cJe6mcTgcHDt2jICAgEq3kK+O/Px82rVrR2ZmptvepePufVT/XJ+799Hd+wfu30f1r/oMw6CgoIDWrVvj4VH5yhCXuDLi4eFx1W3nayIwMNAt/4D9krv3Uf1zfe7eR3fvH7h/H9W/6rnSFZGLtIBVRERETKUwIiIiIqZq1GHE19eXadOmufUTgt29j+qf63P3Prp7/8D9+6j+1T2XWMAqIiIi7qtRXxkRERER8ymMiIiIiKkURkRERMRUCiMiIiJiKrcOI9999x3Dhg2jdevWWCwWPvvss6uek5qaSkJCAn5+fnTq1Ik5c+bUfaHV5Gz/UlJSsFgsl7327t1bPwU7KSkpiWuuuYaAgABCQ0O599572bdv31XPc5UxrE7/XG0MZ8+eTe/evcs2U0pMTOSLL7644jmuMn7gfP9cbfwulZSUhMVi4cknn7xiO1caw0tVpY+uNI4vvvjiZXWGh4df8Rwzxs+tw0hhYSGxsbEkJydXqX1GRgZDhw5l4MCBpKen89xzzzFhwgSWLl1ax5VWj7P9u2jfvn1kZ2eXvbp27VpHFdZMamoqY8eOZcOGDXz11VeUlpYyePBgCgsLKz3HlcawOv27yFXGsG3btrz66qts3ryZzZs3c8stt3DPPfewa9euCtu70viB8/27yFXG75c2bdrE3Llz6d279xXbudoY/lJV+3iRq4xjdHR0uTp37NhRaVvTxs9oJABj2bJlV2zzzDPPGD169Ch37A9/+IPRr1+/OqysdlSlf2vXrjUA4/Tp0/VSU23Lzc01ACM1NbXSNq48hlXpn6uPoWEYRosWLYz333+/wp+58vhddKX+uer4FRQUGF27djW++uor48YbbzQmTpxYaVtXHUNn+uhK4zht2jQjNja2yu3NGj+3vjLirPXr1zN48OByx4YMGcLmzZspKSkxqaraFx8fT0REBIMGDWLt2rVml1NlVqsVgJYtW1baxpXHsCr9u8gVx9But7N48WIKCwtJTEyssI0rj19V+neRq43f2LFjufPOO7n11luv2tZVx9CZPl7kKuN44MABWrduTWRkJCNGjODQoUOVtjVr/FziQXn1JScnh7CwsHLHwsLCKC0tJS8vj4iICJMqqx0RERHMnTuXhIQEbDYbH374IYMGDSIlJYUbbrjB7PKuyDAMJk2axIABA4iJiam0nauOYVX754pjuGPHDhITEykqKqJZs2YsW7aMqKioCtu64vg50z9XHL/FixeTlpbGpk2bqtTeFcfQ2T660jhed911zJ8/n27dunH8+HFefvll+vfvz65duwgODr6svVnjpzByCYvFUu698b8b1F563BV1796d7t27l71PTEwkMzOTN954o8H9B3SpcePGsX37dn744YertnXFMaxq/1xxDLt3787WrVs5c+YMS5cu5bHHHiM1NbXSL2xXGz9n+udq45eZmcnEiRNZs2YNfn5+VT7PlcawOn10pXG84447yv65V69eJCYm0rlzZz744AMmTZpU4TlmjJ+maX4hPDycnJyccsdyc3Px8vKqMEG6g379+nHgwAGzy7ii8ePHs3z5ctauXUvbtm2v2NYVx9CZ/lWkoY+hj48PXbp0oW/fviQlJREbG8vMmTMrbOuK4+dM/yrSkMdvy5Yt5ObmkpCQgJeXF15eXqSmpjJr1iy8vLyw2+2XneNqY1idPlakIY/jL/n7+9OrV69KazVr/HRl5BcSExNZsWJFuWNr1qyhb9++eHt7m1RV3UpPT2+Ql03hQhofP348y5YtIyUlhcjIyKue40pjWJ3+VaQhj2FFDMPAZrNV+DNXGr/KXKl/FWnI4zdo0KDL7rz47W9/S48ePZgyZQqenp6XneNqY1idPlakIY/jL9lsNvbs2cPAgQMr/Llp41eny2NNVlBQYKSnpxvp6ekGYLz11ltGenq6cfjwYcMwDOPZZ581Hn300bL2hw4dMpo2bWo89dRTxu7du4158+YZ3t7exieffGJWF67I2f79/e9/N5YtW2bs37/f2Llzp/Hss88agLF06VKzunBFjz/+uBEUFGSkpKQY2dnZZa9z586VtXHlMaxO/1xtDKdOnWp89913RkZGhrF9+3bjueeeMzw8PIw1a9YYhuHa42cYzvfP1cavIpfeaeLqY1iRq/XRlcbx6aefNlJSUoxDhw4ZGzZsMO666y4jICDA+Pnnnw3DaDjj59Zh5OLtV5e+HnvsMcMwDOOxxx4zbrzxxnLnpKSkGPHx8YaPj4/RsWNHY/bs2fVfeBU527/XXnvN6Ny5s+Hn52e0aNHCGDBggLFy5Upziq+CivoGGP/85z/L2rjyGFanf642hr/73e+MDh06GD4+PkZISIgxaNCgsi9qw3Dt8TMM5/vnauNXkUu/qF19DCtytT660jg+9NBDRkREhOHt7W20bt3auO+++4xdu3aV/byhjJ/FMP53ZYqIiIiICbSAVUREREylMCIiIiKmUhgRERERUymMiIiIiKkURkRERMRUCiMiIiJiKoURERERMZXCiIiIiJhKYURERERMpTAiIiIiplIYEREREVMpjIiIiIip/j+yQQ6S6XdD8QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.plot(x,ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c93ae9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.55368848"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1=0.6368*x+0.5396\n",
    "(sum((y-y1)**2))/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f230c0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1: m = 0.6368, c = 0.5396, loss = 4.3420000000000005\n",
      "Iteration 2: m = 0.741128, c = 0.5701999999999999, loss = 2.55368848\n",
      "Iteration 3: m = 0.82066784, c = 0.59392832, loss = 1.5114379498240005\n",
      "Iteration 4: m = 0.881285216, c = 0.6124096832, loss = 0.9039555795463169\n",
      "Iteration 5: m = 0.927457887488, c = 0.626884376576, loss = 0.5498353139033791\n",
      "Iteration 6: m = 0.9626040896460799, c = 0.6382992157952001, loss = 0.34336267967347356\n",
      "Iteration 7: m = 0.9893332369762303, c = 0.6473769861005313, loss = 0.22293251044249524\n",
      "Iteration 8: m = 1.0096373056754278, c = 0.6546694521599469, loss = 0.15264436013137625\n",
      "Iteration 9: m = 1.025036931297237, c = 0.6605978247762223, loss = 0.1115772211499588\n",
      "Iteration 10: m = 1.0366929369252715, c = 0.6654836524028637, loss = 0.0875393611101418\n",
      "Iteration 11: m = 1.04549147165754, c = 0.6695724031392901, loss = 0.07342603708702748\n",
      "Iteration 12: m = 1.0521090037045238, c = 0.673051466777052, loss = 0.06509695180763637\n",
      "Iteration 13: m = 1.0570619348829053, c = 0.6760638972192395, loss = 0.06013934019760636\n",
      "Iteration 14: m = 1.0607444753755118, c = 0.6787189031818804, loss = 0.05714715745588968\n",
      "Iteration 15: m = 1.0634575566019864, c = 0.6810998565957121, loss = 0.05530102554948661\n",
      "Iteration 16: m = 1.0654309027538067, c = 0.6832704060676787, loss = 0.05412344682582182\n",
      "Iteration 17: m = 1.0668398797839085, c = 0.6852791437810968, loss = 0.053336154624387254\n",
      "Iteration 18: m = 1.0678183576045828, c = 0.6871631681184404, loss = 0.052776984275093496\n",
      "Iteration 19: m = 1.0684685288444682, c = 0.6889508032997966, loss = 0.052351429631338944\n",
      "Iteration 20: m = 1.0688684043006973, c = 0.6906636755031326, loss = 0.052004412615547765\n",
      "Iteration 21: m = 1.069077534824356, c = 0.6923182977350281, loss = 0.051703831907695244\n",
      "Iteration 22: m = 1.069141379298896, c = 0.6939272796908662, loss = 0.051430975935222764\n",
      "Iteration 23: m = 1.069094639071687, c = 0.6955002513391151, loss = 0.05117493603797417\n",
      "Iteration 24: m = 1.0689638033955688, c = 0.6970445679680316, loss = 0.05092935073710071\n",
      "Iteration 25: m = 1.0687690925704618, c = 0.6985658484049369, loss = 0.050690508455955595\n",
      "Iteration 26: m = 1.068525941300664, c = 0.7000683858826104, loss = 0.05045624187955593\n",
      "Iteration 27: m = 1.0682461310615614, c = 0.7015554616869184, loss = 0.05022528364181229\n",
      "Iteration 28: m = 1.0679386545268028, c = 0.7030295845894864, loss = 0.0499968908517444\n",
      "Iteration 29: m = 1.067610375455537, c = 0.7044926736260885, loss = 0.049770626285748194\n",
      "Iteration 30: m = 1.0672665324377537, c = 0.7059461976262345, loss = 0.04954623087708595\n",
      "Iteration 31: m = 1.0669111234438737, c = 0.7073912817274446, loss = 0.04932354940887489\n",
      "Iteration 32: m = 1.0665471993825748, c = 0.7088287886862633, loss = 0.049102487211447776\n",
      "Iteration 33: m = 1.0661770881972326, c = 0.7102593809495835, loss = 0.048882984927522626\n",
      "Iteration 34: m = 1.0658025659368664, c = 0.7116835680387579, loss = 0.048665003806402554\n",
      "Iteration 35: m = 1.0654249873484303, c = 0.7131017427217707, loss = 0.04844851713397123\n",
      "Iteration 36: m = 1.0650453855684694, c = 0.7145142086264296, loss = 0.04823350523832935\n",
      "Iteration 37: m = 1.0646645482258204, c = 0.7159212013197928, loss = 0.04801995257913945\n",
      "Iteration 38: m = 1.0642830755369523, c = 0.7173229043998477, loss = 0.04780784605125168\n",
      "Iteration 39: m = 1.063901424654832, c = 0.7187194617796336, loss = 0.04759717399595571\n",
      "Iteration 40: m = 1.0635199435239908, c = 0.7201109870647511, loss = 0.04738792562460338\n",
      "Iteration 41: m = 1.0631388967248279, c = 0.7214975707120166, loss = 0.0471800906825406\n",
      "Iteration 42: m = 1.0627584852026448, c = 0.7228792854942866, loss = 0.046973659253081154\n",
      "Iteration 43: m = 1.0623788613284058, c = 0.7242561906722421, loss = 0.04676862164309236\n",
      "Iteration 44: m = 1.062000140395822, c = 0.725628335179093, loss = 0.04656496831614028\n",
      "Iteration 45: m = 1.0616224093979956, c = 0.7269957600517618, loss = 0.04636268985335109\n",
      "Iteration 46: m = 1.0612457337273309, c = 0.7283585002868468, loss = 0.04616177693042644\n",
      "Iteration 47: m = 1.0608701622901073, c = 0.72971658625747, loss = 0.045962220304073424\n",
      "Iteration 48: m = 1.0604957314108356, c = 0.7310700447949142, loss = 0.04576401080392066\n",
      "Iteration 49: m = 1.060122467812757, c = 0.7324189000143658, loss = 0.04556713932763547\n",
      "Iteration 50: m = 1.0597503908930885, c = 0.7337631739453131, loss = 0.045371596837904524\n",
      "Iteration 51: m = 1.0593795144598903, c = 0.7351028870128216, loss = 0.045177374360503605\n",
      "Iteration 52: m = 1.059009848057945, c = 0.7364380584049717, loss = 0.044984462983003196\n",
      "Iteration 53: m = 1.0586413979808988, c = 0.7377687063533955, loss = 0.04479285385384424\n",
      "Iteration 54: m = 1.0582741680438974, c = 0.7390948483474737, loss = 0.04460253818163207\n",
      "Iteration 55: m = 1.0579081601733915, c = 0.7404165012978904, loss = 0.044413507234559106\n",
      "Iteration 56: m = 1.057543374857372, c = 0.7417336816615291, loss = 0.04422575233990104\n",
      "Iteration 57: m = 1.0571798114890585, c = 0.7430464055368562, loss = 0.04403926488356093\n",
      "Iteration 58: m = 1.0568174686292542, c = 0.7443546887367756, loss = 0.04385403630963843\n",
      "Iteration 59: m = 1.0564563442066117, c = 0.7456585468442848, loss = 0.043670058120017355\n",
      "Iteration 60: m = 1.0560964356705, c = 0.7469579952550024, loss = 0.04348732187396446\n",
      "Iteration 61: m = 1.05573774010769, c = 0.7482530492096724, loss = 0.04330581918773475\n",
      "Iteration 62: m = 1.055380254331418, c = 0.7495437238190176, loss = 0.043125541734183495\n",
      "Iteration 63: m = 1.0550239749493648, c = 0.7508300340827522, loss = 0.04294648124238087\n",
      "Iteration 64: m = 1.0546688984155395, c = 0.7521119949041353, loss = 0.04276862949723256\n",
      "Iteration 65: m = 1.0543150210698726, c = 0.7533896211011202, loss = 0.042591978339100514\n",
      "Iteration 66: m = 1.0539623391684334, c = 0.7546629274149054, loss = 0.04241651966342939\n",
      "Iteration 67: m = 1.0536108489064837, c = 0.7559319285165013, loss = 0.042242245420373706\n",
      "Iteration 68: m = 1.0532605464360671, c = 0.7571966390117822, loss = 0.042069147614428884\n",
      "Iteration 69: m = 1.0529114278794254, c = 0.7584570734453826, loss = 0.04189721830406383\n",
      "Iteration 70: m = 1.0525634893392288, c = 0.7597132463037094, loss = 0.04172644960135679\n",
      "Iteration 71: m = 1.052216726906376, c = 0.7609651720172815, loss = 0.04155683367163364\n",
      "Iteration 72: m = 1.0518711366659363, c = 0.7622128649625534, loss = 0.04138836273310802\n",
      "Iteration 73: m = 1.0515267147016771, c = 0.7634563394633461, loss = 0.04122102905652424\n",
      "Iteration 74: m = 1.0511834570995073, c = 0.7646956097919786, loss = 0.041054824964803484\n",
      "Iteration 75: m = 1.050841359950097, c = 0.7659306901701686, loss = 0.04088974283269055\n",
      "Iteration 76: m = 1.0505004193508656, c = 0.7671615947697594, loss = 0.04072577508640463\n",
      "Iteration 77: m = 1.0501606314074896, c = 0.7683883377133123, loss = 0.04056291420329164\n",
      "Iteration 78: m = 1.0498219922350431, c = 0.7696109330745966, loss = 0.040401152711479246\n",
      "Iteration 79: m = 1.0494844979588578, c = 0.770829394879002, loss = 0.0402404831895337\n",
      "Iteration 80: m = 1.049148144715169, c = 0.7720437371038905, loss = 0.04008089826611988\n",
      "Iteration 81: m = 1.0488129286515984, c = 0.7732539736789026, loss = 0.0399223906196625\n",
      "Iteration 82: m = 1.0484788459275125, c = 0.7744601184862286, loss = 0.039764952978010686\n",
      "Iteration 83: m = 1.0481458927142862, c = 0.7756621853608533, loss = 0.03960857811810429\n",
      "Iteration 84: m = 1.047814065195492, c = 0.7768601880907791, loss = 0.03945325886564237\n",
      "Iteration 85: m = 1.047483359567037, c = 0.778054140417234, loss = 0.03929898809475367\n",
      "Iteration 86: m = 1.0471537720372548, c = 0.7792440560348671, loss = 0.039145758727670454\n",
      "Iteration 87: m = 1.0468252988269666, c = 0.7804299485919345, loss = 0.03899356373440319\n",
      "Iteration 88: m = 1.046497936169518, c = 0.7816118316904778, loss = 0.038842396132418695\n",
      "Iteration 89: m = 1.0461716803107952, c = 0.7827897188864972, loss = 0.038692248986318706\n",
      "Iteration 90: m = 1.0458465275092304, c = 0.7839636236901195, loss = 0.038543115407522685\n",
      "Iteration 91: m = 1.0455224740357925, c = 0.7851335595657634, loss = 0.03839498855395124\n",
      "Iteration 92: m = 1.0451995161739722, c = 0.7862995399323005, loss = 0.03824786162971281\n",
      "Iteration 93: m = 1.0448776502197603, c = 0.7874615781632162, loss = 0.03810172788479079\n",
      "Iteration 94: m = 1.04455687248162, c = 0.7886196875867663, loss = 0.037956580614735\n",
      "Iteration 95: m = 1.0442371792804577, c = 0.7897738814861337, loss = 0.037812413160353456\n",
      "Iteration 96: m = 1.043918566949589, c = 0.7909241730995835, loss = 0.03766921890740699\n",
      "Iteration 97: m = 1.0436010318347044, c = 0.7920705756206166, loss = 0.03752699128630596\n",
      "Iteration 98: m = 1.0432845702938325, c = 0.7932131021981219, loss = 0.03738572377180825\n",
      "Iteration 99: m = 1.042969178697302, c = 0.7943517659365296, loss = 0.03724540988272097\n",
      "Iteration 100: m = 1.0426548534277038, c = 0.7954865798959608, loss = 0.037106043181602\n",
      "Iteration 101: m = 1.0423415908798512, c = 0.7966175570923794, loss = 0.03696761727446552\n",
      "Iteration 102: m = 1.0420293874607411, c = 0.7977447104977407, loss = 0.03683012581048789\n",
      "Iteration 103: m = 1.0417182395895137, c = 0.7988680530401414, loss = 0.036693562481716735\n",
      "Iteration 104: m = 1.0414081436974123, c = 0.7999875976039678, loss = 0.03655792102278181\n",
      "Iteration 105: m = 1.0410990962277435, c = 0.8011033570300437, loss = 0.036423195210606635\n",
      "Iteration 106: m = 1.0407910936358373, c = 0.8022153441157782, loss = 0.036289378864124255\n",
      "Iteration 107: m = 1.0404841323890064, c = 0.8033235716153124, loss = 0.036156465843992326\n",
      "Iteration 108: m = 1.0401782089665061, c = 0.8044280522396658, loss = 0.03602445005231254\n",
      "Iteration 109: m = 1.039873319859495, c = 0.8055287986568822, loss = 0.03589332543235014\n",
      "Iteration 110: m = 1.0395694615709932, c = 0.8066258234921748, loss = 0.035763085968256385\n",
      "Iteration 111: m = 1.0392666306158442, c = 0.8077191393280717, loss = 0.03563372568479263\n",
      "Iteration 112: m = 1.0389648235206743, c = 0.8088087587045596, loss = 0.035505238647055945\n",
      "Iteration 113: m = 1.0386640368238524, c = 0.809894694119228, loss = 0.035377618960206754\n",
      "Iteration 114: m = 1.0383642670754512, c = 0.8109769580274123, loss = 0.03525086076919877\n",
      "Iteration 115: m = 1.0380655108372072, c = 0.812055562842337, loss = 0.03512495825851014\n",
      "Iteration 116: m = 1.0377677646824814, c = 0.8131305209352578, loss = 0.03499990565187647\n",
      "Iteration 117: m = 1.03747102519622, c = 0.8142018446356037, loss = 0.03487569721202629\n",
      "Iteration 118: m = 1.0371752889749153, c = 0.8152695462311185, loss = 0.034752327240417304\n",
      "Iteration 119: m = 1.0368805526265668, c = 0.8163336379680012, loss = 0.03462979007697524\n",
      "Iteration 120: m = 1.036586812770642, c = 0.8173941320510472, loss = 0.03450808009983407\n",
      "Iteration 121: m = 1.036294066038038, c = 0.8184510406437877, loss = 0.03438719172507832\n",
      "Iteration 122: m = 1.0360023090710424, c = 0.8195043758686297, loss = 0.03426711940648674\n",
      "Iteration 123: m = 1.0357115385232953, c = 0.8205541498069945, loss = 0.034147857635277404\n",
      "Iteration 124: m = 1.0354217510597508, c = 0.8216003744994569, loss = 0.034029400939855826\n",
      "Iteration 125: m = 1.035132943356638, c = 0.8226430619458827, loss = 0.0339117438855631\n",
      "Iteration 126: m = 1.0348451121014248, c = 0.8236822241055667, loss = 0.033794881074427234\n",
      "Iteration 127: m = 1.0345582539927773, c = 0.8247178728973699, loss = 0.03367880714491515\n",
      "Iteration 128: m = 1.0342723657405242, c = 0.8257500201998558, loss = 0.033563516771686765\n",
      "Iteration 129: m = 1.0339874440656176, c = 0.8267786778514272, loss = 0.03344900466535046\n",
      "Iteration 130: m = 1.0337034857000962, c = 0.8278038576504616, loss = 0.03333526557222107\n",
      "Iteration 131: m = 1.0334204873870474, c = 0.8288255713554467, loss = 0.033222294274077906\n",
      "Iteration 132: m = 1.0331384458805701, c = 0.8298438306851149, loss = 0.033110085587926066\n",
      "Iteration 133: m = 1.0328573579457379, c = 0.8308586473185784, loss = 0.03299863436575841\n",
      "Iteration 134: m = 1.0325772203585608, c = 0.8318700328954626, loss = 0.03288793549431955\n",
      "Iteration 135: m = 1.0322980299059497, c = 0.8328779990160396, loss = 0.032777983894870744\n",
      "Iteration 136: m = 1.0320197833856783, c = 0.8338825572413618, loss = 0.032668774522957564\n",
      "Iteration 137: m = 1.0317424776063475, c = 0.8348837190933939, loss = 0.03256030236817782\n",
      "Iteration 138: m = 1.0314661093873474, c = 0.8358814960551452, loss = 0.03245256245395254\n",
      "Iteration 139: m = 1.0311906755588223, c = 0.8368758995708014, loss = 0.032345549837296275\n",
      "Iteration 140: m = 1.0309161729616334, c = 0.8378669410458561, loss = 0.032239259608592016\n",
      "Iteration 141: m = 1.0306425984473226, c = 0.838854631847241, loss = 0.03213368689136477\n",
      "Iteration 142: m = 1.0303699488780773, c = 0.8398389833034567, loss = 0.03202882684205773\n",
      "Iteration 143: m = 1.030098221126693, c = 0.840820006704703, loss = 0.031924674649811316\n",
      "Iteration 144: m = 1.0298274120765383, c = 0.8417977133030073, loss = 0.03182122553624095\n",
      "Iteration 145: m = 1.0295575186215193, c = 0.8427721143123549, loss = 0.03171847475521876\n",
      "Iteration 146: m = 1.029288537666044, c = 0.8437432209088166, loss = 0.03161641759265566\n",
      "Iteration 147: m = 1.0290204661249853, c = 0.8447110442306777, loss = 0.0315150493662847\n",
      "Iteration 148: m = 1.0287533009236478, c = 0.845675595378565, loss = 0.03141436542544687\n",
      "Iteration 149: m = 1.0284870389977314, c = 0.8466368854155748, loss = 0.03131436115087718\n",
      "Iteration 150: m = 1.028221677293296, c = 0.8475949253673994, loss = 0.031215031954493145\n",
      "Iteration 151: m = 1.027957212766727, c = 0.8485497262224537, loss = 0.0311163732791839\n",
      "Iteration 152: m = 1.0276936423846998, c = 0.849501298932001, loss = 0.031018380598601476\n",
      "Iteration 153: m = 1.0274309631241458, c = 0.850449654410279, loss = 0.03092104941695295\n",
      "Iteration 154: m = 1.027169171972217, c = 0.8513948035346246, loss = 0.030824375268794134\n",
      "Iteration 155: m = 1.0269082659262516, c = 0.8523367571455991, loss = 0.030728353718824885\n",
      "Iteration 156: m = 1.0266482419937404, c = 0.853275526047112, loss = 0.030632980361685512\n",
      "Iteration 157: m = 1.0263890971922909, c = 0.8542111210065453, loss = 0.030538250821754615\n",
      "Iteration 158: m = 1.0261308285495943, c = 0.855143552754877, loss = 0.030444160752948517\n",
      "Iteration 159: m = 1.025873433103391, c = 0.8560728319868037, loss = 0.030350705838521685\n",
      "Iteration 160: m = 1.0256169079014368, c = 0.8569989693608642, loss = 0.030257881790868628\n",
      "Iteration 161: m = 1.0253612500014688, c = 0.8579219754995607, loss = 0.0301656843513274\n",
      "Iteration 162: m = 1.025106456471172, c = 0.8588418609894813, loss = 0.030074109289984143\n",
      "Iteration 163: m = 1.0248525243881452, c = 0.8597586363814214, loss = 0.029983152405479226\n",
      "Iteration 164: m = 1.024599450839868, c = 0.8606723121905042, loss = 0.02989280952481385\n",
      "Iteration 165: m = 1.0243472329236667, c = 0.861582898896302, loss = 0.029803076503159158\n",
      "Iteration 166: m = 1.0240958677466818, c = 0.862490406942956, loss = 0.029713949223666075\n",
      "Iteration 167: m = 1.0238453524258344, c = 0.8633948467392959, loss = 0.02962542359727624\n",
      "Iteration 168: m = 1.0235956840877931, c = 0.8642962286589599, loss = 0.02953749556253435\n",
      "Iteration 169: m = 1.023346859868941, c = 0.8651945630405131, loss = 0.029450161085401976\n",
      "Iteration 170: m = 1.0230988769153433, c = 0.8660898601875664, loss = 0.029363416159072453\n",
      "Iteration 171: m = 1.0228517323827138, c = 0.8669821303688945, loss = 0.0292772568037871\n",
      "Iteration 172: m = 1.022605423436383, c = 0.8678713838185538, loss = 0.029191679066652466\n",
      "Iteration 173: m = 1.0223599472512654, c = 0.8687576307359998, loss = 0.02910667902145911\n",
      "Iteration 174: m = 1.0221153010118271, c = 0.8696408812862039, loss = 0.02902225276850142\n",
      "Iteration 175: m = 1.021871481912053, c = 0.8705211455997701, loss = 0.028938396434398744\n",
      "Iteration 176: m = 1.021628487155415, c = 0.8713984337730516, loss = 0.028855106171917794\n",
      "Iteration 177: m = 1.0213863139548407, c = 0.8722727558682657, loss = 0.028772378159795765\n",
      "Iteration 178: m = 1.0211449595326798, c = 0.8731441219136099, loss = 0.028690208602565343\n",
      "Iteration 179: m = 1.0209044211206737, c = 0.874012541903377, loss = 0.028608593730380633\n",
      "Iteration 180: m = 1.0206646959599228, c = 0.874878025798069, loss = 0.02852752979884398\n",
      "Iteration 181: m = 1.0204257813008557, c = 0.8757405835245122, loss = 0.028447013088834072\n",
      "Iteration 182: m = 1.0201876744031968, c = 0.8766002249759707, loss = 0.02836703990633572\n",
      "Iteration 183: m = 1.0199503725359353, c = 0.8774569600122595, loss = 0.028287606582270235\n",
      "Iteration 184: m = 1.019713872977294, c = 0.8783107984598582, loss = 0.028208709472326628\n",
      "Iteration 185: m = 1.019478173014698, c = 0.8791617501120234, loss = 0.02813034495679532\n",
      "Iteration 186: m = 1.0192432699447431, c = 0.880009824728901, loss = 0.028052509440401042\n",
      "Iteration 187: m = 1.0190091610731655, c = 0.8808550320376384, loss = 0.027975199352138914\n",
      "Iteration 188: m = 1.018775843714811, c = 0.8816973817324957, loss = 0.02789841114510977\n",
      "Iteration 189: m = 1.0185433151936027, c = 0.8825368834749571, loss = 0.027822141296357607\n",
      "Iteration 190: m = 1.0183115728425127, c = 0.8833735468938417, loss = 0.027746386306708774\n",
      "Iteration 191: m = 1.0180806140035294, c = 0.8842073815854141, loss = 0.027671142700609976\n",
      "Iteration 192: m = 1.0178504360276281, c = 0.8850383971134941, loss = 0.02759640702597014\n",
      "Iteration 193: m = 1.0176210362747404, c = 0.8858666030095665, loss = 0.027522175854001418\n",
      "Iteration 194: m = 1.0173924121137234, c = 0.8866920087728908, loss = 0.02744844577906177\n",
      "Iteration 195: m = 1.0171645609223308, c = 0.8875146238706095, loss = 0.027375213418499123\n",
      "Iteration 196: m = 1.0169374800871813, c = 0.8883344577378575, loss = 0.027302475412495898\n",
      "Iteration 197: m = 1.0167111670037299, c = 0.8891515197778694, loss = 0.027230228423914933\n",
      "Iteration 198: m = 1.016485619076237, c = 0.8899658193620883, loss = 0.02715846913814645\n",
      "Iteration 199: m = 1.0162608337177397, c = 0.8907773658302723, loss = 0.02708719426295584\n",
      "Iteration 200: m = 1.0160368083500206, c = 0.8915861684906025, loss = 0.027016400528332866\n",
      "Iteration 201: m = 1.01581354040358, c = 0.8923922366197892, loss = 0.026946084686341094\n",
      "Iteration 202: m = 1.015591027317605, c = 0.8931955794631786, loss = 0.026876243510969837\n",
      "Iteration 203: m = 1.0153692665399412, c = 0.8939962062348588, loss = 0.02680687379798493\n",
      "Iteration 204: m = 1.0151482555270626, c = 0.8947941261177651, loss = 0.026737972364782963\n",
      "Iteration 205: m = 1.0149279917440428, c = 0.895589348263786, loss = 0.02666953605024428\n",
      "Iteration 206: m = 1.0147084726645261, c = 0.8963818817938677, loss = 0.02660156171458843\n",
      "Iteration 207: m = 1.0144896957706984, c = 0.8971717357981187, loss = 0.026534046239230134\n",
      "Iteration 208: m = 1.0142716585532576, c = 0.8979589193359144, loss = 0.026466986526635938\n",
      "Iteration 209: m = 1.0140543585113861, c = 0.8987434414360007, loss = 0.026400379500182397\n",
      "Iteration 210: m = 1.0138377931527212, c = 0.8995253110965975, loss = 0.026334222104014805\n",
      "Iteration 211: m = 1.0136219599933267, c = 0.9003045372855023, loss = 0.026268511302906854\n",
      "Iteration 212: m = 1.0134068565576646, c = 0.9010811289401927, loss = 0.026203244082121734\n",
      "Iteration 213: m = 1.0131924803785668, c = 0.9018550949679289, loss = 0.026138417447273143\n",
      "Iteration 214: m = 1.0129788289972064, c = 0.9026264442458564, loss = 0.026074028424188996\n",
      "Iteration 215: m = 1.0127658999630695, c = 0.9033951856211069, loss = 0.026010074058773834\n",
      "Iteration 216: m = 1.0125536908339279, c = 0.9041613279109005, loss = 0.0259465514168739\n",
      "Iteration 217: m = 1.0123421991758097, c = 0.9049248799026468, loss = 0.025883457584142705\n",
      "Iteration 218: m = 1.0121314225629727, c = 0.9056858503540453, loss = 0.025820789665906667\n",
      "Iteration 219: m = 1.011921358577876, c = 0.906444247993186, loss = 0.025758544787032933\n",
      "Iteration 220: m = 1.011712004811152, c = 0.9072000815186497, loss = 0.02569672009179707\n",
      "Iteration 221: m = 1.0115033588615796, c = 0.9079533595996077, loss = 0.02563531274375235\n",
      "Iteration 222: m = 1.0112954183360556, c = 0.9087040908759207, loss = 0.025574319925599165\n",
      "Iteration 223: m = 1.0110881808495682, c = 0.909452283958239, loss = 0.025513738839056326\n",
      "Iteration 224: m = 1.010881644025169, c = 0.9101979474281001, loss = 0.025453566704732467\n",
      "Iteration 225: m = 1.0106758054939458, c = 0.910941089838028, loss = 0.02539380076199821\n",
      "Iteration 226: m = 1.010470662894996, c = 0.9116817197116307, loss = 0.02533443826886018\n",
      "Iteration 227: m = 1.010266213875399, c = 0.9124198455436984, loss = 0.02527547650183428\n",
      "Iteration 228: m = 1.0100624560901894, c = 0.9131554758003004, loss = 0.02521691275582179\n",
      "Iteration 229: m = 1.0098593872023298, c = 0.9138886189188831, loss = 0.025158744343984518\n",
      "Iteration 230: m = 1.0096570048826843, c = 0.9146192833083656, loss = 0.025100968597621724\n",
      "Iteration 231: m = 1.0094553068099918, c = 0.9153474773492373, loss = 0.025043582866047596\n",
      "Iteration 232: m = 1.0092542906708395, c = 0.916073209393653, loss = 0.024986584516470154\n",
      "Iteration 233: m = 1.0090539541596357, c = 0.9167964877655296, loss = 0.02492997093386977\n",
      "Iteration 234: m = 1.0088542949785841, c = 0.9175173207606409, loss = 0.02487373952087944\n",
      "Iteration 235: m = 1.0086553108376572, c = 0.918235716646713, loss = 0.02481788769766585\n",
      "Iteration 236: m = 1.0084569994545698, c = 0.9189516836635193, loss = 0.024762412901810693\n",
      "Iteration 237: m = 1.0082593585547532, c = 0.9196652300229747, loss = 0.024707312588193385\n",
      "Iteration 238: m = 1.0080623858713291, c = 0.92037636390923, loss = 0.024652584228874116\n",
      "Iteration 239: m = 1.0078660791450829, c = 0.9210850934787657, loss = 0.024598225312977763\n",
      "Iteration 240: m = 1.0076704361244386, c = 0.9217914268604853, loss = 0.024544233346579042\n",
      "Iteration 241: m = 1.007475454565433, c = 0.9224953721558093, loss = 0.024490605852587874\n",
      "Iteration 242: m = 1.0072811322316892, c = 0.9231969374387672, loss = 0.024437340370635552\n",
      "Iteration 243: m = 1.0070874668943917, c = 0.9238961307560905, loss = 0.024384434456962496\n",
      "Iteration 244: m = 1.0068944563322602, c = 0.9245929601273052, loss = 0.024331885684305242\n",
      "Iteration 245: m = 1.0067020983315247, c = 0.9252874335448235, loss = 0.024279691641785745\n",
      "Iteration 246: m = 1.0065103906858999, c = 0.9259795589740355, loss = 0.024227849934800726\n",
      "Iteration 247: m = 1.0063193311965597, c = 0.9266693443534008, loss = 0.02417635818491148\n",
      "Iteration 248: m = 1.0061289176721124, c = 0.9273567975945392, loss = 0.024125214029734773\n",
      "Iteration 249: m = 1.0059391479285753, c = 0.9280419265823217, loss = 0.024074415122835216\n",
      "Iteration 250: m = 1.0057500197893494, c = 0.9287247391749607, loss = 0.024023959133616202\n",
      "Iteration 251: m = 1.0055615310851949, c = 0.9294052432041005, loss = 0.023973843747214625\n",
      "Iteration 252: m = 1.0053736796542059, c = 0.9300834464749067, loss = 0.023924066664393055\n",
      "Iteration 253: m = 1.0051864633417862, c = 0.9307593567661562, loss = 0.023874625601435755\n",
      "Iteration 254: m = 1.004999880000624, c = 0.9314329818303259, loss = 0.02382551829004278\n",
      "Iteration 255: m = 1.0048139274906671, c = 0.9321043293936819, loss = 0.023776742477226345\n",
      "Iteration 256: m = 1.0046286036790995, c = 0.9327734071563683, loss = 0.023728295925207605\n",
      "Iteration 257: m = 1.0044439064403154, c = 0.933440222792495, loss = 0.023680176411313807\n",
      "Iteration 258: m = 1.0042598336558963, c = 0.9341047839502261, loss = 0.023632381727876114\n",
      "Iteration 259: m = 1.0040763832145856, c = 0.9347670982518678, loss = 0.02358490968212896\n",
      "Iteration 260: m = 1.0038935530122648, c = 0.9354271732939553, loss = 0.02353775809610856\n",
      "Iteration 261: m = 1.0037113409519292, c = 0.9360850166473403, loss = 0.02349092480655369\n",
      "Iteration 262: m = 1.0035297449436644, c = 0.9367406358572777, loss = 0.023444407664806287\n",
      "Iteration 263: m = 1.0033487629046216, c = 0.9373940384435123, loss = 0.02339820453671261\n",
      "Iteration 264: m = 1.003168392758994, c = 0.9380452319003648, loss = 0.023352313302525775\n",
      "Iteration 265: m = 1.0029886324379935, c = 0.9386942236968179, loss = 0.0233067318568077\n",
      "Iteration 266: m = 1.002809479879826, c = 0.9393410212766019, loss = 0.02326145810833385\n",
      "Iteration 267: m = 1.002630933029668, c = 0.9399856320582803, loss = 0.023216489979995567\n",
      "Iteration 268: m = 1.0024529898396444, c = 0.9406280634353347, loss = 0.02317182540870656\n",
      "Iteration 269: m = 1.0022756482688024, c = 0.9412683227762493, loss = 0.023127462345306854\n",
      "Iteration 270: m = 1.002098906283091, c = 0.9419064174245961, loss = 0.02308339875446938\n",
      "Iteration 271: m = 1.0019227618553352, c = 0.9425423546991187, loss = 0.023039632614606738\n",
      "Iteration 272: m = 1.0017472129652143, c = 0.9431761418938163, loss = 0.022996161917778035\n",
      "Iteration 273: m = 1.0015722575992383, c = 0.9438077862780271, loss = 0.02295298466959717\n",
      "Iteration 274: m = 1.0013978937507242, c = 0.9444372950965122, loss = 0.022910098889140862\n",
      "Iteration 275: m = 1.0012241194197742, c = 0.9450646755695385, loss = 0.022867502608858246\n",
      "Iteration 276: m = 1.0010509326132515, c = 0.9456899348929614, loss = 0.022825193874480385\n",
      "Iteration 277: m = 1.0008783313447585, c = 0.9463130802383071, loss = 0.02278317074493049\n",
      "Iteration 278: m = 1.0007063136346133, c = 0.9469341187528554, loss = 0.0227414312922351\n",
      "Iteration 279: m = 1.000534877509827, c = 0.9475530575597215, loss = 0.02269997360143565\n",
      "Iteration 280: m = 1.0003640210040818, c = 0.9481699037579375, loss = 0.022658795770500135\n",
      "Iteration 281: m = 1.0001937421577076, c = 0.9487846644225338, loss = 0.022617895910236586\n",
      "Iteration 282: m = 1.00002403901766, c = 0.9493973466046207, loss = 0.022577272144205705\n",
      "Iteration 283: m = 0.9998549096374976, c = 0.9500079573314687, loss = 0.022536922608635327\n",
      "Iteration 284: m = 0.99968635207736, c = 0.9506165036065894, loss = 0.02249684545233456\n",
      "Iteration 285: m = 0.9995183644039455, c = 0.951222992409816, loss = 0.022457038836608875\n",
      "Iteration 286: m = 0.9993509446904885, c = 0.951827430697383, loss = 0.022417500935176034\n",
      "Iteration 287: m = 0.999184091016738, c = 0.9524298254020059, loss = 0.022378229934082013\n",
      "Iteration 288: m = 0.9990178014689353, c = 0.9530301834329615, loss = 0.022339224031617748\n",
      "Iteration 289: m = 0.9988520741397918, c = 0.9536285116761661, loss = 0.02230048143823683\n",
      "Iteration 290: m = 0.9986869071284676, c = 0.9542248169942553, loss = 0.022262000376473048\n",
      "Iteration 291: m = 0.9985222985405494, c = 0.9548191062266621, loss = 0.022223779080858857\n",
      "Iteration 292: m = 0.9983582464880288, c = 0.9554113861896959, loss = 0.02218581579784471\n",
      "Iteration 293: m = 0.9981947490892807, c = 0.9560016636766202, loss = 0.02214810878571822\n",
      "Iteration 294: m = 0.9980318044690418, c = 0.9565899454577309, loss = 0.02211065631452459\n",
      "Iteration 295: m = 0.9978694107583888, c = 0.9571762382804337, loss = 0.022073456665986785\n",
      "Iteration 296: m = 0.9977075660947172, c = 0.9577605488693217, loss = 0.022036508133427366\n",
      "Iteration 297: m = 0.9975462686217201, c = 0.9583428839262522, loss = 0.021999809021689333\n",
      "Iteration 298: m = 0.9973855164893666, c = 0.958923250130424, loss = 0.021963357647059346\n",
      "Iteration 299: m = 0.9972253078538805, c = 0.9595016541384536, loss = 0.021927152337189643\n",
      "Iteration 300: m = 0.9970656408777196, c = 0.9600781025844517, loss = 0.02189119143102166\n",
      "Iteration 301: m = 0.9969065137295542, c = 0.9606526020800995, loss = 0.021855473278709882\n",
      "Iteration 302: m = 0.9967479245842463, c = 0.9612251592147243, loss = 0.021819996241546007\n",
      "Iteration 303: m = 0.9965898716228286, c = 0.9617957805553751, loss = 0.02178475869188396\n",
      "Iteration 304: m = 0.9964323530324838, c = 0.9623644726468978, loss = 0.021749759013064748\n",
      "Iteration 305: m = 0.9962753670065235, c = 0.9629312420120109, loss = 0.021714995599342944\n",
      "Iteration 306: m = 0.9961189117443677, c = 0.9634960951513792, loss = 0.021680466855812677\n",
      "Iteration 307: m = 0.9959629854515241, c = 0.9640590385436896, loss = 0.02164617119833426\n",
      "Iteration 308: m = 0.9958075863395675, c = 0.9646200786457243, loss = 0.021612107053461952\n",
      "Iteration 309: m = 0.9956527126261192, c = 0.9651792218924358, loss = 0.021578272858371484\n",
      "Iteration 310: m = 0.9954983625348268, c = 0.96573647469702, loss = 0.02154466706078833\n",
      "Iteration 311: m = 0.9953445342953438, c = 0.96629184345099, loss = 0.021511288118916526\n",
      "Iteration 312: m = 0.9951912261433088, c = 0.9668453345242495, loss = 0.021478134501368325\n",
      "Iteration 313: m = 0.9950384363203258, c = 0.9673969542651659, loss = 0.02144520468709333\n",
      "Iteration 314: m = 0.9948861630739442, c = 0.9679467090006431, loss = 0.021412497165308943\n",
      "Iteration 315: m = 0.9947344046576378, c = 0.9684946050361936, loss = 0.021380010435431314\n",
      "Iteration 316: m = 0.9945831593307859, c = 0.9690406486560114, loss = 0.021347743007006047\n",
      "Iteration 317: m = 0.9944324253586523, c = 0.969584846123044, loss = 0.021315693399640307\n",
      "Iteration 318: m = 0.9942822010123662, c = 0.9701272036790639, loss = 0.021283860142934336\n",
      "Iteration 319: m = 0.9941324845689018, c = 0.9706677275447406, loss = 0.02125224177641453\n",
      "Iteration 320: m = 0.9939832743110589, c = 0.9712064239197117, loss = 0.021220836849466174\n",
      "Iteration 321: m = 0.9938345685274432, c = 0.9717432989826539, loss = 0.02118964392126678\n",
      "Iteration 322: m = 0.9936863655124465, c = 0.9722783588913542, loss = 0.021158661560720292\n",
      "Iteration 323: m = 0.993538663566227, c = 0.9728116097827803, loss = 0.021127888346391097\n",
      "Iteration 324: m = 0.9933914609946902, c = 0.973343057773151, loss = 0.021097322866439054\n",
      "Iteration 325: m = 0.9932447561094694, c = 0.9738727089580066, loss = 0.021066963718554727\n",
      "Iteration 326: m = 0.9930985472279057, c = 0.9744005694122783, loss = 0.021036809509894845\n",
      "Iteration 327: m = 0.9929528326730297, c = 0.9749266451903583, loss = 0.02100685885701848\n",
      "Iteration 328: m = 0.9928076107735416, c = 0.9754509423261694, loss = 0.020977110385823783\n",
      "Iteration 329: m = 0.9926628798637923, c = 0.9759734668332335, loss = 0.02094756273148455\n",
      "Iteration 330: m = 0.992518638283764, c = 0.9764942247047413, loss = 0.020918214538388068\n",
      "Iteration 331: m = 0.9923748843790514, c = 0.9770132219136207, loss = 0.020889064460072514\n",
      "Iteration 332: m = 0.9922316165008429, c = 0.9775304644126053, loss = 0.0208601111591653\n",
      "Iteration 333: m = 0.9920888330059011, c = 0.9780459581343026, loss = 0.020831353307321936\n",
      "Iteration 334: m = 0.9919465322565447, c = 0.9785597089912625, loss = 0.020802789585164835\n",
      "Iteration 335: m = 0.9918047126206291, c = 0.9790717228760446, loss = 0.02077441868222273\n",
      "Iteration 336: m = 0.991663372471528, c = 0.979582005661286, loss = 0.020746239296871034\n",
      "Iteration 337: m = 0.9915225101881147, c = 0.9800905631997685, loss = 0.020718250136271342\n",
      "Iteration 338: m = 0.9913821241547434, c = 0.9805974013244863, loss = 0.020690449916312713\n",
      "Iteration 339: m = 0.9912422127612307, c = 0.9811025258487119, loss = 0.020662837361552736\n",
      "Iteration 340: m = 0.9911027744028372, c = 0.9816059425660638, loss = 0.020635411205158688\n",
      "Iteration 341: m = 0.9909638074802493, c = 0.9821076572505724, loss = 0.020608170188849702\n",
      "Iteration 342: m = 0.9908253103995601, c = 0.982607675656746, loss = 0.020581113062838864\n",
      "Iteration 343: m = 0.9906872815722522, c = 0.9831060035196375, loss = 0.020554238585775902\n",
      "Iteration 344: m = 0.9905497194151784, c = 0.9836026465549096, loss = 0.020527545524690227\n",
      "Iteration 345: m = 0.9904126223505446, c = 0.9840976104589007, loss = 0.020501032654934727\n",
      "Iteration 346: m = 0.9902759888058907, c = 0.98459090090869, loss = 0.02047469876012888\n",
      "Iteration 347: m = 0.9901398172140734, c = 0.9850825235621627, loss = 0.020448542632103526\n",
      "Iteration 348: m = 0.9900041060132475, c = 0.9855724840580751, loss = 0.020422563070845143\n",
      "Iteration 349: m = 0.9898688536468485, c = 0.9860607880161187, loss = 0.020396758884441066\n",
      "Iteration 350: m = 0.9897340585635747, c = 0.9865474410369854, loss = 0.020371128889024485\n",
      "Iteration 351: m = 0.9895997192173691, c = 0.9870324487024312, loss = 0.02034567190872016\n",
      "Iteration 352: m = 0.9894658340674021, c = 0.9875158165753405, loss = 0.020320386775590955\n",
      "Iteration 353: m = 0.9893324015780531, c = 0.9879975501997895, loss = 0.02029527232958354\n",
      "Iteration 354: m = 0.9891994202188941, c = 0.9884776551011105, loss = 0.020270327418475724\n",
      "Iteration 355: m = 0.9890668884646707, c = 0.9889561367859546, loss = 0.020245550897823178\n",
      "Iteration 356: m = 0.9889348047952858, c = 0.9894330007423553, loss = 0.02022094163090736\n",
      "Iteration 357: m = 0.9888031676957817, c = 0.9899082524397911, loss = 0.02019649848868297\n",
      "Iteration 358: m = 0.9886719756563223, c = 0.9903818973292483, loss = 0.020172220349726433\n",
      "Iteration 359: m = 0.9885412271721765, c = 0.990853940843284, loss = 0.0201481061001843\n",
      "Iteration 360: m = 0.9884109207437006, c = 0.9913243883960877, loss = 0.020124154633722205\n",
      "Iteration 361: m = 0.9882810548763212, c = 0.991793245383544, loss = 0.020100364851474005\n",
      "Iteration 362: m = 0.9881516280805179, c = 0.9922605171832938, loss = 0.020076735661991498\n",
      "Iteration 363: m = 0.9880226388718064, c = 0.9927262091547968, loss = 0.02005326598119435\n",
      "Iteration 364: m = 0.9878940857707212, c = 0.9931903266393924, loss = 0.020029954732320172\n",
      "Iteration 365: m = 0.9877659673027991, c = 0.9936528749603614, loss = 0.020006800845875392\n",
      "Iteration 366: m = 0.9876382819985616, c = 0.9941138594229862, loss = 0.019983803259585955\n",
      "Iteration 367: m = 0.9875110283934989, c = 0.9945732853146129, loss = 0.019960960918348765\n",
      "Iteration 368: m = 0.9873842050280524, c = 0.9950311579047106, loss = 0.019938272774182954\n",
      "Iteration 369: m = 0.9872578104475982, c = 0.9954874824449332, loss = 0.019915737786182455\n",
      "Iteration 370: m = 0.9871318432024306, c = 0.9959422641691786, loss = 0.019893354920467544\n",
      "Iteration 371: m = 0.9870063018477452, c = 0.9963955082936492, loss = 0.019871123150137646\n",
      "Iteration 372: m = 0.9868811849436223, c = 0.9968472200169115, loss = 0.01984904145522439\n",
      "Iteration 373: m = 0.9867564910550107, c = 0.997297404519956, loss = 0.019827108822644775\n",
      "Iteration 374: m = 0.986632218751711, c = 0.9977460669662562, loss = 0.019805324246154506\n",
      "Iteration 375: m = 0.9865083666083593, c = 0.9981932125018285, loss = 0.019783686726301847\n",
      "Iteration 376: m = 0.9863849332044106, c = 0.9986388462552903, loss = 0.01976219527038205\n",
      "Iteration 377: m = 0.9862619171241228, c = 0.9990829733379198, loss = 0.019740848892391506\n",
      "Iteration 378: m = 0.9861393169565406, c = 0.9995255988437141, loss = 0.019719646612982485\n",
      "Iteration 379: m = 0.9860171312954789, c = 0.9999667278494474, loss = 0.019698587459418743\n",
      "Iteration 380: m = 0.9858953587395067, c = 1.0004063654147297, loss = 0.019677670465529935\n",
      "Iteration 381: m = 0.9857739978919315, c = 1.0008445165820647, loss = 0.019656894671668357\n",
      "Iteration 382: m = 0.9856530473607827, c = 1.0012811863769076, loss = 0.019636259124664046\n",
      "Iteration 383: m = 0.9855325057587961, c = 1.0017163798077224, loss = 0.01961576287778157\n",
      "Iteration 384: m = 0.9854123717033977, c = 1.0021501018660401, loss = 0.019595404990676378\n",
      "Iteration 385: m = 0.9852926438166878, c = 1.0025823575265156, loss = 0.019575184529351607\n",
      "Iteration 386: m = 0.9851733207254255, c = 1.003013151746984, loss = 0.019555100566115657\n",
      "Iteration 387: m = 0.9850544010610128, c = 1.0034424894685188, loss = 0.019535152179539002\n",
      "Iteration 388: m = 0.9849358834594789, c = 1.0038703756154876, loss = 0.019515338454412303\n",
      "Iteration 389: m = 0.9848177665614642, c = 1.004296815095609, loss = 0.01949565848170438\n",
      "Iteration 390: m = 0.9847000490122055, c = 1.004721812800009, loss = 0.019476111358520377\n",
      "Iteration 391: m = 0.9845827294615198, c = 1.0051453736032765, loss = 0.019456696188060434\n",
      "Iteration 392: m = 0.9844658065637889, c = 1.0055675023635198, loss = 0.0194374120795787\n",
      "Iteration 393: m = 0.9843492789779441, c = 1.005988203922422, loss = 0.019418258148342072\n",
      "Iteration 394: m = 0.9842331453674511, c = 1.006407483105297, loss = 0.019399233515589934\n",
      "Iteration 395: m = 0.984117404400294, c = 1.006825344721144, loss = 0.01938033730849379\n",
      "Iteration 396: m = 0.9840020547489607, c = 1.0072417935627034, loss = 0.01936156866011702\n",
      "Iteration 397: m = 0.9838870950904272, c = 1.0076568344065118, loss = 0.01934292670937538\n",
      "Iteration 398: m = 0.9837725241061425, c = 1.0080704720129559, loss = 0.0193244106009974\n",
      "Iteration 399: m = 0.9836583404820138, c = 1.0084827111263281, loss = 0.019306019485484986\n",
      "Iteration 400: m = 0.9835445429083911, c = 1.0088935564748807, loss = 0.019287752519074698\n",
      "Iteration 401: m = 0.9834311300800522, c = 1.0093030127708795, loss = 0.01926960886369871\n",
      "Iteration 402: m = 0.983318100696188, c = 1.0097110847106587, loss = 0.0192515876869468\n",
      "Iteration 403: m = 0.9832054534603871, c = 1.0101177769746743, loss = 0.01923368816202793\n",
      "Iteration 404: m = 0.9830931870806215, c = 1.0105230942275576, loss = 0.01921590946773207\n",
      "Iteration 405: m = 0.9829813002692314, c = 1.0109270411181692, loss = 0.0191982507883929\n",
      "Iteration 406: m = 0.9828697917429103, c = 1.011329622279652, loss = 0.0191807113138504\n",
      "Iteration 407: m = 0.982758660222691, c = 1.0117308423294844, loss = 0.019163290239413287\n",
      "Iteration 408: m = 0.9826479044339299, c = 1.0121307058695332, loss = 0.019145986765822486\n",
      "Iteration 409: m = 0.9825375231062934, c = 1.0125292174861067, loss = 0.019128800099214197\n",
      "Iteration 410: m = 0.9824275149737425, c = 1.012926381750007, loss = 0.019111729451083786\n",
      "Iteration 411: m = 0.9823178787745187, c = 1.0133222032165823, loss = 0.01909477403824917\n",
      "Iteration 412: m = 0.9822086132511296, c = 1.0137166864257796, loss = 0.019077933082815378\n",
      "Iteration 413: m = 0.9820997171503343, c = 1.0141098359021963, loss = 0.019061205812138403\n",
      "Iteration 414: m = 0.981991189223129, c = 1.0145016561551323, loss = 0.019044591458790075\n",
      "Iteration 415: m = 0.9818830282247327, c = 1.014892151678642, loss = 0.01902808926052269\n",
      "Iteration 416: m = 0.981775232914573, c = 1.0152813269515852, loss = 0.019011698460234244\n",
      "Iteration 417: m = 0.9816678020562718, c = 1.0156691864376792, loss = 0.018995418305933303\n",
      "Iteration 418: m = 0.9815607344176313, c = 1.0160557345855494, loss = 0.018979248050705003\n",
      "Iteration 419: m = 0.9814540287706194, c = 1.0164409758287807, loss = 0.018963186952676174\n",
      "Iteration 420: m = 0.9813476838913563, c = 1.0168249145859678, loss = 0.01894723427498215\n",
      "Iteration 421: m = 0.9812416985600999, c = 1.0172075552607671, loss = 0.018931389285731928\n",
      "Iteration 422: m = 0.981136071561232, c = 1.0175889022419458, loss = 0.018915651257975542\n",
      "Iteration 423: m = 0.9810308016832442, c = 1.017968959903433, loss = 0.018900019469670078\n",
      "Iteration 424: m = 0.9809258877187245, c = 1.0183477326043697, loss = 0.018884493203646917\n",
      "Iteration 425: m = 0.9808213284643429, c = 1.018725224689159, loss = 0.018869071747578438\n",
      "Iteration 426: m = 0.9807171227208379, c = 1.0191014404875152, loss = 0.018853754393945977\n",
      "Iteration 427: m = 0.9806132692930026, c = 1.0194763843145145, loss = 0.01883854044000651\n",
      "Iteration 428: m = 0.9805097669896712, c = 1.019850060470644, loss = 0.018823429187761233\n",
      "Iteration 429: m = 0.9804066146237048, c = 1.0202224732418508, loss = 0.018808419943923065\n",
      "Iteration 430: m = 0.9803038110119787, c = 1.0205936268995914, loss = 0.018793512019884787\n",
      "Iteration 431: m = 0.9802013549753679, c = 1.020963525700881, loss = 0.018778704731687898\n",
      "Iteration 432: m = 0.980099245338734, c = 1.0213321738883412, loss = 0.018763997399990864\n",
      "Iteration 433: m = 0.9799974809309121, c = 1.0216995756902503, loss = 0.018749389350037848\n",
      "Iteration 434: m = 0.9798960605846965, c = 1.0220657353205906, loss = 0.018734879911628182\n",
      "Iteration 435: m = 0.9797949831368278, c = 1.022430656979097, loss = 0.018720468419085364\n",
      "Iteration 436: m = 0.9796942474279798, c = 1.0227943448513055, loss = 0.01870615421122644\n",
      "Iteration 437: m = 0.979593852302746, c = 1.0231568031086007, loss = 0.018691936631331715\n",
      "Iteration 438: m = 0.9794937966096259, c = 1.0235180359082638, loss = 0.018677815027114845\n",
      "Iteration 439: m = 0.9793940792010124, c = 1.023878047393521, loss = 0.018663788750692696\n",
      "Iteration 440: m = 0.9792946989331784, c = 1.0242368416935899, loss = 0.018649857158555515\n",
      "Iteration 441: m = 0.9791956546662638, c = 1.0245944229237274, loss = 0.01863601961153775\n",
      "Iteration 442: m = 0.9790969452642622, c = 1.024950795185277, loss = 0.01862227547478843\n",
      "Iteration 443: m = 0.9789985695950079, c = 1.0253059625657157, loss = 0.01860862411774229\n",
      "Iteration 444: m = 0.9789005265301632, c = 1.025659929138701, loss = 0.018595064914090256\n",
      "Iteration 445: m = 0.9788028149452053, c = 1.0260126989641172, loss = 0.01858159724175177\n",
      "Iteration 446: m = 0.9787054337194131, c = 1.0263642760881224, loss = 0.018568220482845184\n",
      "Iteration 447: m = 0.9786083817358548, c = 1.0267146645431953, loss = 0.018554934023659944\n",
      "Iteration 448: m = 0.9785116578813751, c = 1.02706386834818, loss = 0.01854173725462851\n",
      "Iteration 449: m = 0.9784152610465817, c = 1.027411891508334, loss = 0.01852862957029796\n",
      "Iteration 450: m = 0.9783191901258337, c = 1.0277587380153723, loss = 0.018515610369302687\n",
      "Iteration 451: m = 0.9782234440172279, c = 1.0281044118475149, loss = 0.018502679054336498\n",
      "Iteration 452: m = 0.9781280216225869, c = 1.028448916969531, loss = 0.01848983503212543\n",
      "Iteration 453: m = 0.978032921847446, c = 1.0287922573327852, loss = 0.01847707771340027\n",
      "Iteration 454: m = 0.9779381436010407, c = 1.0291344368752828, loss = 0.018464406512869624\n",
      "Iteration 455: m = 0.9778436857962948, c = 1.0294754595217148, loss = 0.018451820849193366\n",
      "Iteration 456: m = 0.977749547349807, c = 1.0298153291835028, loss = 0.018439320144955407\n",
      "Iteration 457: m = 0.9776557271818394, c = 1.0301540497588444, loss = 0.018426903826637628\n",
      "Iteration 458: m = 0.977562224216304, c = 1.0304916251327572, loss = 0.01841457132459353\n",
      "Iteration 459: m = 0.9774690373807517, c = 1.0308280591771237, loss = 0.01840232207302188\n",
      "Iteration 460: m = 0.977376165606359, c = 1.031163355750736, loss = 0.01839015550994094\n",
      "Iteration 461: m = 0.9772836078279159, c = 1.0314975186993398, loss = 0.018378071077162498\n",
      "Iteration 462: m = 0.977191362983814, c = 1.031830551855678, loss = 0.01836606822026657\n",
      "Iteration 463: m = 0.9770994300160343, c = 1.0321624590395357, loss = 0.018354146388575805\n",
      "Iteration 464: m = 0.9770078078701346, c = 1.032493244057783, loss = 0.018342305035129958\n",
      "Iteration 465: m = 0.9769164954952381, c = 1.0328229107044193, loss = 0.018330543616661234\n",
      "Iteration 466: m = 0.9768254918440206, c = 1.0331514627606166, loss = 0.018318861593569054\n",
      "Iteration 467: m = 0.9767347958726991, c = 1.0334789039947632, loss = 0.01830725842989562\n",
      "Iteration 468: m = 0.9766444065410195, c = 1.033805238162506, loss = 0.018295733593300743\n",
      "Iteration 469: m = 0.9765543228122449, c = 1.0341304690067947, loss = 0.018284286555038158\n",
      "Iteration 470: m = 0.9764645436531433, c = 1.0344546002579242, loss = 0.01827291678993064\n",
      "Iteration 471: m = 0.9763750680339763, c = 1.0347776356335772, loss = 0.01826162377634632\n",
      "Iteration 472: m = 0.9762858949284869, c = 1.035099578838867, loss = 0.018250406996174605\n",
      "Iteration 473: m = 0.9761970233138878, c = 1.0354204335663806, loss = 0.01823926593480222\n",
      "Iteration 474: m = 0.9761084521708496, c = 1.0357402034962198, loss = 0.018228200081090058\n",
      "Iteration 475: m = 0.9760201804834895, c = 1.0360588922960443, loss = 0.01821720892734922\n",
      "Iteration 476: m = 0.9759322072393591, c = 1.036376503621114, loss = 0.01820629196931816\n",
      "Iteration 477: m = 0.9758445314294333, c = 1.0366930411143302, loss = 0.01819544870613914\n",
      "Iteration 478: m = 0.9757571520480981, c = 1.0370085084062777, loss = 0.018184678640335523\n",
      "Iteration 479: m = 0.9756700680931398, c = 1.0373229091152663, loss = 0.01817398127778905\n",
      "Iteration 480: m = 0.9755832785657331, c = 1.0376362468473725, loss = 0.018163356127716693\n",
      "Iteration 481: m = 0.9754967824704295, c = 1.037948525196481, loss = 0.018152802702648706\n",
      "Iteration 482: m = 0.9754105788151461, c = 1.0382597477443256, loss = 0.018142320518406058\n",
      "Iteration 483: m = 0.9753246666111545, c = 1.0385699180605303, loss = 0.018131909094077858\n",
      "Iteration 484: m = 0.9752390448730687, c = 1.0388790397026504, loss = 0.01812156795199988\n",
      "Iteration 485: m = 0.9751537126188345, c = 1.0391871162162132, loss = 0.018111296617732166\n",
      "Iteration 486: m = 0.9750686688697181, c = 1.0394941511347588, loss = 0.018101094620037724\n",
      "Iteration 487: m = 0.9749839126502946, c = 1.0398001479798806, loss = 0.01809096149086034\n",
      "Iteration 488: m = 0.974899442988437, c = 1.0401051102612653, loss = 0.01808089676530359\n",
      "Iteration 489: m = 0.974815258915305, c = 1.0404090414767337, loss = 0.018070899981609205\n",
      "Iteration 490: m = 0.9747313594653338, c = 1.0407119451122808, loss = 0.018060970681136285\n",
      "Iteration 491: m = 0.9746477436762235, c = 1.0410138246421152, loss = 0.01805110840833968\n",
      "Iteration 492: m = 0.9745644105889275, c = 1.0413146835286995, loss = 0.01804131271074954\n",
      "Iteration 493: m = 0.9744813592476415, c = 1.0416145252227897, loss = 0.018031583138950293\n",
      "Iteration 494: m = 0.9743985886997929, c = 1.0419133531634754, loss = 0.01802191924656037\n",
      "Iteration 495: m = 0.9743160979960299, c = 1.0422111707782185, loss = 0.018012320590211267\n",
      "Iteration 496: m = 0.9742338861902102, c = 1.0425079814828924, loss = 0.018002786729527546\n",
      "Iteration 497: m = 0.9741519523393904, c = 1.042803788681822, loss = 0.0179933172271065\n",
      "Iteration 498: m = 0.9740702955038152, c = 1.043098595767822, loss = 0.01798391164849813\n",
      "Iteration 499: m = 0.9739889147469065, c = 1.0433924061222366, loss = 0.017974569562185162\n",
      "Iteration 500: m = 0.9739078091352529, c = 1.0436852231149776, loss = 0.017965290539563285\n",
      "Iteration 501: m = 0.9738269777385986, c = 1.0439770501045629, loss = 0.017956074154921398\n",
      "Iteration 502: m = 0.9737464196298331, c = 1.0442678904381557, loss = 0.01794691998542231\n",
      "Iteration 503: m = 0.9736661338849805, c = 1.0445577474516026, loss = 0.01793782761108318\n",
      "Iteration 504: m = 0.9735861195831886, c = 1.0448466244694716, loss = 0.017928796614756066\n",
      "Iteration 505: m = 0.9735063758067188, c = 1.045134524805091, loss = 0.017919826582109173\n",
      "Iteration 506: m = 0.9734269016409353, c = 1.045421451760586, loss = 0.017910917101607554\n",
      "Iteration 507: m = 0.9733476961742944, c = 1.0457074086269182, loss = 0.017902067764494423\n",
      "Iteration 508: m = 0.9732687584983345, c = 1.0459923986839221, loss = 0.017893278164772184\n",
      "Iteration 509: m = 0.9731900877076656, c = 1.0462764252003436, loss = 0.01788454789918397\n",
      "Iteration 510: m = 0.9731116828999585, c = 1.0465594914338767, loss = 0.017875876567195203\n",
      "Iteration 511: m = 0.973033543175935, c = 1.0468416006312016, loss = 0.01786726377097481\n",
      "Iteration 512: m = 0.9729556676393573, c = 1.0471227560280214, loss = 0.017858709115377715\n",
      "Iteration 513: m = 0.9728780553970174, c = 1.0474029608490996, loss = 0.017850212207925865\n",
      "Iteration 514: m = 0.9728007055587277, c = 1.0476822183082966, loss = 0.017841772658790882\n",
      "Iteration 515: m = 0.9727236172373098, c = 1.047960531608607, loss = 0.017833390080775783\n",
      "Iteration 516: m = 0.9726467895485853, c = 1.0482379039421963, loss = 0.017825064089297505\n",
      "Iteration 517: m = 0.9725702216113647, c = 1.0485143384904372, loss = 0.01781679430236876\n",
      "Iteration 518: m = 0.9724939125474382, c = 1.0487898384239465, loss = 0.01780858034058144\n",
      "Iteration 519: m = 0.9724178614815651, c = 1.0490644069026211, loss = 0.01780042182708804\n",
      "Iteration 520: m = 0.9723420675414635, c = 1.0493380470756748, loss = 0.017792318387585427\n",
      "Iteration 521: m = 0.972266529857801, c = 1.0496107620816735, loss = 0.017784269650296815\n",
      "Iteration 522: m = 0.9721912475641844, c = 1.049882555048572, loss = 0.01777627524595545\n",
      "Iteration 523: m = 0.9721162197971496, c = 1.0501534290937495, loss = 0.017768334807786938\n",
      "Iteration 524: m = 0.9720414456961517, c = 1.0504233873240456, loss = 0.017760447971493155\n",
      "Iteration 525: m = 0.9719669244035556, c = 1.0506924328357956, loss = 0.01775261437523492\n",
      "Iteration 526: m = 0.9718926550646256, c = 1.0509605687148664, loss = 0.017744833659615704\n",
      "Iteration 527: m = 0.971818636827516, c = 1.0512277980366915, loss = 0.01773710546766514\n",
      "Iteration 528: m = 0.971744868843261, c = 1.0514941238663067, loss = 0.017729429444822677\n",
      "Iteration 529: m = 0.9716713502657651, c = 1.0517595492583849, loss = 0.017721805238920998\n",
      "Iteration 530: m = 0.9715980802517937, c = 1.0520240772572713, loss = 0.01771423250017004\n",
      "Iteration 531: m = 0.9715250579609629, c = 1.0522877108970183, loss = 0.01770671088114144\n",
      "Iteration 532: m = 0.9714522825557299, c = 1.0525504532014203, loss = 0.017699240036751655\n",
      "Iteration 533: m = 0.9713797532013841, c = 1.052812307184048, loss = 0.017691819624246884\n",
      "Iteration 534: m = 0.9713074690660367, c = 1.0530732758482841, loss = 0.017684449303187067\n",
      "Iteration 535: m = 0.9712354293206116, c = 1.0533333621873562, loss = 0.01767712873543005\n",
      "Iteration 536: m = 0.9711636331388357, c = 1.0535925691843724, loss = 0.017669857585116723\n",
      "Iteration 537: m = 0.9710920796972295, c = 1.0538508998123548, loss = 0.017662635518654927\n",
      "Iteration 538: m = 0.9710207681750977, c = 1.054108357034274, loss = 0.017655462204704396\n",
      "Iteration 539: m = 0.9709496977545198, c = 1.0543649438030827, loss = 0.017648337314161655\n",
      "Iteration 540: m = 0.9708788676203405, c = 1.0546206630617498, loss = 0.017641260520144735\n",
      "Iteration 541: m = 0.9708082769601606, c = 1.0548755177432945, loss = 0.017634231497978402\n",
      "Iteration 542: m = 0.9707379249643276, c = 1.055129510770819, loss = 0.017627249925179115\n",
      "Iteration 543: m = 0.9706678108259265, c = 1.055382645057543, loss = 0.017620315481440323\n",
      "Iteration 544: m = 0.9705979337407701, c = 1.0556349235068365, loss = 0.01761342784861748\n",
      "Iteration 545: m = 0.9705282929073905, c = 1.0558863490122536, loss = 0.01760658671071389\n",
      "Iteration 546: m = 0.9704588875270294, c = 1.0561369244575651, loss = 0.017599791753865928\n",
      "Iteration 547: m = 0.970389716803629, c = 1.056386652716792, loss = 0.017593042666328638\n",
      "Iteration 548: m = 0.970320779943823, c = 1.0566355366542384, loss = 0.017586339138461495\n",
      "Iteration 549: m = 0.9702520761569277, c = 1.0568835791245241, loss = 0.017579680862714366\n",
      "Iteration 550: m = 0.9701836046549321, c = 1.057130782972618, loss = 0.017573067533613033\n",
      "Iteration 551: m = 0.97011536465249, c = 1.0573771510338696, loss = 0.017566498847745506\n",
      "Iteration 552: m = 0.97004735536691, c = 1.0576226861340428, loss = 0.017559974503748004\n",
      "Iteration 553: m = 0.9699795760181472, c = 1.0578673910893472, loss = 0.01755349420229093\n",
      "Iteration 554: m = 0.969912025828794, c = 1.0581112687064715, loss = 0.01754705764606537\n",
      "Iteration 555: m = 0.9698447040240711, c = 1.0583543217826146, loss = 0.01754066453976949\n",
      "Iteration 556: m = 0.9697776098318186, c = 1.058596553105518, loss = 0.01753431459009488\n",
      "Iteration 557: m = 0.9697107424824875, c = 1.0588379654534985, loss = 0.017528007505713008\n",
      "Iteration 558: m = 0.9696441012091302, c = 1.0590785615954792, loss = 0.017521742997261995\n",
      "Iteration 559: m = 0.9695776852473929, c = 1.059318344291022, loss = 0.017515520777333347\n",
      "Iteration 560: m = 0.9695114938355052, c = 1.059557316290358, loss = 0.017509340560458622\n",
      "Iteration 561: m = 0.9694455262142726, c = 1.0597954803344205, loss = 0.017503202063096537\n",
      "Iteration 562: m = 0.9693797816270674, c = 1.0600328391548757, loss = 0.017497105003619666\n",
      "Iteration 563: m = 0.9693142593198201, c = 1.0602693954741542, loss = 0.01749104910230206\n",
      "Iteration 564: m = 0.9692489585410105, c = 1.060505152005482, loss = 0.017485034081305757\n",
      "Iteration 565: m = 0.9691838785416592, c = 1.0607401114529118, loss = 0.017479059664668326\n",
      "Iteration 566: m = 0.9691190185753195, c = 1.0609742765113541, loss = 0.017473125578290366\n",
      "Iteration 567: m = 0.9690543778980679, c = 1.0612076498666079, loss = 0.017467231549922878\n",
      "Iteration 568: m = 0.9689899557684966, c = 1.0614402341953917, loss = 0.017461377309154234\n",
      "Iteration 569: m = 0.9689257514477038, c = 1.061672032165374, loss = 0.017455562587398814\n",
      "Iteration 570: m = 0.9688617641992865, c = 1.0619030464352044, loss = 0.017449787117883572\n",
      "Iteration 571: m = 0.9687979932893312, c = 1.062133279654543, loss = 0.017444050635636688\n",
      "Iteration 572: m = 0.9687344379864058, c = 1.0623627344640922, loss = 0.017438352877474736\n",
      "Iteration 573: m = 0.968671097561551, c = 1.062591413495626, loss = 0.017432693581991097\n",
      "Iteration 574: m = 0.9686079712882723, c = 1.0628193193720203, loss = 0.017427072489543713\n",
      "Iteration 575: m = 0.9685450584425311, c = 1.0630464547072835, loss = 0.017421489342243246\n",
      "Iteration 576: m = 0.9684823583027373, c = 1.063272822106586, loss = 0.017415943883941243\n",
      "Iteration 577: m = 0.96841987014974, c = 1.06349842416629, loss = 0.01741043586021834\n",
      "Iteration 578: m = 0.9683575932668198, c = 1.0637232634739797, loss = 0.017404965018372666\n",
      "Iteration 579: m = 0.9682955269396807, c = 1.0639473426084909, loss = 0.01739953110740824\n",
      "Iteration 580: m = 0.9682336704564415, c = 1.0641706641399402, loss = 0.017394133878023396\n",
      "Iteration 581: m = 0.968172023107628, c = 1.064393230629755, loss = 0.01738877308259939\n",
      "Iteration 582: m = 0.9681105841861645, c = 1.0646150446307021, loss = 0.01738344847518889\n",
      "Iteration 583: m = 0.9680493529873662, c = 1.0648361086869182, loss = 0.017378159811505107\n",
      "Iteration 584: m = 0.9679883288089305, c = 1.0650564253339379, loss = 0.017372906848910113\n",
      "Iteration 585: m = 0.9679275109509295, c = 1.0652759970987233, loss = 0.017367689346403876\n",
      "Iteration 586: m = 0.9678668987158017, c = 1.065494826499693, loss = 0.01736250706461339\n",
      "Iteration 587: m = 0.9678064914083437, c = 1.0657129160467511, loss = 0.017357359765781365\n",
      "Iteration 588: m = 0.9677462883357031, c = 1.0659302682413154, loss = 0.01735224721375573\n",
      "Iteration 589: m = 0.9676862888073695, c = 1.066146885576347, loss = 0.01734716917397823\n",
      "Iteration 590: m = 0.9676264921351674, c = 1.0663627705363778, loss = 0.01734212541347427\n",
      "Iteration 591: m = 0.9675668976332479, c = 1.0665779255975403, loss = 0.017337115700841763\n",
      "Iteration 592: m = 0.967507504618081, c = 1.0667923532275947, loss = 0.017332139806240883\n",
      "Iteration 593: m = 0.9674483124084475, c = 1.067006055885958, loss = 0.01732719750138306\n",
      "Iteration 594: m = 0.9673893203254316, c = 1.067219036023732, loss = 0.017322288559521188\n",
      "Iteration 595: m = 0.9673305276924127, c = 1.0674312960837313, loss = 0.017317412755438414\n",
      "Iteration 596: m = 0.967271933835058, c = 1.067642838500512, loss = 0.017312569865438505\n",
      "Iteration 597: m = 0.9672135380813146, c = 1.067853665700398, loss = 0.01730775966733501\n",
      "Iteration 598: m = 0.9671553397614016, c = 1.0680637801015112, loss = 0.017302981940441647\n",
      "Iteration 599: m = 0.9670973382078025, c = 1.068273184113797, loss = 0.017298236465561688\n",
      "Iteration 600: m = 0.9670395327552582, c = 1.0684818801390528, loss = 0.01729352302497799\n",
      "Iteration 601: m = 0.9669819227407582, c = 1.0686898705709562, loss = 0.017288841402443533\n",
      "Iteration 602: m = 0.966924507503534, c = 1.0688971577950916, loss = 0.01728419138317058\n",
      "Iteration 603: m = 0.966867286385051, c = 1.0691037441889777, loss = 0.017279572753821578\n",
      "Iteration 604: m = 0.9668102587290012, c = 1.0693096321220952, loss = 0.01727498530249906\n",
      "Iteration 605: m = 0.9667534238812951, c = 1.0695148239559131, loss = 0.017270428818735965\n",
      "Iteration 606: m = 0.9666967811900554, c = 1.0697193220439172, loss = 0.017265903093485992\n",
      "Iteration 607: m = 0.9666403300056082, c = 1.0699231287316355, loss = 0.017261407919114007\n",
      "Iteration 608: m = 0.9665840696804763, c = 1.0701262463566663, loss = 0.017256943089386516\n",
      "Iteration 609: m = 0.9665279995693715, c = 1.0703286772487044, loss = 0.017252508399462164\n",
      "Iteration 610: m = 0.9664721190291875, c = 1.070530423729568, loss = 0.01724810364588244\n",
      "Iteration 611: m = 0.9664164274189921, c = 1.0707314881132255, loss = 0.01724372862656229\n",
      "Iteration 612: m = 0.9663609241000204, c = 1.0709318727058215, loss = 0.017239383140780735\n",
      "Iteration 613: m = 0.9663056084356666, c = 1.0711315798057037, loss = 0.017235066989171835\n",
      "Iteration 614: m = 0.9662504797914777, c = 1.0713306117034496, loss = 0.017230779973715464\n",
      "Iteration 615: m = 0.9661955375351456, c = 1.071528970681892, loss = 0.017226521897728164\n",
      "Iteration 616: m = 0.9661407810365, c = 1.0717266590161454, loss = 0.017222292565854384\n",
      "Iteration 617: m = 0.9660862096675013, c = 1.0719236789736324, loss = 0.01721809178405703\n",
      "Iteration 618: m = 0.9660318228022331, c = 1.0721200328141096, loss = 0.017213919359609094\n",
      "Iteration 619: m = 0.9659776198168952, c = 1.0723157227896933, loss = 0.017209775101084426\n",
      "Iteration 620: m = 0.9659236000897967, c = 1.0725107511448857, loss = 0.01720565881834916\n",
      "Iteration 621: m = 0.9658697630013483, c = 1.0727051201166002, loss = 0.017201570322552946\n",
      "Iteration 622: m = 0.9658161079340557, c = 1.0728988319341874, loss = 0.017197509426120243\n",
      "Iteration 623: m = 0.9657626342725122, c = 1.0730918888194603, loss = 0.017193475942741617\n",
      "Iteration 624: m = 0.9657093414033919, c = 1.0732842929867203, loss = 0.01718946968736553\n",
      "Iteration 625: m = 0.9656562287154424, c = 1.0734760466427824, loss = 0.017185490476189627\n",
      "Iteration 626: m = 0.9656032955994782, c = 1.0736671519870002, loss = 0.01718153812665202\n",
      "Iteration 627: m = 0.965550541448373, c = 1.0738576112112916, loss = 0.01717761245742352\n",
      "Iteration 628: m = 0.9654979656570535, c = 1.0740474265001634, loss = 0.017173713288398902\n",
      "Iteration 629: m = 0.9654455676224919, c = 1.0742366000307368, loss = 0.01716984044068858\n",
      "Iteration 630: m = 0.9653933467436995, c = 1.0744251339727726, loss = 0.01716599373661084\n",
      "Iteration 631: m = 0.9653413024217192, c = 1.0746130304886952, loss = 0.017162172999683166\n",
      "Iteration 632: m = 0.9652894340596193, c = 1.0748002917336181, loss = 0.01715837805461455\n",
      "Iteration 633: m = 0.9652377410624859, c = 1.0749869198553685, loss = 0.01715460872729716\n",
      "Iteration 634: m = 0.965186222837417, c = 1.0751729169945121, loss = 0.017150864844798667\n",
      "Iteration 635: m = 0.9651348787935146, c = 1.0753582852843768, loss = 0.017147146235353843\n",
      "Iteration 636: m = 0.9650837083418787, c = 1.0755430268510784, loss = 0.017143452728357145\n",
      "Iteration 637: m = 0.9650327108956007, c = 1.075727143813544, loss = 0.017139784154354746\n",
      "Iteration 638: m = 0.964981885869756, c = 1.075910638283537, loss = 0.017136140345036594\n",
      "Iteration 639: m = 0.9649312326813975, c = 1.076093512365681, loss = 0.017132521133228752\n",
      "Iteration 640: m = 0.9648807507495492, c = 1.0762757681574835, loss = 0.017128926352886053\n",
      "Iteration 641: m = 0.9648304394951993, c = 1.076457407749361, loss = 0.017125355839083853\n",
      "Iteration 642: m = 0.9647802983412939, c = 1.0766384332246617, loss = 0.01712180942801133\n",
      "Iteration 643: m = 0.9647303267127295, c = 1.0768188466596909, loss = 0.017118286956962908\n",
      "Iteration 644: m = 0.9646805240363475, c = 1.0769986501237332, loss = 0.017114788264331646\n",
      "Iteration 645: m = 0.964630889740927, c = 1.0771778456790777, loss = 0.017111313189601622\n",
      "Iteration 646: m = 0.9645814232571784, c = 1.0773564353810405, loss = 0.01710786157334027\n",
      "Iteration 647: m = 0.9645321240177368, c = 1.077534421277989, loss = 0.017104433257191385\n",
      "Iteration 648: m = 0.9644829914571553, c = 1.077711805411365, loss = 0.017101028083867698\n",
      "Iteration 649: m = 0.9644340250118992, c = 1.0778885898157085, loss = 0.017097645897143708\n",
      "Iteration 650: m = 0.9643852241203389, c = 1.0780647765186804, loss = 0.0170942865418485\n",
      "Iteration 651: m = 0.9643365882227435, c = 1.0782403675410865, loss = 0.017090949863858805\n",
      "Iteration 652: m = 0.9642881167612747, c = 1.0784153648969002, loss = 0.017087635710091493\n",
      "Iteration 653: m = 0.9642398091799803, c = 1.0785897705932856, loss = 0.017084343928496913\n",
      "Iteration 654: m = 0.9641916649247875, c = 1.078763586630621, loss = 0.017081074368052045\n",
      "Iteration 655: m = 0.964143683443497, c = 1.0789368150025214, loss = 0.01707782687875305\n",
      "Iteration 656: m = 0.9640958641857764, c = 1.079109457695861, loss = 0.017074601311608765\n",
      "Iteration 657: m = 0.9640482066031539, c = 1.0792815166907972, loss = 0.017071397518633923\n",
      "Iteration 658: m = 0.9640007101490122, c = 1.079452993960792, loss = 0.017068215352842066\n",
      "Iteration 659: m = 0.9639533742785821, c = 1.0796238914726355, loss = 0.017065054668239023\n",
      "Iteration 660: m = 0.9639061984489359, c = 1.0797942111864678, loss = 0.017061915319816275\n",
      "Iteration 661: m = 0.9638591821189819, c = 1.0799639550558022, loss = 0.01705879716354402\n",
      "Iteration 662: m = 0.9638123247494578, c = 1.0801331250275472, loss = 0.017055700056364816\n",
      "Iteration 663: m = 0.9637656258029242, c = 1.0803017230420289, loss = 0.017052623856186812\n",
      "Iteration 664: m = 0.9637190847437592, c = 1.0804697510330128, loss = 0.017049568421877572\n",
      "Iteration 665: m = 0.9636727010381514, c = 1.080637210927727, loss = 0.01704653361325719\n",
      "Iteration 666: m = 0.9636264741540945, c = 1.0808041046468833, loss = 0.01704351929109203\n",
      "Iteration 667: m = 0.9635804035613807, c = 1.0809704341047, loss = 0.017040525317088356\n",
      "Iteration 668: m = 0.963534488731595, c = 1.0811362012089232, loss = 0.017037551553886286\n",
      "Iteration 669: m = 0.9634887291381087, c = 1.081301407860849, loss = 0.017034597865052743\n",
      "Iteration 670: m = 0.9634431242560738, c = 1.0814660559553455, loss = 0.01703166411507589\n",
      "Iteration 671: m = 0.9633976735624169, c = 1.0816301473808743, loss = 0.017028750169358585\n",
      "Iteration 672: m = 0.9633523765358327, c = 1.0817936840195117, loss = 0.017025855894212374\n",
      "Iteration 673: m = 0.9633072326567789, c = 1.0819566677469714, loss = 0.017022981156851028\n",
      "Iteration 674: m = 0.9632622414074692, c = 1.0821191004326252, loss = 0.017020125825385098\n",
      "Iteration 675: m = 0.9632174022718685, c = 1.0822809839395244, loss = 0.017017289768815093\n",
      "Iteration 676: m = 0.963172714735686, c = 1.0824423201244218, loss = 0.017014472857025943\n",
      "Iteration 677: m = 0.9631281782863698, c = 1.0826031108377923, loss = 0.01701167496078094\n",
      "Iteration 678: m = 0.9630837924131009, c = 1.0827633579238543, loss = 0.017008895951715834\n",
      "Iteration 679: m = 0.9630395566067875, c = 1.082923063220591, loss = 0.017006135702332833\n",
      "Iteration 680: m = 0.9629954703600588, c = 1.083082228559772, loss = 0.01700339408599469\n",
      "Iteration 681: m = 0.9629515331672596, c = 1.083240855766973, loss = 0.017000670976919367\n",
      "Iteration 682: m = 0.962907744524444, c = 1.083398946661598, loss = 0.01699796625017354\n",
      "Iteration 683: m = 0.9628641039293705, c = 1.0835565030568994, loss = 0.016995279781667625\n",
      "Iteration 684: m = 0.9628206108814951, c = 1.0837135267599993, loss = 0.016992611448149245\n",
      "Iteration 685: m = 0.9627772648819662, c = 1.0838700195719095, loss = 0.016989961127198396\n",
      "Iteration 686: m = 0.9627340654336191, c = 1.0840259832875534, loss = 0.016987328697221422\n",
      "Iteration 687: m = 0.9626910120409696, c = 1.0841814196957853, loss = 0.016984714037445458\n",
      "Iteration 688: m = 0.9626481042102092, c = 1.0843363305794114, loss = 0.016982117027912667\n",
      "Iteration 689: m = 0.9626053414491985, c = 1.0844907177152106, loss = 0.016979537549475333\n",
      "Iteration 690: m = 0.9625627232674622, c = 1.0846445828739544, loss = 0.016976975483790034\n",
      "Iteration 691: m = 0.9625202491761833, c = 1.0847979278204276, loss = 0.016974430713311818\n",
      "Iteration 692: m = 0.9624779186881973, c = 1.084950754313448, loss = 0.01697190312128979\n",
      "Iteration 693: m = 0.962435731317987, c = 1.0851030641058872, loss = 0.016969392591760734\n",
      "Iteration 694: m = 0.9623936865816767, c = 1.0852548589446902, loss = 0.016966899009544456\n",
      "Iteration 695: m = 0.9623517839970264, c = 1.085406140570896, loss = 0.016964422260238178\n",
      "Iteration 696: m = 0.9623100230834268, c = 1.0855569107196563, loss = 0.01696196223021158\n",
      "Iteration 697: m = 0.9622684033618936, c = 1.0857071711202575, loss = 0.016959518806601123\n",
      "Iteration 698: m = 0.9622269243550615, c = 1.0858569234961388, loss = 0.016957091877305507\n",
      "Iteration 699: m = 0.9621855855871797, c = 1.0860061695649124, loss = 0.016954681330979705\n",
      "Iteration 700: m = 0.9621443865841054, c = 1.0861549110383832, loss = 0.016952287057030745\n",
      "Iteration 701: m = 0.9621033268732992, c = 1.0863031496225692, loss = 0.01694990894561212\n",
      "Iteration 702: m = 0.9620624059838192, c = 1.0864508870177199, loss = 0.016947546887618604\n",
      "Iteration 703: m = 0.9620216234463158, c = 1.0865981249183363, loss = 0.01694520077468185\n",
      "Iteration 704: m = 0.9619809787930261, c = 1.0867448650131906, loss = 0.016942870499164715\n",
      "Iteration 705: m = 0.961940471557769, c = 1.0868911089853452, loss = 0.016940555954156868\n",
      "Iteration 706: m = 0.9619001012759391, c = 1.0870368585121721, loss = 0.01693825703346951\n",
      "Iteration 707: m = 0.9618598674845021, c = 1.0871821152653725, loss = 0.01693597363163096\n",
      "Iteration 708: m = 0.9618197697219893, c = 1.0873268809109948, loss = 0.01693370564388108\n",
      "Iteration 709: m = 0.961779807528492, c = 1.0874711571094555, loss = 0.016931452966167496\n",
      "Iteration 710: m = 0.9617399804456565, c = 1.0876149455155568, loss = 0.016929215495139573\n",
      "Iteration 711: m = 0.9617002880166786, c = 1.0877582477785064, loss = 0.01692699312814493\n",
      "Iteration 712: m = 0.9616607297862989, c = 1.0879010655419354, loss = 0.016924785763223742\n",
      "Iteration 713: m = 0.961621305300797, c = 1.0880434004439188, loss = 0.016922593299104765\n",
      "Iteration 714: m = 0.9615820141079866, c = 1.0881852541169925, loss = 0.01692041563520006\n",
      "Iteration 715: m = 0.96154285575721, c = 1.0883266281881734, loss = 0.016918252671600922\n",
      "Iteration 716: m = 0.9615038297993334, c = 1.0884675242789774, loss = 0.01691610430907312\n",
      "Iteration 717: m = 0.9614649357867414, c = 1.088607944005438, loss = 0.01691397044905218\n",
      "Iteration 718: m = 0.961426173273332, c = 1.0887478889781246, loss = 0.01691185099363899\n",
      "Iteration 719: m = 0.9613875418145115, c = 1.088887360802162, loss = 0.016909745845595375\n",
      "Iteration 720: m = 0.9613490409671892, c = 1.0890263610772482, loss = 0.016907654908339547\n",
      "Iteration 721: m = 0.9613106702897727, c = 1.089164891397672, loss = 0.016905578085941585\n",
      "Iteration 722: m = 0.9612724293421624, c = 1.0893029533523322, loss = 0.01690351528311943\n",
      "Iteration 723: m = 0.9612343176857467, c = 1.0894405485247558, loss = 0.01690146640523383\n",
      "Iteration 724: m = 0.9611963348833971, c = 1.089577678493116, loss = 0.01689943135828473\n",
      "Iteration 725: m = 0.9611584804994627, c = 1.0897143448302498, loss = 0.01689741004890632\n",
      "Iteration 726: m = 0.9611207540997659, c = 1.089850549103677, loss = 0.0168954023843634\n",
      "Iteration 727: m = 0.9610831552515968, c = 1.0899862928756174, loss = 0.01689340827254652\n",
      "Iteration 728: m = 0.9610456835237084, c = 1.0901215777030093, loss = 0.016891427621968123\n",
      "Iteration 729: m = 0.9610083384863121, c = 1.0902564051375265, loss = 0.01688946034175818\n",
      "Iteration 730: m = 0.9609711197110719, c = 1.0903907767255974, loss = 0.016887506341660124\n",
      "Iteration 731: m = 0.9609340267711002, c = 1.090524694008421, loss = 0.016885565532026605\n",
      "Iteration 732: m = 0.9608970592409529, c = 1.0906581585219866, loss = 0.01688363782381554\n",
      "Iteration 733: m = 0.960860216696624, c = 1.0907911717970897, loss = 0.01688172312858583\n",
      "Iteration 734: m = 0.9608234987155414, c = 1.0909237353593504, loss = 0.016879821358493453\n",
      "Iteration 735: m = 0.9607869048765613, c = 1.091055850729231, loss = 0.016877932426287302\n",
      "Iteration 736: m = 0.9607504347599639, c = 1.0911875194220526, loss = 0.01687605624530543\n",
      "Iteration 737: m = 0.9607140879474487, c = 1.0913187429480138, loss = 0.016874192729470675\n",
      "Iteration 738: m = 0.9606778640221292, c = 1.0914495228122065, loss = 0.016872341793287084\n",
      "Iteration 739: m = 0.9606417625685284, c = 1.0915798605146347, loss = 0.016870503351835757\n",
      "Iteration 740: m = 0.9606057831725741, c = 1.0917097575502304, loss = 0.016868677320771172\n",
      "Iteration 741: m = 0.9605699254215939, c = 1.0918392154088714, loss = 0.01686686361631709\n",
      "Iteration 742: m = 0.960534188904311, c = 1.0919682355753983, loss = 0.016865062155262785\n",
      "Iteration 743: m = 0.9604985732108386, c = 1.0920968195296317, loss = 0.016863272854959175\n",
      "Iteration 744: m = 0.9604630779326763, c = 1.0922249687463887, loss = 0.016861495633315276\n",
      "Iteration 745: m = 0.9604277026627042, c = 1.0923526846955003, loss = 0.016859730408794273\n",
      "Iteration 746: m = 0.9603924469951792, c = 1.092479968841828, loss = 0.016857977100409524\n",
      "Iteration 747: m = 0.9603573105257301, c = 1.0926068226452808, loss = 0.016856235627721282\n",
      "Iteration 748: m = 0.9603222928513527, c = 1.0927332475608313, loss = 0.01685450591083276\n",
      "Iteration 749: m = 0.9602873935704053, c = 1.0928592450385335, loss = 0.016852787870386462\n",
      "Iteration 750: m = 0.9602526122826041, c = 1.0929848165235385, loss = 0.016851081427560727\n",
      "Iteration 751: m = 0.9602179485890189, c = 1.0931099634561114, loss = 0.016849386504065908\n",
      "Iteration 752: m = 0.9601834020920681, c = 1.093234687271648, loss = 0.016847703022140784\n",
      "Iteration 753: m = 0.9601489723955142, c = 1.093358989400691, loss = 0.016846030904548993\n",
      "Iteration 754: m = 0.9601146591044597, c = 1.0934828712689464, loss = 0.016844370074575933\n",
      "Iteration 755: m = 0.9600804618253418, c = 1.0936063342973, loss = 0.016842720456024453\n",
      "Iteration 756: m = 0.9600463801659286, c = 1.0937293799018335, loss = 0.016841081973211915\n",
      "Iteration 757: m = 0.9600124137353143, c = 1.093852009493841, loss = 0.01683945455096669\n",
      "Iteration 758: m = 0.9599785621439147, c = 1.0939742244798454, loss = 0.01683783811462434\n",
      "Iteration 759: m = 0.9599448250034628, c = 1.0940960262616135, loss = 0.016836232590024744\n",
      "Iteration 760: m = 0.9599112019270042, c = 1.0942174162361735, loss = 0.0168346379035082\n",
      "Iteration 761: m = 0.9598776925288929, c = 1.0943383957958297, loss = 0.016833053981912302\n",
      "Iteration 762: m = 0.9598442964247866, c = 1.0944589663281796, loss = 0.016831480752568576\n",
      "Iteration 763: m = 0.9598110132316429, c = 1.0945791292161289, loss = 0.01682991814329889\n",
      "Iteration 764: m = 0.9597778425677137, c = 1.0946988858379076, loss = 0.016828366082412668\n",
      "Iteration 765: m = 0.9597447840525423, c = 1.0948182375670867, loss = 0.016826824498703055\n",
      "Iteration 766: m = 0.9597118373069577, c = 1.0949371857725925, loss = 0.016825293321443936\n",
      "Iteration 767: m = 0.9596790019530715, c = 1.095055731818723, loss = 0.016823772480386672\n",
      "Iteration 768: m = 0.9596462776142725, c = 1.0951738770651642, loss = 0.016822261905756773\n",
      "Iteration 769: m = 0.9596136639152226, c = 1.0952916228670047, loss = 0.0168207615282508\n",
      "Iteration 770: m = 0.9595811604818534, c = 1.0954089705747512, loss = 0.016819271279033148\n",
      "Iteration 771: m = 0.9595487669413606, c = 1.095525921534345, loss = 0.01681779108973287\n",
      "Iteration 772: m = 0.9595164829222006, c = 1.0956424770871764, loss = 0.016816320892440454\n",
      "Iteration 773: m = 0.9594843080540859, c = 1.0957586385701008, loss = 0.016814860619705135\n",
      "Iteration 774: m = 0.959452241967981, c = 1.0958744073154536, loss = 0.016813410204531046\n",
      "Iteration 775: m = 0.9594202842960979, c = 1.0959897846510658, loss = 0.016811969580374907\n",
      "Iteration 776: m = 0.9593884346718925, c = 1.0961047719002786, loss = 0.016810538681142455\n",
      "Iteration 777: m = 0.9593566927300594, c = 1.0962193703819594, loss = 0.016809117441185746\n",
      "Iteration 778: m = 0.9593250581065288, c = 1.0963335814105166, loss = 0.0168077057952998\n",
      "Iteration 779: m = 0.9592935304384614, c = 1.0964474062959146, loss = 0.01680630367871995\n",
      "Iteration 780: m = 0.959262109364245, c = 1.0965608463436887, loss = 0.016804911027118685\n",
      "Iteration 781: m = 0.9592307945234898, c = 1.0966739028549601, loss = 0.016803527776602725\n",
      "Iteration 782: m = 0.9591995855570244, c = 1.0967865771264516, loss = 0.016802153863710107\n",
      "Iteration 783: m = 0.959168482106892, c = 1.0968988704505012, loss = 0.01680078922540732\n",
      "Iteration 784: m = 0.9591374838163457, c = 1.0970107841150776, loss = 0.01679943379908616\n",
      "Iteration 785: m = 0.959106590329845, c = 1.0971223194037953, loss = 0.016798087522561327\n",
      "Iteration 786: m = 0.9590758012930514, c = 1.0972334775959287, loss = 0.01679675033406716\n",
      "Iteration 787: m = 0.9590451163528244, c = 1.0973442599664271, loss = 0.016795422172254996\n",
      "Iteration 788: m = 0.9590145351572175, c = 1.0974546677859291, loss = 0.016794102976190235\n",
      "Iteration 789: m = 0.9589840573554739, c = 1.0975647023207775, loss = 0.016792792685349674\n",
      "Iteration 790: m = 0.9589536825980229, c = 1.0976743648330336, loss = 0.01679149123961863\n",
      "Iteration 791: m = 0.9589234105364759, c = 1.0977836565804915, loss = 0.01679019857928833\n",
      "Iteration 792: m = 0.9588932408236217, c = 1.097892578816693, loss = 0.016788914645052888\n",
      "Iteration 793: m = 0.9588631731134234, c = 1.098001132790942, loss = 0.016787639378006935\n",
      "Iteration 794: m = 0.9588332070610137, c = 1.0981093197483178, loss = 0.016786372719642614\n",
      "Iteration 795: m = 0.9588033423226916, c = 1.0982171409296906, loss = 0.016785114611847132\n",
      "Iteration 796: m = 0.958773578555918, c = 1.0983245975717353, loss = 0.016783864996899846\n",
      "Iteration 797: m = 0.9587439154193119, c = 1.0984316909069456, loss = 0.016782623817469925\n",
      "Iteration 798: m = 0.9587143525726466, c = 1.098538422163648, loss = 0.016781391016613408\n",
      "Iteration 799: m = 0.9586848896768455, c = 1.0986447925660163, loss = 0.016780166537770765\n",
      "Iteration 800: m = 0.9586555263939786, c = 1.0987508033340854, loss = 0.016778950324764362\n",
      "Iteration 801: m = 0.9586262623872581, c = 1.098856455683765, loss = 0.016777742321795793\n",
      "Iteration 802: m = 0.9585970973210355, c = 1.0989617508268543, loss = 0.01677654247344314\n",
      "Iteration 803: m = 0.9585680308607964, c = 1.099066689971055, loss = 0.016775350724658748\n",
      "Iteration 804: m = 0.9585390626731579, c = 1.0991712743199862, loss = 0.0167741670207665\n",
      "Iteration 805: m = 0.958510192425864, c = 1.099275505073197, loss = 0.016772991307459455\n",
      "Iteration 806: m = 0.9584814197877821, c = 1.0993793834261814, loss = 0.016771823530797276\n",
      "Iteration 807: m = 0.9584527444288992, c = 1.0994829105703907, loss = 0.0167706636372036\n",
      "Iteration 808: m = 0.9584241660203179, c = 1.099586087693249, loss = 0.01676951157346391\n",
      "Iteration 809: m = 0.958395684234253, c = 1.099688915978165, loss = 0.016768367286722652\n",
      "Iteration 810: m = 0.9583672987440275, c = 1.0997913966045467, loss = 0.016767230724481517\n",
      "Iteration 811: m = 0.9583390092240687, c = 1.0998935307478142, loss = 0.01676610183459611\n",
      "Iteration 812: m = 0.9583108153499047, c = 1.0999953195794137, loss = 0.01676498056527431\n",
      "Iteration 813: m = 0.9582827167981609, c = 1.1000967642668311, loss = 0.016763866865073553\n",
      "Iteration 814: m = 0.9582547132465556, c = 1.100197865973605, loss = 0.01676276068289851\n",
      "Iteration 815: m = 0.9582268043738971, c = 1.1002986258593395, loss = 0.01676166196799886\n",
      "Iteration 816: m = 0.9581989898600793, c = 1.1003990450797188, loss = 0.01676057066996681\n",
      "Iteration 817: m = 0.9581712693860788, c = 1.1004991247865197, loss = 0.016759486738734765\n",
      "Iteration 818: m = 0.9581436426339502, c = 1.1005988661276245, loss = 0.01675841012457329\n",
      "Iteration 819: m = 0.9581161092868238, c = 1.100698270247035, loss = 0.016757340778088457\n",
      "Iteration 820: m = 0.9580886690289004, c = 1.1007973382848848, loss = 0.016756278650219912\n",
      "Iteration 821: m = 0.9580613215454493, c = 1.1008960713774532, loss = 0.016755223692238478\n",
      "Iteration 822: m = 0.9580340665228033, c = 1.100994470657177, loss = 0.0167541758557438\n",
      "Iteration 823: m = 0.958006903648356, c = 1.1010925372526652, loss = 0.016753135092662384\n",
      "Iteration 824: m = 0.9579798326105577, c = 1.1011902722887106, loss = 0.016752101355245123\n",
      "Iteration 825: m = 0.9579528530989124, c = 1.101287676886303, loss = 0.016751074596065375\n",
      "Iteration 826: m = 0.9579259648039735, c = 1.101384752162642, loss = 0.016750054768016664\n",
      "Iteration 827: m = 0.9578991674173408, c = 1.1014814992311508, loss = 0.016749041824310234\n",
      "Iteration 828: m = 0.9578724606316568, c = 1.1015779192014874, loss = 0.016748035718473636\n",
      "Iteration 829: m = 0.957845844140603, c = 1.1016740131795582, loss = 0.01674703640434775\n",
      "Iteration 830: m = 0.9578193176388968, c = 1.1017697822675308, loss = 0.01674604383608504\n",
      "Iteration 831: m = 0.9577928808222876, c = 1.1018652275638463, loss = 0.016745057968147882\n",
      "Iteration 832: m = 0.9577665333875536, c = 1.101960350163232, loss = 0.016744078755305557\n",
      "Iteration 833: m = 0.9577402750324979, c = 1.1020551511567143, loss = 0.01674310615263296\n",
      "Iteration 834: m = 0.9577141054559456, c = 1.1021496316316302, loss = 0.016742140115508237\n",
      "Iteration 835: m = 0.9576880243577398, c = 1.1022437926716409, loss = 0.01674118059961065\n",
      "Iteration 836: m = 0.9576620314387386, c = 1.1023376353567436, loss = 0.016740227560918683\n",
      "Iteration 837: m = 0.9576361264008115, c = 1.1024311607632844, loss = 0.016739280955708074\n",
      "Iteration 838: m = 0.957610308946836, c = 1.10252436996397, loss = 0.016738340740549505\n",
      "Iteration 839: m = 0.9575845787806938, c = 1.1026172640278804, loss = 0.016737406872307084\n",
      "Iteration 840: m = 0.9575589356072683, c = 1.1027098440204812, loss = 0.01673647930813605\n",
      "Iteration 841: m = 0.9575333791324404, c = 1.1028021110036355, loss = 0.01673555800548069\n",
      "Iteration 842: m = 0.9575079090630854, c = 1.1028940660356163, loss = 0.01673464292207274\n",
      "Iteration 843: m = 0.9574825251070695, c = 1.102985710171119, loss = 0.016733734015929126\n",
      "Iteration 844: m = 0.9574572269732471, c = 1.1030770444612723, loss = 0.016732831245350473\n",
      "Iteration 845: m = 0.9574320143714564, c = 1.1031680699536521, loss = 0.016731934568918534\n",
      "Iteration 846: m = 0.9574068870125169, c = 1.1032587876922917, loss = 0.016731043945494815\n",
      "Iteration 847: m = 0.9573818446082256, c = 1.1033491987176949, loss = 0.01673015933421854\n",
      "Iteration 848: m = 0.9573568868713543, c = 1.1034393040668475, loss = 0.016729280694504824\n",
      "Iteration 849: m = 0.9573320135156456, c = 1.1035291047732294, loss = 0.016728407986042512\n",
      "Iteration 850: m = 0.9573072242558098, c = 1.1036186018668261, loss = 0.016727541168792888\n",
      "Iteration 851: m = 0.9572825188075221, c = 1.103707796374141, loss = 0.01672668020298729\n",
      "Iteration 852: m = 0.9572578968874188, c = 1.103796689318207, loss = 0.016725825049125616\n",
      "Iteration 853: m = 0.9572333582130943, c = 1.1038852817185978, loss = 0.016724975667974318\n",
      "Iteration 854: m = 0.9572089025030976, c = 1.10397357459144, loss = 0.016724132020564816\n",
      "Iteration 855: m = 0.9571845294769298, c = 1.1040615689494253, loss = 0.0167232940681915\n",
      "Iteration 856: m = 0.9571602388550398, c = 1.104149265801821, loss = 0.016722461772410043\n",
      "Iteration 857: m = 0.9571360303588218, c = 1.1042366661544822, loss = 0.016721635095035728\n",
      "Iteration 858: m = 0.957111903710612, c = 1.1043237710098632, loss = 0.016720813998141508\n",
      "Iteration 859: m = 0.9570878586336856, c = 1.1044105813670293, loss = 0.01671999844405632\n",
      "Iteration 860: m = 0.9570638948522531, c = 1.1044970982216675, loss = 0.01671918839536351\n",
      "Iteration 861: m = 0.9570400120914574, c = 1.104583322566099, loss = 0.016718383814898957\n",
      "Iteration 862: m = 0.9570162100773708, c = 1.1046692553892896, loss = 0.016717584665749526\n",
      "Iteration 863: m = 0.9569924885369918, c = 1.1047548976768615, loss = 0.01671679091125107\n",
      "Iteration 864: m = 0.9569688471982419, c = 1.1048402504111048, loss = 0.016716002514986956\n",
      "Iteration 865: m = 0.9569452857899624, c = 1.104925314570988, loss = 0.016715219440786595\n",
      "Iteration 866: m = 0.9569218040419114, c = 1.1050100911321705, loss = 0.016714441652723365\n",
      "Iteration 867: m = 0.9568984016847607, c = 1.1050945810670125, loss = 0.016713669115113287\n",
      "Iteration 868: m = 0.9568750784500926, c = 1.1051787853445867, loss = 0.016712901792513137\n",
      "Iteration 869: m = 0.956851834070397, c = 1.1052627049306893, loss = 0.016712139649719054\n",
      "Iteration 870: m = 0.9568286682790683, c = 1.1053463407878517, loss = 0.01671138265176478\n",
      "Iteration 871: m = 0.9568055808104022, c = 1.1054296938753505, loss = 0.01671063076392015\n",
      "Iteration 872: m = 0.9567825713995928, c = 1.1055127651492194, loss = 0.016709883951689354\n",
      "Iteration 873: m = 0.9567596397827292, c = 1.1055955555622594, loss = 0.016709142180809537\n",
      "Iteration 874: m = 0.9567367856967932, c = 1.1056780660640504, loss = 0.016708405417249057\n",
      "Iteration 875: m = 0.9567140088796557, c = 1.1057602976009617, loss = 0.016707673627206095\n",
      "Iteration 876: m = 0.9566913090700738, c = 1.1058422511161632, loss = 0.016706946777106914\n",
      "Iteration 877: m = 0.9566686860076878, c = 1.1059239275496355, loss = 0.01670622483360442\n",
      "Iteration 878: m = 0.9566461394330183, c = 1.1060053278381816, loss = 0.016705507763576686\n",
      "Iteration 879: m = 0.9566236690874634, c = 1.1060864529154368, loss = 0.01670479553412546\n",
      "Iteration 880: m = 0.9566012747132953, c = 1.1061673037118802, loss = 0.016704088112574282\n",
      "Iteration 881: m = 0.9565789560536575, c = 1.1062478811548448, loss = 0.01670338546646761\n",
      "Iteration 882: m = 0.9565567128525622, c = 1.1063281861685286, loss = 0.016702687563568772\n",
      "Iteration 883: m = 0.9565345448548868, c = 1.1064082196740044, loss = 0.016701994371858757\n",
      "Iteration 884: m = 0.9565124518063715, c = 1.106487982589231, loss = 0.01670130585953476\n",
      "Iteration 885: m = 0.9564904334536158, c = 1.1065674758290642, loss = 0.016700621995008512\n",
      "Iteration 886: m = 0.9564684895440765, c = 1.106646700305266, loss = 0.016699942746905276\n",
      "Iteration 887: m = 0.9564466198260637, c = 1.106725656926516, loss = 0.01669926808406176\n",
      "Iteration 888: m = 0.9564248240487387, c = 1.1068043465984219, loss = 0.016698597975525295\n",
      "Iteration 889: m = 0.956403101962111, c = 1.106882770223529, loss = 0.016697932390551916\n",
      "Iteration 890: m = 0.9563814533170348, c = 1.1069609287013318, loss = 0.016697271298605522\n",
      "Iteration 891: m = 0.9563598778652073, c = 1.107038822928283, loss = 0.01669661466935591\n",
      "Iteration 892: m = 0.9563383753591647, c = 1.1071164537978049, loss = 0.016695962472677513\n",
      "Iteration 893: m = 0.9563169455522802, c = 1.1071938222002988, loss = 0.016695314678648578\n",
      "Iteration 894: m = 0.9562955881987606, c = 1.107270929023156, loss = 0.016694671257548813\n",
      "Iteration 895: m = 0.9562743030536439, c = 1.1073477751507672, loss = 0.016694032179858886\n",
      "Iteration 896: m = 0.9562530898727962, c = 1.1074243614645332, loss = 0.01669339741625865\n",
      "Iteration 897: m = 0.956231948412909, c = 1.1075006888428747, loss = 0.01669276693762583\n",
      "Iteration 898: m = 0.9562108784314965, c = 1.1075767581612426, loss = 0.016692140715034772\n",
      "Iteration 899: m = 0.9561898796868927, c = 1.1076525702921278, loss = 0.016691518719755143\n",
      "Iteration 900: m = 0.9561689519382487, c = 1.1077281261050718, loss = 0.01669090092325045\n",
      "Iteration 901: m = 0.9561480949455297, c = 1.1078034264666754, loss = 0.01669028729717693\n",
      "Iteration 902: m = 0.9561273084695127, c = 1.10787847224061, loss = 0.016689677813382132\n",
      "Iteration 903: m = 0.9561065922717833, c = 1.107953264287627, loss = 0.016689072443903653\n",
      "Iteration 904: m = 0.9560859461147334, c = 1.1080278034655675, loss = 0.016688471160967715\n",
      "Iteration 905: m = 0.956065369761558, c = 1.1081020906293721, loss = 0.016687873936988236\n",
      "Iteration 906: m = 0.9560448629762529, c = 1.1081761266310912, loss = 0.016687280744565245\n",
      "Iteration 907: m = 0.9560244255236118, c = 1.1082499123198941, loss = 0.016686691556483706\n",
      "Iteration 908: m = 0.9560040571692235, c = 1.1083234485420794, loss = 0.01668610634571238\n",
      "Iteration 909: m = 0.9559837576794696, c = 1.1083967361410845, loss = 0.01668552508540243\n",
      "Iteration 910: m = 0.9559635268215212, c = 1.1084697759574946, loss = 0.016684947748886344\n",
      "Iteration 911: m = 0.9559433643633368, c = 1.1085425688290536, loss = 0.016684374309676515\n",
      "Iteration 912: m = 0.9559232700736595, c = 1.1086151155906723, loss = 0.01668380474146418\n",
      "Iteration 913: m = 0.9559032437220141, c = 1.1086874170744392, loss = 0.016683239018118322\n",
      "Iteration 914: m = 0.9558832850787046, c = 1.1087594741096296, loss = 0.01668267711368414\n",
      "Iteration 915: m = 0.9558633939148118, c = 1.1088312875227146, loss = 0.016682119002382007\n",
      "Iteration 916: m = 0.9558435700021903, c = 1.1089028581373717, loss = 0.016681564658606488\n",
      "Iteration 917: m = 0.9558238131134662, c = 1.1089741867744929, loss = 0.016681014056924934\n",
      "Iteration 918: m = 0.9558041230220341, c = 1.109045274252195, loss = 0.016680467172076337\n",
      "Iteration 919: m = 0.9557844995020549, c = 1.1091161213858292, loss = 0.016679923978970244\n",
      "Iteration 920: m = 0.9557649423284531, c = 1.1091867289879893, loss = 0.016679384452685582\n",
      "Iteration 921: m = 0.9557454512769141, c = 1.1092570978685223, loss = 0.01667884856846948\n",
      "Iteration 922: m = 0.9557260261238817, c = 1.109327228834537, loss = 0.01667831630173617\n",
      "Iteration 923: m = 0.9557066666465555, c = 1.1093971226904134, loss = 0.01667778762806595\n",
      "Iteration 924: m = 0.9556873726228884, c = 1.1094667802378118, loss = 0.016677262523203774\n",
      "Iteration 925: m = 0.9556681438315843, c = 1.1095362022756823, loss = 0.016676740963058392\n",
      "Iteration 926: m = 0.9556489800520948, c = 1.1096053896002736, loss = 0.016676222923701346\n",
      "Iteration 927: m = 0.9556298810646175, c = 1.1096743430051423, loss = 0.016675708381365482\n",
      "Iteration 928: m = 0.9556108466500931, c = 1.1097430632811625, loss = 0.01667519731244421\n",
      "Iteration 929: m = 0.9555918765902028, c = 1.1098115512165336, loss = 0.016674689693490265\n",
      "Iteration 930: m = 0.9555729706673662, c = 1.1098798075967908, loss = 0.016674185501214696\n",
      "Iteration 931: m = 0.9555541286647382, c = 1.109947833204813, loss = 0.01667368471248564\n",
      "Iteration 932: m = 0.9555353503662071, c = 1.1100156288208325, loss = 0.016673187304327562\n",
      "Iteration 933: m = 0.9555166355563915, c = 1.1100831952224435, loss = 0.01667269325391995\n",
      "Iteration 934: m = 0.9554979840206388, c = 1.110150533184611, loss = 0.01667220253859634\n",
      "Iteration 935: m = 0.9554793955450216, c = 1.1102176434796807, loss = 0.016671715135843188\n",
      "Iteration 936: m = 0.955460869916336, c = 1.1102845268773858, loss = 0.016671231023299083\n",
      "Iteration 937: m = 0.955442406922099, c = 1.110351184144858, loss = 0.0166707501787534\n",
      "Iteration 938: m = 0.9554240063505458, c = 1.1104176160466348, loss = 0.016670272580145695\n",
      "Iteration 939: m = 0.9554056679906276, c = 1.1104838233446694, loss = 0.01666979820556414\n",
      "Iteration 940: m = 0.9553873916320094, c = 1.1105498067983384, loss = 0.016669327033245054\n",
      "Iteration 941: m = 0.955369177065067, c = 1.110615567164451, loss = 0.01666885904157151\n",
      "Iteration 942: m = 0.9553510240808851, c = 1.110681105197258, loss = 0.016668394209072585\n",
      "Iteration 943: m = 0.955332932471255, c = 1.1107464216484597, loss = 0.016667932514422452\n",
      "Iteration 944: m = 0.9553149020286713, c = 1.1108115172672153, loss = 0.016667473936438866\n",
      "Iteration 945: m = 0.9552969325463306, c = 1.1108763928001506, loss = 0.016667018454082937\n",
      "Iteration 946: m = 0.9552790238181289, c = 1.1109410489913678, loss = 0.016666566046457547\n",
      "Iteration 947: m = 0.9552611756386585, c = 1.1110054865824528, loss = 0.0166661166928068\n",
      "Iteration 948: m = 0.9552433878032065, c = 1.1110697063124841, loss = 0.01666567037251493\n",
      "Iteration 949: m = 0.955225660107752, c = 1.111133708918042, loss = 0.01666522706510517\n",
      "Iteration 950: m = 0.955207992348964, c = 1.111197495133216, loss = 0.016664786750239104\n",
      "Iteration 951: m = 0.955190384324199, c = 1.1112610656896138, loss = 0.016664349407715596\n",
      "Iteration 952: m = 0.9551728358314984, c = 1.1113244213163695, loss = 0.016663915017469867\n",
      "Iteration 953: m = 0.9551553466695866, c = 1.1113875627401522, loss = 0.01666348355957259\n",
      "Iteration 954: m = 0.9551379166378684, c = 1.1114504906851739, loss = 0.01666305501422896\n",
      "Iteration 955: m = 0.9551205455364269, c = 1.1115132058731982, loss = 0.01666262936177775\n",
      "Iteration 956: m = 0.9551032331660211, c = 1.1115757090235487, loss = 0.016662206582690596\n",
      "Iteration 957: m = 0.9550859793280835, c = 1.1116380008531166, loss = 0.016661786657570815\n",
      "Iteration 958: m = 0.9550687838247182, c = 1.1117000820763692, loss = 0.016661369567152827\n",
      "Iteration 959: m = 0.955051646458698, c = 1.1117619534053587, loss = 0.016660955292300803\n",
      "Iteration 960: m = 0.9550345670334629, c = 1.1118236155497296, loss = 0.01666054381400846\n",
      "Iteration 961: m = 0.9550175453531173, c = 1.1118850692167273, loss = 0.016660135113397492\n",
      "Iteration 962: m = 0.9550005812224279, c = 1.1119463151112057, loss = 0.016659729171717326\n",
      "Iteration 963: m = 0.9549836744468214, c = 1.1120073539356359, loss = 0.016659325970343787\n",
      "Iteration 964: m = 0.9549668248323826, c = 1.1120681863901138, loss = 0.016658925490778378\n",
      "Iteration 965: m = 0.9549500321858516, c = 1.1121288131723686, loss = 0.016658527714647594\n",
      "Iteration 966: m = 0.9549332963146221, c = 1.11218923497777, loss = 0.01665813262370191\n",
      "Iteration 967: m = 0.954916617026739, c = 1.1122494524993374, loss = 0.016657740199815023\n",
      "Iteration 968: m = 0.9548999941308962, c = 1.1123094664277462, loss = 0.016657350424982946\n",
      "Iteration 969: m = 0.9548834274364343, c = 1.1123692774513374, loss = 0.016656963281323267\n",
      "Iteration 970: m = 0.9548669167533386, c = 1.1124288862561247, loss = 0.016656578751074284\n",
      "Iteration 971: m = 0.9548504618922365, c = 1.1124882935258018, loss = 0.016656196816594176\n",
      "Iteration 972: m = 0.9548340626643964, c = 1.1125474999417515, loss = 0.016655817460360108\n",
      "Iteration 973: m = 0.9548177188817241, c = 1.1126065061830528, loss = 0.01665544066496787\n",
      "Iteration 974: m = 0.9548014303567616, c = 1.1126653129264883, loss = 0.016655066413130394\n",
      "Iteration 975: m = 0.9547851969026847, c = 1.112723920846553, loss = 0.016654694687677423\n",
      "Iteration 976: m = 0.9547690183333009, c = 1.1127823306154607, loss = 0.016654325471554612\n",
      "Iteration 977: m = 0.954752894463047, c = 1.1128405429031534, loss = 0.016653958747822807\n",
      "Iteration 978: m = 0.9547368251069875, c = 1.1128985583773074, loss = 0.016653594499657035\n",
      "Iteration 979: m = 0.9547208100808119, c = 1.112956377703342, loss = 0.01665323271034614\n",
      "Iteration 980: m = 0.9547048492008328, c = 1.1130140015444265, loss = 0.01665287336329154\n",
      "Iteration 981: m = 0.9546889422839839, c = 1.113071430561488, loss = 0.016652516442006816\n",
      "Iteration 982: m = 0.9546730891478182, c = 1.113128665413219, loss = 0.016652161930116826\n",
      "Iteration 983: m = 0.9546572896105051, c = 1.1131857067560855, loss = 0.016651809811356943\n",
      "Iteration 984: m = 0.9546415434908289, c = 1.1132425552443335, loss = 0.016651460069572497\n",
      "Iteration 985: m = 0.9546258506081865, c = 1.1132992115299971, loss = 0.01665111268871753\n",
      "Iteration 986: m = 0.9546102107825857, c = 1.113355676262906, loss = 0.016650767652854722\n",
      "Iteration 987: m = 0.9545946238346424, c = 1.1134119500906927, loss = 0.016650424946154204\n",
      "Iteration 988: m = 0.9545790895855796, c = 1.1134680336588003, loss = 0.01665008455289298\n",
      "Iteration 989: m = 0.954563607857224, c = 1.1135239276104896, loss = 0.016649746457454147\n",
      "Iteration 990: m = 0.9545481784720053, c = 1.1135796325868463, loss = 0.01664941064432634\n",
      "Iteration 991: m = 0.9545328012529534, c = 1.113635149226789, loss = 0.016649077098102753\n",
      "Iteration 992: m = 0.9545174760236963, c = 1.113690478167076, loss = 0.016648745803480792\n",
      "Iteration 993: m = 0.9545022026084585, c = 1.1137456200423128, loss = 0.016648416745260925\n",
      "Iteration 994: m = 0.954486980832059, c = 1.1138005754849591, loss = 0.016648089908346365\n",
      "Iteration 995: m = 0.9544718105199085, c = 1.1138553451253363, loss = 0.016647765277742206\n",
      "Iteration 996: m = 0.9544566914980085, c = 1.113909929591635, loss = 0.01664744283855477\n",
      "Iteration 997: m = 0.9544416235929485, c = 1.1139643295099217, loss = 0.016647122575990915\n",
      "Iteration 998: m = 0.9544266066319045, c = 1.1140185455041465, loss = 0.016646804475357324\n",
      "Iteration 999: m = 0.9544116404426367, c = 1.1140725781961494, loss = 0.01664648852205995\n",
      "Iteration 1000: m = 0.9543967248534877, c = 1.1141264282056682, loss = 0.01664617470160319\n",
      "Final parameters: m = 0.9543967248534877, c = 1.1141264282056682\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2.1, 2.9, 4.2, 4.8, 5.9])\n",
    "\n",
    "# Initial parameters\n",
    "m = 0.5\n",
    "c = 0.5\n",
    "alpha = 0.01\n",
    "n = len(x)\n",
    "\n",
    "# Perform gradient descent\n",
    "for i in range(1000):\n",
    "    # Calculate the predicted values\n",
    "    y1 = m * x + c\n",
    "    \n",
    "    # Compute gradients\n",
    "    slope_gradient = sum(-2 * (y - y1) * x / n)\n",
    "    intercept_gradient = sum(-2 * (y - y1) / n)\n",
    "    \n",
    "    # Update parameters\n",
    "    m -= alpha * slope_gradient\n",
    "    c -= alpha * intercept_gradient\n",
    "\n",
    "    # Calculate the loss\n",
    "    loss = sum((y - y1) ** 2) / n\n",
    "    print(f\"Iteration {i+1}: m = {m}, c = {c}, loss = {loss}\")\n",
    "\n",
    "# Final results\n",
    "print(f\"Final parameters: m = {m}, c = {c}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8900ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb2d63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred=m*x+c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77bfd9b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c6f6683d0>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.plot(x,ypred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c06e569e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.5816 0.5248\n",
      "\n",
      "Loss 1:  1.6239999999999994\n",
      "Loss 2:  0.9826412799999996\n",
      "Error:  0.6413587199999998\n",
      "\n",
      " 0.64376 0.544208\n",
      "\n",
      "Loss 1:  0.9826412799999996\n",
      "Loss 2:  0.6087052733439996\n",
      "Error:  0.373936006656\n",
      "\n",
      " 0.69108032 0.55949824\n",
      "\n",
      "Loss 1:  0.6087052733439996\n",
      "Loss 2:  0.39061122619924477\n",
      "Error:  0.21809404714475483\n",
      "\n",
      " 0.7270727551999999 0.571643456\n",
      "\n",
      "Loss 1:  0.39061122619924477\n",
      "Loss 2:  0.2633353908467543\n",
      "Error:  0.12727583535249049\n",
      "\n",
      " 0.754418141696 0.581386221568\n",
      "\n",
      "Loss 1:  0.2633353908467543\n",
      "Loss 2:  0.18898513790355767\n",
      "Error:  0.07435025294319661\n",
      "\n",
      " 0.7751629772288 0.58929340863488\n",
      "\n",
      "Loss 1:  0.18898513790355767\n",
      "Loss 2:  0.1454785106370018\n",
      "Error:  0.04350662726655588\n",
      "\n",
      " 0.7908695177203712 0.5957977618284543\n",
      "\n",
      "Loss 1:  0.1454785106370018\n",
      "Loss 2:  0.11994722965664124\n",
      "Error:  0.025531280980360546\n",
      "\n",
      " 0.8027303581121823 0.6012296355286629\n",
      "\n",
      "Loss 1:  0.11994722965664124\n",
      "Loss 2:  0.10489229064375272\n",
      "Error:  0.015054939012888527\n",
      "\n",
      " 0.8116559011957825 0.6058412213313588\n",
      "\n",
      "Loss 1:  0.10489229064375272\n",
      "Loss 2:  0.09594363703138886\n",
      "Error:  0.008948653612363855\n",
      "\n",
      " 0.8183411296528288 0.6098250428329847\n",
      "\n",
      "Loss 1:  0.09594363703138886\n",
      "Loss 2:  0.09055460815314856\n",
      "Error:  0.005389028878240304\n",
      "\n",
      " 0.8233165785592274 0.6133280741971553\n",
      "\n",
      "Loss 1:  0.09055460815314856\n",
      "Loss 2:  0.08724112825747403\n",
      "Error:  0.0033134798956745287\n",
      "\n",
      " 0.826987246824368 0.6164625179996586\n",
      "\n",
      "Loss 1:  0.08724112825747403\n",
      "Loss 2:  0.08513834353005699\n",
      "Error:  0.0021027847274170397\n",
      "\n",
      " 0.8296623014430274 0.6193140328302034\n",
      "\n",
      "Loss 1:  0.08513834353005699\n",
      "Loss 2:  0.0837422520995696\n",
      "Error:  0.001396091430487384\n",
      "\n",
      " 0.8315777531557492 0.6219480140870176\n",
      "\n",
      "Loss 1:  0.0837422520995696\n",
      "Loss 2:  0.08275913879568844\n",
      "Error:  0.000983113303881164\n",
      "\n",
      " 0.8329137666162634 0.6244143886159323\n",
      "\n",
      "Loss 1:  0.08275913879568844\n",
      "Loss 2:  0.08201783317969913\n",
      "Error:  0.0007413056159893128\n",
      "\n",
      " 0.8338078746437295 0.626751274846638\n",
      "\n",
      "Loss 1:  0.08201783317969913\n",
      "Loss 2:  0.08141857786819176\n",
      "Error:  0.0005992553115073684\n",
      "\n",
      " 0.8343650657313108 0.6289877768710814\n",
      "\n",
      "Loss 1:  0.08141857786819176\n",
      "Loss 2:  0.08090323152311626\n",
      "Error:  0.0005153463450754958\n",
      "\n",
      " 0.8346654846581575 0.6311461173897811\n",
      "\n",
      "Loss 1:  0.08090323152311626\n",
      "Loss 2:  0.08043790462918615\n",
      "Error:  0.0004653268939301125\n",
      "\n",
      " 0.834770310989976 0.633243265962496\n",
      "\n",
      "Loss 1:  0.08043790462918615\n",
      "Loss 2:  0.08000284048424511\n",
      "Error:  0.0004350641449410442\n",
      "\n",
      " 0.8347262466144315 0.6352921819838475\n",
      "\n",
      "Loss 1:  0.08000284048424511\n",
      "Loss 2:  0.07958651834106434\n",
      "Error:  0.00041632214318076954\n",
      "\n",
      " 0.8345689414402258 0.6373027635473046\n",
      "\n",
      "Loss 1:  0.07958651834106434\n",
      "Loss 2:  0.07918221700997075\n",
      "Error:  0.0004043013310935928\n",
      "\n",
      " 0.8343256085105378 0.639282571789945\n",
      "\n",
      "Loss 1:  0.07918221700997075\n",
      "Loss 2:  0.07878601229624059\n",
      "Error:  0.00039620471373015553\n",
      "\n",
      " 0.8340170203308228 0.6412373838435138\n",
      "\n",
      "Loss 1:  0.07878601229624059\n",
      "Loss 2:  0.078395610005413\n",
      "Error:  0.00039040229082759614\n",
      "\n",
      " 0.8336590328274309 0.6431716149467942\n",
      "\n",
      "Loss 1:  0.078395610005413\n",
      "Loss 2:  0.07800966587622234\n",
      "Error:  0.00038594412919065735\n",
      "\n",
      " 0.8332637487085884 0.6450886406782125\n",
      "\n",
      "Loss 1:  0.07800966587622234\n",
      "Loss 2:  0.07762738927084277\n",
      "Error:  0.00038227660537956676\n",
      "\n",
      " 0.8328404055520062 0.6469910429421329\n",
      "\n",
      "Loss 1:  0.07762738927084277\n",
      "Loss 2:  0.07724831222485064\n",
      "Error:  0.0003790770459921322\n",
      "\n",
      " 0.8323960537540369 0.6488807977501699\n",
      "\n",
      "Loss 1:  0.07724831222485064\n",
      "Loss 2:  0.07687215486064324\n",
      "Error:  0.0003761573642074023\n",
      "\n",
      " 0.8319360740631386 0.6507594185699244\n",
      "\n",
      "Loss 1:  0.07687215486064324\n",
      "Loss 2:  0.07649874695671484\n",
      "Error:  0.0003734079039283966\n",
      "\n",
      " 0.8314645726550527 0.6526280657547375\n",
      "\n",
      "Loss 1:  0.07649874695671484\n",
      "Loss 2:  0.07612798224178534\n",
      "Error:  0.00037076471492950014\n",
      "\n",
      " 0.8309846827256568 0.6544876300803396\n",
      "\n",
      "Loss 1:  0.07612798224178534\n",
      "Loss 2:  0.0757597917593578\n",
      "Error:  0.00036819048242753283\n",
      "\n",
      " 0.8304987947211919 0.6563387965151934\n",
      "\n",
      "Loss 1:  0.0757597917593578\n",
      "Loss 2:  0.07539412834557806\n",
      "Error:  0.00036566341377974876\n",
      "\n",
      " 0.8300087320916181 0.6581820929016181\n",
      "\n",
      "Loss 1:  0.07539412834557806\n",
      "Loss 2:  0.07503095758337978\n",
      "Error:  0.0003631707621982727\n",
      "\n",
      " 0.829515885457365 0.6600179271180887\n",
      "\n",
      "Loss 1:  0.07503095758337978\n",
      "Loss 2:  0.07467025253069035\n",
      "Error:  0.000360705052689439\n",
      "\n",
      " 0.8290213150296594 0.661846615448285\n",
      "\n",
      "Loss 1:  0.07467025253069035\n",
      "Loss 2:  0.07431199064797361\n",
      "Error:  0.00035826188271673165\n",
      "\n",
      " 0.8285258287962372 0.6636684042375398\n",
      "\n",
      "Loss 1:  0.07431199064797361\n",
      "Loss 2:  0.07395615200744063\n",
      "Error:  0.000355838640532985\n",
      "\n",
      " 0.8280300422068125 0.6654834864250148\n",
      "\n",
      "Loss 1:  0.07395615200744063\n",
      "Loss 2:  0.07360271824915496\n",
      "Error:  0.0003534337582856706\n",
      "\n",
      " 0.8275344237358129 0.6672920141641057\n",
      "\n",
      "Loss 1:  0.07360271824915496\n",
      "Loss 2:  0.07325167197239216\n",
      "Error:  0.00035104627676280087\n",
      "\n",
      " 0.8270393296640877 0.6690941084566748\n",
      "\n",
      "Loss 1:  0.07325167197239216\n",
      "Loss 2:  0.0729029963806476\n",
      "Error:  0.00034867559174456275\n",
      "\n",
      " 0.8265450306305879 0.6708898665076961\n",
      "\n",
      "Loss 1:  0.0729029963806476\n",
      "Loss 2:  0.07255667507445838\n",
      "Error:  0.00034632130618920953\n",
      "\n",
      " 0.8260517319013968 0.6726793673397069\n",
      "\n",
      "Loss 1:  0.07255667507445838\n",
      "Loss 2:  0.0722126919303677\n",
      "Error:  0.00034398314409068986\n",
      "\n",
      " 0.8255595888427071 0.6744626760788289\n",
      "\n",
      "Loss 1:  0.0722126919303677\n",
      "Loss 2:  0.07187103103008978\n",
      "Error:  0.0003416609002779153\n",
      "\n",
      " 0.8250687187325818 0.67623984722669\n",
      "\n",
      "Loss 1:  0.07187103103008978\n",
      "Loss 2:  0.07153167661893103\n",
      "Error:  0.000339354411158746\n",
      "\n",
      " 0.8245792097778124 0.6780109271582012\n",
      "\n",
      "Loss 1:  0.07153167661893103\n",
      "Loss 2:  0.07119461308126294\n",
      "Error:  0.00033706353766808916\n",
      "\n",
      " 0.8240911279972015 0.6797759560283685\n",
      "\n",
      "Loss 1:  0.07119461308126294\n",
      "Loss 2:  0.07085982492593419\n",
      "Error:  0.0003347881553287524\n",
      "\n",
      " 0.823604522476115 0.6815349692279691\n",
      "\n",
      "Loss 1:  0.07085982492593419\n",
      "Loss 2:  0.07052729677747563\n",
      "Error:  0.0003325281484585635\n",
      "\n",
      " 0.8231194293776916 0.6832879984948428\n",
      "\n",
      "Loss 1:  0.07052729677747563\n",
      "Loss 2:  0.07019701337068407\n",
      "Error:  0.00033028340679155943\n",
      "\n",
      " 0.8226358750049089 0.6850350727622845\n",
      "\n",
      "Loss 1:  0.07019701337068407\n",
      "Loss 2:  0.0698689595471769\n",
      "Error:  0.00032805382350717394\n",
      "\n",
      " 0.8221538781380918 0.6867762188067442\n",
      "\n",
      "Loss 1:  0.0698689595471769\n",
      "Loss 2:  0.06954312025309625\n",
      "Error:  0.00032583929408064316\n",
      "\n",
      " 0.821673451819307 0.6885114617423238\n",
      "\n",
      "Loss 1:  0.06954312025309625\n",
      "Loss 2:  0.0692194805374869\n",
      "Error:  0.0003236397156093501\n",
      "\n",
      " 0.82119460471452 0.6902408253983189\n",
      "\n",
      "Loss 1:  0.0692194805374869\n",
      "Loss 2:  0.06889802555106629\n",
      "Error:  0.00032145498642061066\n",
      "\n",
      " 0.8207173421534264 0.6919643326074812\n",
      "\n",
      "Loss 1:  0.06889802555106629\n",
      "Loss 2:  0.06857874054522688\n",
      "Error:  0.00031928500583941477\n",
      "\n",
      " 0.8202416669232238 0.693682005426126\n",
      "\n",
      "Loss 1:  0.06857874054522688\n",
      "Loss 2:  0.06826161087117516\n",
      "Error:  0.00031712967405171655\n",
      "\n",
      " 0.819767579874547 0.69539386530221\n",
      "\n",
      "Loss 1:  0.06826161087117516\n",
      "Loss 2:  0.06794662197915219\n",
      "Error:  0.00031498889202297153\n",
      "\n",
      " 0.819295080384014 0.697099933203693\n",
      "\n",
      "Loss 1:  0.06794662197915219\n",
      "Loss 2:  0.06763375941770262\n",
      "Error:  0.0003128625614495645\n",
      "\n",
      " 0.8188241667073093 0.6988002297165783\n",
      "\n",
      "Loss 1:  0.06763375941770262\n",
      "Loss 2:  0.06732300883297643\n",
      "Error:  0.00031075058472619654\n",
      "\n",
      " 0.8183548362487065 0.7004947751198082\n",
      "\n",
      "Loss 1:  0.06732300883297643\n",
      "Loss 2:  0.0670143559680478\n",
      "Error:  0.0003086528649286213\n",
      "\n",
      " 0.8178870857668026 0.7021835894424896\n",
      "\n",
      "Loss 1:  0.0670143559680478\n",
      "Loss 2:  0.06670778666224955\n",
      "Error:  0.00030656930579825437\n",
      "\n",
      " 0.8174209115315566 0.7038666925076317\n",
      "\n",
      "Loss 1:  0.06670778666224955\n",
      "Loss 2:  0.06640328685051597\n",
      "Error:  0.00030449981173358287\n",
      "\n",
      " 0.8169563094441562 0.7055441039655856\n",
      "\n",
      "Loss 1:  0.06640328685051597\n",
      "Loss 2:  0.06610084256273305\n",
      "Error:  0.00030244428778292143\n",
      "\n",
      " 0.8164932751285067 0.7072158433196245\n",
      "\n",
      "Loss 1:  0.06610084256273305\n",
      "Loss 2:  0.0658004399230955\n",
      "Error:  0.00030040263963754255\n",
      "\n",
      " 0.8160318040010577 0.7088819299455216\n",
      "\n",
      "Loss 1:  0.0658004399230955\n",
      "Loss 2:  0.06550206514946831\n",
      "Error:  0.0002983747736271941\n",
      "\n",
      " 0.8155718913240937 0.7105423831065477\n",
      "\n",
      "Loss 1:  0.06550206514946831\n",
      "Loss 2:  0.06520570455275412\n",
      "Error:  0.00029636059671418746\n",
      "\n",
      " 0.8151135322464003 0.7121972219649711\n",
      "\n",
      "Loss 1:  0.06520570455275412\n",
      "Loss 2:  0.0649113445362641\n",
      "Error:  0.0002943600164900251\n",
      "\n",
      " 0.8146567218342939 0.7138464655908877\n",
      "\n",
      "Loss 1:  0.0649113445362641\n",
      "Loss 2:  0.0646189715950944\n",
      "Error:  0.0002923729411696968\n",
      "\n",
      " 0.814201455095296 0.7154901329690123\n",
      "\n",
      "Loss 1:  0.0646189715950944\n",
      "Loss 2:  0.06432857231550607\n",
      "Error:  0.00029039927958833534\n",
      "\n",
      " 0.8137477269961901 0.7171282430039143\n",
      "\n",
      "Loss 1:  0.06432857231550607\n",
      "Loss 2:  0.06404013337430962\n",
      "Error:  0.0002884389411964422\n",
      "\n",
      " 0.8132955324767934 0.7187608145240646\n",
      "\n",
      "Loss 1:  0.06404013337430962\n",
      "Loss 2:  0.06375364153825358\n",
      "Error:  0.00028649183605604367\n",
      "\n",
      " 0.812844866460455 0.7203878662849756\n",
      "\n",
      "Loss 1:  0.06375364153825358\n",
      "Loss 2:  0.06346908366341801\n",
      "Error:  0.0002845578748355698\n",
      "\n",
      " 0.8123957238620563 0.7220094169716488\n",
      "\n",
      "Loss 1:  0.06346908366341801\n",
      "Loss 2:  0.06318644669461033\n",
      "Error:  0.00028263696880767575\n",
      "\n",
      " 0.811948099594105 0.7236254852004924\n",
      "\n",
      "Loss 1:  0.06318644669461033\n",
      "Loss 2:  0.06290571766476745\n",
      "Error:  0.0002807290298428855\n",
      "\n",
      " 0.8115019885713723 0.7252360895208363\n",
      "\n",
      "Loss 1:  0.06290571766476745\n",
      "Loss 2:  0.06262688369435998\n",
      "Error:  0.0002788339704074688\n",
      "\n",
      " 0.8110573857144202 0.7268412484161372\n",
      "\n",
      "Loss 1:  0.06262688369435998\n",
      "Loss 2:  0.06234993199080198\n",
      "Error:  0.00027695170355800103\n",
      "\n",
      " 0.8106142859522796 0.7284409803049492\n",
      "\n",
      "Loss 1:  0.06234993199080198\n",
      "Loss 2:  0.06207484984786379\n",
      "Error:  0.00027508214293819194\n",
      "\n",
      " 0.8101726842244811 0.7300353035417134\n",
      "\n",
      "Loss 1:  0.06207484984786379\n",
      "Loss 2:  0.061801624645088725\n",
      "Error:  0.00027322520277506257\n",
      "\n",
      " 0.8097325754825925 0.7316242364174103\n",
      "\n",
      "Loss 1:  0.061801624645088725\n",
      "Loss 2:  0.06153024384721484\n",
      "Error:  0.00027138079787388664\n",
      "\n",
      " 0.8092939546913775 0.7332077971601065\n",
      "\n",
      "Loss 1:  0.06153024384721484\n",
      "Loss 2:  0.06126069500359921\n",
      "Error:  0.00026954884361563014\n",
      "\n",
      " 0.808856816829668 0.7347860039354217\n",
      "\n",
      "Loss 1:  0.06126069500359921\n",
      "Loss 2:  0.06099296574764664\n",
      "Error:  0.00026772925595256597\n",
      "\n",
      " 0.8084211568910158 0.7363588748469332\n",
      "\n",
      "Loss 1:  0.06099296574764664\n",
      "Loss 2:  0.06072704379624309\n",
      "Error:  0.00026592195140355546\n",
      "\n",
      " 0.8079869698841763 0.7379264279365336\n",
      "\n",
      "Loss 1:  0.06072704379624309\n",
      "Loss 2:  0.060462916949191224\n",
      "Error:  0.0002641268470518626\n",
      "\n",
      " 0.8075542508334654 0.7394886811847524\n",
      "\n",
      "Loss 1:  0.060462916949191224\n",
      "Loss 2:  0.06020057308865111\n",
      "Error:  0.00026234386054011655\n",
      "\n",
      " 0.8071229947790178 0.7410456525110495\n",
      "\n",
      "Loss 1:  0.06020057308865111\n",
      "Loss 2:  0.05994000017858414\n",
      "Error:  0.0002605729100669668\n",
      "\n",
      " 0.8066931967769709 0.7425973597740875\n",
      "\n",
      "Loss 1:  0.05994000017858414\n",
      "Loss 2:  0.059681186264201234\n",
      "Error:  0.0002588139143829063\n",
      "\n",
      " 0.8062648518995921 0.7441438207719875\n",
      "\n",
      "Loss 1:  0.059681186264201234\n",
      "Loss 2:  0.05942411947141365\n",
      "Error:  0.0002570667927875858\n",
      "\n",
      " 0.8058379552353625 0.7456850532425722\n",
      "\n",
      "Loss 1:  0.05942411947141365\n",
      "Loss 2:  0.0591687880062887\n",
      "Error:  0.00025533146512495\n",
      "\n",
      " 0.8054125018890285 0.747221074863599\n",
      "\n",
      "Loss 1:  0.0591687880062887\n",
      "Loss 2:  0.05891518015450882\n",
      "Error:  0.0002536078517798787\n",
      "\n",
      " 0.8049884869816263 0.7487519032529854\n",
      "\n",
      "Loss 1:  0.05891518015450882\n",
      "Loss 2:  0.05866328428083366\n",
      "Error:  0.000251895873675162\n",
      "\n",
      " 0.8045659056504894 0.7502775559690281\n",
      "\n",
      "Loss 1:  0.05866328428083366\n",
      "Loss 2:  0.05841308882856627\n",
      "Error:  0.00025019545226738493\n",
      "\n",
      " 0.80414475304924 0.7517980505106182\n",
      "\n",
      "Loss 1:  0.05841308882856627\n",
      "Loss 2:  0.058164582319023495\n",
      "Error:  0.00024850650954277853\n",
      "\n",
      " 0.8037250243477702 0.7533134043174514\n",
      "\n",
      "Loss 1:  0.058164582319023495\n",
      "Loss 2:  0.05791775335100889\n",
      "Error:  0.0002468289680146035\n",
      "\n",
      " 0.8033067147322136 0.7548236347702362\n",
      "\n",
      "Loss 1:  0.05791775335100889\n",
      "Loss 2:  0.057672590600289245\n",
      "Error:  0.00024516275071964633\n",
      "\n",
      " 0.8028898194049124 0.7563287591908986\n",
      "\n",
      "Loss 1:  0.057672590600289245\n",
      "Loss 2:  0.057429082819076285\n",
      "Error:  0.00024350778121295935\n",
      "\n",
      " 0.8024743335843778 0.7578287948427859\n",
      "\n",
      "Loss 1:  0.057429082819076285\n",
      "Loss 2:  0.0571872188355092\n",
      "Error:  0.00024186398356708383\n",
      "\n",
      " 0.8020602525052475 0.7593237589308675\n",
      "\n",
      "Loss 1:  0.0571872188355092\n",
      "Loss 2:  0.05694698755314294\n",
      "Error:  0.0002402312823662628\n",
      "\n",
      " 0.801647571418241 0.7608136686019352\n",
      "\n",
      "Loss 1:  0.05694698755314294\n",
      "Loss 2:  0.05670837795043922\n",
      "Error:  0.000238609602703721\n",
      "\n",
      " 0.8012362855901118 0.7622985409448021\n",
      "\n",
      "Loss 1:  0.05670837795043922\n",
      "Loss 2:  0.056471379080260155\n",
      "Error:  0.0002369988701790629\n",
      "\n",
      " 0.8008263903035991 0.7637783929904993\n",
      "\n",
      "Loss 1:  0.056471379080260155\n",
      "Loss 2:  0.05623598006936668\n",
      "Error:  0.0002353990108934778\n",
      "\n",
      " 0.8004178808573773 0.7652532417124733\n",
      "\n",
      "Loss 1:  0.05623598006936668\n",
      "Loss 2:  0.056002170117919414\n",
      "Error:  0.00023380995144726274\n",
      "\n",
      " 0.8000107525660058 0.7667231040267812\n",
      "\n",
      "Loss 1:  0.056002170117919414\n",
      "Loss 2:  0.05576993849898325\n",
      "Error:  0.00023223161893616562\n",
      "\n",
      " 0.7996050007598777 0.7681879967922852\n",
      "\n",
      "Loss 1:  0.05576993849898325\n",
      "Loss 2:  0.05553927455803505\n",
      "Error:  0.0002306639409482003\n",
      "\n",
      " 0.7992006207851675 0.7696479368108469\n",
      "\n",
      "Loss 1:  0.05553927455803505\n",
      "Loss 2:  0.05531016771247519\n",
      "Error:  0.000229106845559858\n",
      "\n",
      " 0.7987976080037799 0.7711029408275198\n",
      "\n",
      "Loss 1:  0.05531016771247519\n",
      "Loss 2:  0.05508260745114148\n",
      "Error:  0.00022756026133371327\n",
      "\n",
      " 0.7983959577932971 0.7725530255307427\n",
      "\n",
      "Loss 1:  0.05508260745114148\n",
      "Loss 2:  0.054856583333827626\n",
      "Error:  0.00022602411731385136\n",
      "\n",
      " 0.7979956655469271 0.77399820755253\n",
      "\n",
      "Loss 1:  0.054856583333827626\n",
      "Loss 2:  0.05463208499080362\n",
      "Error:  0.00022449834302400856\n",
      "\n",
      " 0.7975967266734514 0.7754385034686638\n",
      "\n",
      "Loss 1:  0.05463208499080362\n",
      "Loss 2:  0.05440910212234047\n",
      "Error:  0.0002229828684631452\n",
      "\n",
      " 0.7971991365971722 0.7768739297988835\n",
      "\n",
      "Loss 1:  0.05440910212234047\n",
      "Loss 2:  0.054187624498237184\n",
      "Error:  0.00022147762410328758\n",
      "\n",
      " 0.7968028907578614 0.7783045030070754\n",
      "\n",
      "Loss 1:  0.054187624498237184\n",
      "Loss 2:  0.053967641957351785\n",
      "Error:  0.00021998254088539948\n",
      "\n",
      " 0.7964079846107074 0.7797302395014623\n",
      "\n",
      "Loss 1:  0.053967641957351785\n",
      "Loss 2:  0.053749144407135144\n",
      "Error:  0.00021849755021664113\n",
      "\n",
      " 0.796014413626264 0.7811511556347905\n",
      "\n",
      "Loss 1:  0.053749144407135144\n",
      "Loss 2:  0.05353212182316749\n",
      "Error:  0.00021702258396765622\n",
      "\n",
      " 0.7956221732903985 0.7825672677045189\n",
      "\n",
      "Loss 1:  0.05353212182316749\n",
      "Loss 2:  0.05331656424869935\n",
      "Error:  0.0002155575744681379\n",
      "\n",
      " 0.7952312591042398 0.7839785919530046\n",
      "\n",
      "Loss 1:  0.05331656424869935\n",
      "Loss 2:  0.053102461794193576\n",
      "Error:  0.00021410245450577403\n",
      "\n",
      " 0.7948416665841267 0.78538514456769\n",
      "\n",
      "Loss 1:  0.053102461794193576\n",
      "Loss 2:  0.05288980463687283\n",
      "Error:  0.00021265715732074475\n",
      "\n",
      " 0.7944533912615575 0.7867869416812886\n",
      "\n",
      "Loss 1:  0.05288980463687283\n",
      "Loss 2:  0.05267858302026811\n",
      "Error:  0.00021122161660472316\n",
      "\n",
      " 0.7940664286831375 0.7881839993719694\n",
      "\n",
      "Loss 1:  0.05267858302026811\n",
      "Loss 2:  0.05246878725377139\n",
      "Error:  0.000209795766496719\n",
      "\n",
      " 0.7936807744105291 0.7895763336635417\n",
      "\n",
      "Loss 1:  0.05246878725377139\n",
      "Loss 2:  0.05226040771219111\n",
      "Error:  0.00020837954158027527\n",
      "\n",
      " 0.7932964240204001 0.7909639605256391\n",
      "\n",
      "Loss 1:  0.05226040771219111\n",
      "Loss 2:  0.05205343483531031\n",
      "Error:  0.0002069728768808038\n",
      "\n",
      " 0.7929133731043737 0.7923468958739023\n",
      "\n",
      "Loss 1:  0.05205343483531031\n",
      "Loss 2:  0.05184785912744853\n",
      "Error:  0.00020557570786178259\n",
      "\n",
      " 0.7925316172689774 0.7937251555701618\n",
      "\n",
      "Loss 1:  0.05184785912744853\n",
      "Loss 2:  0.05164367115702571\n",
      "Error:  0.00020418797042282\n",
      "\n",
      " 0.7921511521355926 0.7950987554226199\n",
      "\n",
      "Loss 1:  0.05164367115702571\n",
      "Loss 2:  0.05144086155612935\n",
      "Error:  0.0002028096008963587\n",
      "\n",
      " 0.791771973340405 0.7964677111860319\n",
      "\n",
      "Loss 1:  0.05144086155612935\n",
      "Loss 2:  0.051239421020085316\n",
      "Error:  0.00020144053604403273\n",
      "\n",
      " 0.791394076534354 0.7978320385618869\n",
      "\n",
      "Loss 1:  0.051239421020085316\n",
      "Loss 2:  0.051039340307030515\n",
      "Error:  0.00020008071305480102\n",
      "\n",
      " 0.7910174573830829 0.7991917531985879\n",
      "\n",
      "Loss 1:  0.051039340307030515\n",
      "Loss 2:  0.05084061023748897\n",
      "Error:  0.00019873006954154726\n",
      "\n",
      " 0.7906421115668893 0.8005468706916312\n",
      "\n",
      "Loss 1:  0.05084061023748897\n",
      "Loss 2:  0.05064322169395056\n",
      "Error:  0.00019738854353840846\n",
      "\n",
      " 0.7902680347806758 0.8018974065837853\n",
      "\n",
      "Loss 1:  0.05064322169395056\n",
      "Loss 2:  0.05044716562045324\n",
      "Error:  0.00019605607349731935\n",
      "\n",
      " 0.7898952227339 0.803243376365269\n",
      "\n",
      "Loss 1:  0.05044716562045324\n",
      "Loss 2:  0.050252433022166657\n",
      "Error:  0.00019473259828658301\n",
      "\n",
      " 0.7895236711505259 0.8045847954739296\n",
      "\n",
      "Loss 1:  0.050252433022166657\n",
      "Loss 2:  0.05005901496498037\n",
      "Error:  0.00019341805718628424\n",
      "\n",
      " 0.7891533757689744 0.8059216792954195\n",
      "\n",
      "Loss 1:  0.05005901496498037\n",
      "Loss 2:  0.049866902575093505\n",
      "Error:  0.00019211238988686707\n",
      "\n",
      " 0.7887843323420748 0.8072540431633726\n",
      "\n",
      "Loss 1:  0.049866902575093505\n",
      "Loss 2:  0.049676087038607805\n",
      "Error:  0.00019081553648570004\n",
      "\n",
      " 0.7884165366370159 0.8085819023595806\n",
      "\n",
      "Loss 1:  0.049676087038607805\n",
      "Loss 2:  0.04948655960112286\n",
      "Error:  0.00018952743748494594\n",
      "\n",
      " 0.7880499844352976 0.8099052721141681\n",
      "\n",
      "Loss 1:  0.04948655960112286\n",
      "Loss 2:  0.04929831156733509\n",
      "Error:  0.00018824803378776622\n",
      "\n",
      " 0.7876846715326821 0.8112241676057669\n",
      "\n",
      "Loss 1:  0.04929831156733509\n",
      "Loss 2:  0.04911133430063846\n",
      "Error:  0.0001869772666966349\n",
      "\n",
      " 0.787320593739146 0.8125386039616906\n",
      "\n",
      "Loss 1:  0.04911133430063846\n",
      "Loss 2:  0.04892561922272821\n",
      "Error:  0.00018571507791025066\n",
      "\n",
      " 0.7869577468788324 0.813848596258108\n",
      "\n",
      "Loss 1:  0.04892561922272821\n",
      "Loss 2:  0.04874115781320729\n",
      "Error:  0.00018446140952091405\n",
      "\n",
      " 0.7865961267900028 0.8151541595202159\n",
      "\n",
      "Loss 1:  0.04874115781320729\n",
      "Loss 2:  0.04855794160919582\n",
      "Error:  0.00018321620401147432\n",
      "\n",
      " 0.7862357293249892 0.8164553087224113\n",
      "\n",
      "Loss 1:  0.04855794160919582\n",
      "Loss 2:  0.04837596220494219\n",
      "Error:  0.00018197940425362935\n",
      "\n",
      " 0.7858765503501469 0.8177520587884638\n",
      "\n",
      "Loss 1:  0.04837596220494219\n",
      "Loss 2:  0.048195211251437914\n",
      "Error:  0.0001807509535042759\n",
      "\n",
      " 0.7855185857458068 0.8190444245916857\n",
      "\n",
      "Loss 1:  0.048195211251437914\n",
      "Loss 2:  0.04801568045603462\n",
      "Error:  0.00017953079540329597\n",
      "\n",
      " 0.7851618314062282 0.8203324209551036\n",
      "\n",
      "Loss 1:  0.04801568045603462\n",
      "Loss 2:  0.04783736158206299\n",
      "Error:  0.00017831887397162793\n",
      "\n",
      " 0.7848062832395518 0.8216160626516279\n",
      "\n",
      "Loss 1:  0.04783736158206299\n",
      "Loss 2:  0.04766024644845566\n",
      "Error:  0.00017711513360733205\n",
      "\n",
      " 0.7844519371677527 0.8228953644042223\n",
      "\n",
      "Loss 1:  0.04766024644845566\n",
      "Loss 2:  0.04748432692937138\n",
      "Error:  0.0001759195190842791\n",
      "\n",
      " 0.7840987891265938 0.8241703408860727\n",
      "\n",
      "Loss 1:  0.04748432692937138\n",
      "Loss 2:  0.04730959495382219\n",
      "Error:  0.00017473197554918746\n",
      "\n",
      " 0.7837468350655789 0.8254410067207556\n",
      "\n",
      "Loss 1:  0.04730959495382219\n",
      "Loss 2:  0.04713604250530359\n",
      "Error:  0.00017355244851860463\n",
      "\n",
      " 0.7833960709479062 0.8267073764824058\n",
      "\n",
      "Loss 1:  0.04713604250530359\n",
      "Loss 2:  0.04696366162142603\n",
      "Error:  0.00017238088387755424\n",
      "\n",
      " 0.7830464927504225 0.8279694646958833\n",
      "\n",
      "Loss 1:  0.04696366162142603\n",
      "Loss 2:  0.04679244439355047\n",
      "Error:  0.00017121722787555999\n",
      "\n",
      " 0.7826980964635765 0.8292272858369403\n",
      "\n",
      "Loss 1:  0.04679244439355047\n",
      "Loss 2:  0.04662238296642479\n",
      "Error:  0.00017006142712568117\n",
      "\n",
      " 0.7823508780913733 0.8304808543323868\n",
      "\n",
      "Loss 1:  0.04662238296642479\n",
      "Loss 2:  0.046453469537823706\n",
      "Error:  0.00016891342860108488\n",
      "\n",
      " 0.7820048336513279 0.8317301845602567\n",
      "\n",
      "Loss 1:  0.046453469537823706\n",
      "Loss 2:  0.046285696358191006\n",
      "Error:  0.0001677731796327006\n",
      "\n",
      " 0.7816599591744203 0.8329752908499719\n",
      "\n",
      "Loss 1:  0.046285696358191006\n",
      "Loss 2:  0.046119055730283486\n",
      "Error:  0.00016664062790752027\n",
      "\n",
      " 0.7813162507050495 0.8342161874825073\n",
      "\n",
      "Loss 1:  0.046119055730283486\n",
      "Loss 2:  0.04595354000881843\n",
      "Error:  0.0001655157214650524\n",
      "\n",
      " 0.7809737043009882 0.8354528886905541\n",
      "\n",
      "Loss 1:  0.04595354000881843\n",
      "Loss 2:  0.045789141600122464\n",
      "Error:  0.00016439840869596906\n",
      "\n",
      " 0.7806323160333376 0.8366854086586838\n",
      "\n",
      "Loss 1:  0.045789141600122464\n",
      "Loss 2:  0.04562585296178309\n",
      "Error:  0.00016328863833937196\n",
      "\n",
      " 0.7802920819864823 0.8379137615235098\n",
      "\n",
      "Loss 1:  0.04562585296178309\n",
      "Loss 2:  0.045463666602303075\n",
      "Error:  0.00016218635948001686\n",
      "\n",
      " 0.7799529982580455 0.8391379613738507\n",
      "\n",
      "Loss 1:  0.045463666602303075\n",
      "Loss 2:  0.04530257508075637\n",
      "Error:  0.00016109152154670375\n",
      "\n",
      " 0.7796150609588445 0.840358022250891\n",
      "\n",
      "Loss 1:  0.04530257508075637\n",
      "Loss 2:  0.045142571006446634\n",
      "Error:  0.00016000407430973723\n",
      "\n",
      " 0.7792782662128452 0.8415739581483425\n",
      "\n",
      "Loss 1:  0.045142571006446634\n",
      "Loss 2:  0.04498364703856885\n",
      "Error:  0.00015892396787778318\n",
      "\n",
      " 0.7789426101571187 0.8427857830126049\n",
      "\n",
      "Loss 1:  0.04498364703856885\n",
      "Loss 2:  0.04482579588587164\n",
      "Error:  0.00015785115269720956\n",
      "\n",
      " 0.7786080889417963 0.8439935107429256\n",
      "\n",
      "Loss 1:  0.04482579588587164\n",
      "Loss 2:  0.04466901030632332\n",
      "Error:  0.00015678557954831862\n",
      "\n",
      " 0.7782746987300256 0.8451971551915594\n",
      "\n",
      "Loss 1:  0.04466901030632332\n",
      "Loss 2:  0.0445132831067795\n",
      "Error:  0.0001557271995438203\n",
      "\n",
      " 0.7779424356979264 0.8463967301639266\n",
      "\n",
      "Loss 1:  0.0445132831067795\n",
      "Loss 2:  0.044358607142653085\n",
      "Error:  0.00015467596412641754\n",
      "\n",
      " 0.777611296034547 0.8475922494187724\n",
      "\n",
      "Loss 1:  0.044358607142653085\n",
      "Loss 2:  0.044204975317586354\n",
      "Error:  0.0001536318250667315\n",
      "\n",
      " 0.7772812759418203 0.8487837266683241\n",
      "\n",
      "Loss 1:  0.044204975317586354\n",
      "Loss 2:  0.04405238058312565\n",
      "Error:  0.00015259473446070648\n",
      "\n",
      " 0.7769523716345204 0.8499711755784485\n",
      "\n",
      "Loss 1:  0.04405238058312565\n",
      "Loss 2:  0.043900815938397716\n",
      "Error:  0.00015156464472793063\n",
      "\n",
      " 0.776624579340219 0.8511546097688083\n",
      "\n",
      "Loss 1:  0.043900815938397716\n",
      "Loss 2:  0.043750274429788814\n",
      "Error:  0.00015054150860890209\n",
      "\n",
      " 0.7762978952992423 0.8523340428130189\n",
      "\n",
      "Loss 1:  0.043750274429788814\n",
      "Loss 2:  0.04360074915062538\n",
      "Error:  0.000149525279163433\n",
      "\n",
      " 0.7759723157646279 0.853509488238804\n",
      "\n",
      "Loss 1:  0.04360074915062538\n",
      "Loss 2:  0.04345223324085731\n",
      "Error:  0.00014851590976806828\n",
      "\n",
      " 0.7756478370020815 0.8546809595281503\n",
      "\n",
      "Loss 1:  0.04345223324085731\n",
      "Loss 2:  0.043304719886743274\n",
      "Error:  0.0001475133541140386\n",
      "\n",
      " 0.7753244552899345 0.8558484701174623\n",
      "\n",
      "Loss 1:  0.043304719886743274\n",
      "Loss 2:  0.0431582023205381\n",
      "Error:  0.0001465175662051718\n",
      "\n",
      " 0.7750021669191012 0.857012033397717\n",
      "\n",
      "Loss 1:  0.0431582023205381\n",
      "Loss 2:  0.043012673820182076\n",
      "Error:  0.00014552850035602638\n",
      "\n",
      " 0.7746809681930359 0.8581716627146166\n",
      "\n",
      "Loss 1:  0.043012673820182076\n",
      "Loss 2:  0.042868127708992905\n",
      "Error:  0.00014454611118917132\n",
      "\n",
      " 0.774360855427691 0.8593273713687422\n",
      "\n",
      "Loss 1:  0.042868127708992905\n",
      "Loss 2:  0.04272455735535907\n",
      "Error:  0.00014357035363383314\n",
      "\n",
      " 0.7740418249514744 0.8604791726157058\n",
      "\n",
      "Loss 1:  0.04272455735535907\n",
      "Loss 2:  0.04258195617243572\n",
      "Error:  0.00014260118292334922\n",
      "\n",
      " 0.7737238731052077 0.8616270796663033\n",
      "\n",
      "Loss 1:  0.04258195617243572\n",
      "Loss 2:  0.042440317617842435\n",
      "Error:  0.00014163855459328745\n",
      "\n",
      " 0.7734069962420839 0.8627711056866647\n",
      "\n",
      "Loss 1:  0.042440317617842435\n",
      "Loss 2:  0.042299635193363196\n",
      "Error:  0.00014068242447923957\n",
      "\n",
      " 0.7730911907276256 0.8639112637984063\n",
      "\n",
      "Loss 1:  0.042299635193363196\n",
      "Loss 2:  0.04215990244464808\n",
      "Error:  0.00013973274871511426\n",
      "\n",
      " 0.7727764529396435 0.8650475670787806\n",
      "\n",
      "Loss 1:  0.04215990244464808\n",
      "Loss 2:  0.04202111296091712\n",
      "Error:  0.00013878948373095834\n",
      "\n",
      " 0.7724627792681951 0.8661800285608264\n",
      "\n",
      "Loss 1:  0.04202111296091712\n",
      "Loss 2:  0.04188326037466634\n",
      "Error:  0.00013785258625078484\n",
      "\n",
      " 0.7721501661155425 0.8673086612335182\n",
      "\n",
      "Loss 1:  0.04188326037466634\n",
      "Loss 2:  0.041746338361375694\n",
      "Error:  0.00013692201329064402\n",
      "\n",
      " 0.7718386098961121 0.8684334780419153\n",
      "\n",
      "Loss 1:  0.041746338361375694\n",
      "Loss 2:  0.041610340639218535\n",
      "Error:  0.00013599772215715927\n",
      "\n",
      " 0.7715281070364525 0.8695544918873103\n",
      "\n",
      "Loss 1:  0.041610340639218535\n",
      "Loss 2:  0.041475260968773874\n",
      "Error:  0.00013507967044466135\n",
      "\n",
      " 0.7712186539751943 0.8706717156273769\n",
      "\n",
      "Loss 1:  0.041475260968773874\n",
      "Loss 2:  0.041341093152739664\n",
      "Error:  0.00013416781603420996\n",
      "\n",
      " 0.7709102471630089 0.8717851620763177\n",
      "\n",
      "Loss 1:  0.041341093152739664\n",
      "Loss 2:  0.041207831035648915\n",
      "Error:  0.00013326211709074887\n",
      "\n",
      " 0.7706028830625679 0.8728948440050108\n",
      "\n",
      "Loss 1:  0.041207831035648915\n",
      "Loss 2:  0.04107546850358692\n",
      "Error:  0.0001323625320619956\n",
      "\n",
      " 0.7702965581485023 0.8740007741411565\n",
      "\n",
      "Loss 1:  0.04107546850358692\n",
      "Loss 2:  0.04094399948391088\n",
      "Error:  0.0001314690196760407\n",
      "\n",
      " 0.7699912689073624 0.8751029651694232\n",
      "\n",
      "Loss 1:  0.04094399948391088\n",
      "Loss 2:  0.040813417944971606\n",
      "Error:  0.00013058153893927282\n",
      "\n",
      " 0.7696870118375773 0.876201429731593\n",
      "\n",
      "Loss 1:  0.040813417944971606\n",
      "Loss 2:  0.04068371789583621\n",
      "Error:  0.00012970004913539362\n",
      "\n",
      " 0.7693837834494147 0.8772961804267065\n",
      "\n",
      "Loss 1:  0.04068371789583621\n",
      "Loss 2:  0.04055489338601366\n",
      "Error:  0.00012882450982255184\n",
      "\n",
      " 0.7690815802649411 0.8783872298112075\n",
      "\n",
      "Loss 1:  0.04055489338601366\n",
      "Loss 2:  0.04042693850518175\n",
      "Error:  0.00012795488083190698\n",
      "\n",
      " 0.7687803988179817 0.8794745903990869\n",
      "\n",
      "Loss 1:  0.04042693850518175\n",
      "Loss 2:  0.04029984738291583\n",
      "Error:  0.0001270911222659224\n",
      "\n",
      " 0.7684802356540805 0.8805582746620263\n",
      "\n",
      "Loss 1:  0.04029984738291583\n",
      "Loss 2:  0.040173614188419436\n",
      "Error:  0.00012623319449639459\n",
      "\n",
      " 0.7681810873304612 0.8816382950295409\n",
      "\n",
      "Loss 1:  0.040173614188419436\n",
      "Loss 2:  0.0400482331302569\n",
      "Error:  0.00012538105816253808\n",
      "\n",
      " 0.7678829504159873 0.8827146638891225\n",
      "\n",
      "Loss 1:  0.0400482331302569\n",
      "Loss 2:  0.03992369845608759\n",
      "Error:  0.00012453467416930625\n",
      "\n",
      " 0.7675858214911228 0.8837873935863808\n",
      "\n",
      "Loss 1:  0.03992369845608759\n",
      "Loss 2:  0.039800004452402026\n",
      "Error:  0.00012369400368556632\n",
      "\n",
      " 0.7672896971478929 0.8848564964251858\n",
      "\n",
      "Loss 1:  0.039800004452402026\n",
      "Loss 2:  0.03967714544425984\n",
      "Error:  0.0001228590081421843\n",
      "\n",
      " 0.7669945739898453 0.8859219846678086\n",
      "\n",
      "Loss 1:  0.03967714544425984\n",
      "Loss 2:  0.039555115795029114\n",
      "Error:  0.0001220296492307274\n",
      "\n",
      " 0.7667004486320108 0.8869838705350617\n",
      "\n",
      "Loss 1:  0.039555115795029114\n",
      "Loss 2:  0.039433909906128065\n",
      "Error:  0.00012120588890104922\n",
      "\n",
      " 0.7664073177008647 0.8880421662064398\n",
      "\n",
      "Loss 1:  0.039433909906128065\n",
      "Loss 2:  0.03931352221676818\n",
      "Error:  0.00012038768935988126\n",
      "\n",
      " 0.7661151778342881 0.8890968838202592\n",
      "\n",
      "Loss 1:  0.03931352221676818\n",
      "Loss 2:  0.03919394720369881\n",
      "Error:  0.00011957501306937568\n",
      "\n",
      " 0.7658240256815292 0.8901480354737967\n",
      "\n",
      "Loss 1:  0.03919394720369881\n",
      "Loss 2:  0.039075179380954325\n",
      "Error:  0.00011876782274448244\n",
      "\n",
      " 0.765533857903165 0.891195633223429\n",
      "\n",
      "Loss 1:  0.039075179380954325\n",
      "Loss 2:  0.03895721329960162\n",
      "Error:  0.00011796608135270642\n",
      "\n",
      " 0.7652446711710629 0.8922396890847705\n",
      "\n",
      "Loss 1:  0.03895721329960162\n",
      "Loss 2:  0.03884004354749086\n",
      "Error:  0.00011716975211075592\n",
      "\n",
      " 0.7649564621683428 0.8932802150328113\n",
      "\n",
      "Loss 1:  0.03884004354749086\n",
      "Loss 2:  0.038723664749006924\n",
      "Error:  0.000116378798483939\n",
      "\n",
      " 0.7646692275893386 0.8943172230020545\n",
      "\n",
      "Loss 1:  0.038723664749006924\n",
      "Loss 2:  0.03860807156482253\n",
      "Error:  0.00011559318418439407\n",
      "\n",
      " 0.7643829641395609 0.8953507248866531\n",
      "\n",
      "Loss 1:  0.03860807156482253\n",
      "Loss 2:  0.038493258691653764\n",
      "Error:  0.00011481287316876532\n",
      "\n",
      " 0.7640976685356583 0.8963807325405464\n",
      "\n",
      "Loss 1:  0.038493258691653764\n",
      "Loss 2:  0.03837922086201616\n",
      "Error:  0.000114037829637606\n",
      "\n",
      " 0.7638133375053807 0.897407257777596\n",
      "\n",
      "Loss 1:  0.03837922086201616\n",
      "Loss 2:  0.038265952843983646\n",
      "Error:  0.00011326801803251269\n",
      "\n",
      " 0.7635299677875412 0.8984303123717212\n",
      "\n",
      "Loss 1:  0.038265952843983646\n",
      "Loss 2:  0.03815344944094807\n",
      "Error:  0.00011250340303557704\n",
      "\n",
      " 0.7632475561319789 0.8994499080570343\n",
      "\n",
      "Loss 1:  0.03815344944094807\n",
      "Loss 2:  0.03804170549138118\n",
      "Error:  0.00011174394956688788\n",
      "\n",
      " 0.7629660992995215 0.9004660565279748\n",
      "\n",
      "Loss 1:  0.03804170549138118\n",
      "Loss 2:  0.03793071586859724\n",
      "Error:  0.00011098962278394131\n",
      "\n",
      " 0.7626855940619482 0.901478769439444\n",
      "\n",
      "Loss 1:  0.03793071586859724\n",
      "Loss 2:  0.0378204754805185\n",
      "Error:  0.00011024038807874031\n",
      "\n",
      " 0.762406037201953 0.9024880584069382\n",
      "\n",
      "Loss 1:  0.0378204754805185\n",
      "Loss 2:  0.03771097926944097\n",
      "Error:  0.00010949621107753105\n",
      "\n",
      " 0.7621274255131071 0.9034939350066823\n",
      "\n",
      "Loss 1:  0.03771097926944097\n",
      "Loss 2:  0.03760222221180289\n",
      "Error:  0.00010875705763807586\n",
      "\n",
      " 0.7618497557998226 0.9044964107757623\n",
      "\n",
      "Loss 1:  0.03760222221180289\n",
      "Loss 2:  0.03749419931795391\n",
      "Error:  0.00010802289384898023\n",
      "\n",
      " 0.7615730248773159 0.9054954972122576\n",
      "\n",
      "Loss 1:  0.03749419931795391\n",
      "Loss 2:  0.03738690563192619\n",
      "Error:  0.0001072936860277221\n",
      "\n",
      " 0.761297229571571 0.9064912057753736\n",
      "\n",
      "Loss 1:  0.03738690563192619\n",
      "Loss 2:  0.037280336231207314\n",
      "Error:  0.00010656940071887555\n",
      "\n",
      " 0.7610223667193029 0.9074835478855718\n",
      "\n",
      "Loss 1:  0.037280336231207314\n",
      "Loss 2:  0.0371744862265142\n",
      "Error:  0.00010585000469311157\n",
      "\n",
      " 0.760748433167922 0.9084725349247023\n",
      "\n",
      "Loss 1:  0.0371744862265142\n",
      "Loss 2:  0.03706935076156865\n",
      "Error:  0.00010513546494555354\n",
      "\n",
      " 0.760475425775497 0.9094581782361328\n",
      "\n",
      "Loss 1:  0.03706935076156865\n",
      "Loss 2:  0.036964925012874926\n",
      "Error:  0.00010442574869372334\n",
      "\n",
      " 0.7602033414107197 0.9104404891248804\n",
      "\n",
      "Loss 1:  0.036964925012874926\n",
      "Loss 2:  0.03686120418949836\n",
      "Error:  0.00010372082337656297\n",
      "\n",
      " 0.7599321769528685 0.9114194788577397\n",
      "\n",
      "Loss 1:  0.03686120418949836\n",
      "Loss 2:  0.03675818353284512\n",
      "Error:  0.000103020656653241\n",
      "\n",
      " 0.759661929291773 0.9123951586634128\n",
      "\n",
      "Loss 1:  0.03675818353284512\n",
      "Loss 2:  0.03665585831644454\n",
      "Error:  0.00010232521640058528\n",
      "\n",
      " 0.7593925953277781 0.9133675397326382\n",
      "\n",
      "Loss 1:  0.03665585831644454\n",
      "Loss 2:  0.03655422384573192\n",
      "Error:  0.00010163447071261794\n",
      "\n",
      " 0.7591241719717087 0.9143366332183187\n",
      "\n",
      "Loss 1:  0.03655422384573192\n",
      "Loss 2:  0.03645327545783295\n",
      "Error:  0.00010094838789896643\n",
      "\n",
      " 0.7588566561448337 0.9153024502356498\n",
      "\n",
      "Loss 1:  0.03645327545783295\n",
      "Loss 2:  0.03635300852135038\n",
      "Error:  0.00010026693648257368\n",
      "\n",
      " 0.7585900447788313 0.9162650018622468\n",
      "\n",
      "Loss 1:  0.03635300852135038\n",
      "Loss 2:  0.03625341843615077\n",
      "Error:  9.959008519960788e-05\n",
      "\n",
      " 0.7583243348157536 0.917224299138272\n",
      "\n",
      "Loss 1:  0.03625341843615077\n",
      "Loss 2:  0.03615450063315429\n",
      "Error:  9.891780299647879e-05\n",
      "\n",
      " 0.7580595232079914 0.9181803530665613\n",
      "\n",
      "Loss 1:  0.03615450063315429\n",
      "Loss 2:  0.036056250574124274\n",
      "Error:  9.82500590300181e-05\n",
      "\n",
      " 0.7577956069182397 0.9191331746127506\n",
      "\n",
      "Loss 1:  0.036056250574124274\n",
      "Loss 2:  0.03595866375145966\n",
      "Error:  9.758682266461371e-05\n",
      "\n",
      " 0.7575325829194619 0.9200827747054012\n",
      "\n",
      "Loss 1:  0.03595866375145966\n",
      "Loss 2:  0.035861735687987686\n",
      "Error:  9.69280634719738e-05\n",
      "\n",
      " 0.7572704481948562 0.9210291642361255\n",
      "\n",
      "Loss 1:  0.035861735687987686\n",
      "Loss 2:  0.035765461936759016\n",
      "Error:  9.627375122867043e-05\n",
      "\n",
      " 0.7570091997378203 0.9219723540597116\n",
      "\n",
      "Loss 1:  0.035765461936759016\n",
      "Loss 2:  0.03566983808084297\n",
      "Error:  9.562385591604938e-05\n",
      "\n",
      " 0.7567488345519171 0.9229123549942481\n",
      "\n",
      "Loss 1:  0.03566983808084297\n",
      "Loss 2:  0.03557485973312587\n",
      "Error:  9.497834771709374e-05\n",
      "\n",
      " 0.7564893496508405 0.9238491778212481\n",
      "\n",
      "Loss 1:  0.03557485973312587\n",
      "Loss 2:  0.03548052253610873\n",
      "Error:  9.433719701714555e-05\n",
      "\n",
      " 0.7562307420583807 0.9247828332857727\n",
      "\n",
      "Loss 1:  0.03548052253610873\n",
      "Loss 2:  0.035386822161708145\n",
      "Error:  9.37003744005821e-05\n",
      "\n",
      " 0.7559730088083906 0.9257133320965544\n",
      "\n",
      "Loss 1:  0.035386822161708145\n",
      "Loss 2:  0.03529375431105734\n",
      "Error:  9.306785065080203e-05\n",
      "\n",
      " 0.7557161469447514 0.9266406849261198\n",
      "\n",
      "Loss 1:  0.03529375431105734\n",
      "Loss 2:  0.035201314714308964\n",
      "Error:  9.24395967483796e-05\n",
      "\n",
      " 0.7554601535213389 0.9275649024109124\n",
      "\n",
      "Loss 1:  0.035201314714308964\n",
      "Loss 2:  0.035109499130439106\n",
      "Error:  9.181558386985728e-05\n",
      "\n",
      " 0.7552050256019895 0.9284859951514138\n",
      "\n",
      "Loss 1:  0.035109499130439106\n",
      "Loss 2:  0.03501830334705318\n",
      "Error:  9.119578338592782e-05\n",
      "\n",
      " 0.754950760260467 0.9294039737122661\n",
      "\n",
      "Loss 1:  0.03501830334705318\n",
      "Loss 2:  0.03492772318019217\n",
      "Error:  9.058016686101095e-05\n",
      "\n",
      " 0.7546973545804283 0.9303188486223928\n",
      "\n",
      "Loss 1:  0.03492772318019217\n",
      "Loss 2:  0.03483775447414075\n",
      "Error:  8.996870605141455e-05\n",
      "\n",
      " 0.7544448056553905 0.9312306303751192\n",
      "\n",
      "Loss 1:  0.03483775447414075\n",
      "Loss 2:  0.03474839310123691\n",
      "Error:  8.936137290384283e-05\n",
      "\n",
      " 0.7541931105886974 0.9321393294282934\n",
      "\n",
      "Loss 1:  0.03474839310123691\n",
      "Loss 2:  0.034659634961682215\n",
      "Error:  8.875813955469547e-05\n",
      "\n",
      " 0.7539422664934864 0.9330449562044056\n",
      "\n",
      "Loss 1:  0.034659634961682215\n",
      "Loss 2:  0.03457147598335408\n",
      "Error:  8.815897832813169e-05\n",
      "\n",
      " 0.7536922704926551 0.9339475210907083\n",
      "\n",
      "Loss 1:  0.03457147598335408\n",
      "Loss 2:  0.034483912121618596\n",
      "Error:  8.756386173548736e-05\n",
      "\n",
      " 0.7534431197188285 0.9348470344393348\n",
      "\n",
      "Loss 1:  0.034483912121618596\n",
      "Loss 2:  0.03439693935914516\n",
      "Error:  8.697276247343622e-05\n",
      "\n",
      " 0.7531948113143261 0.9357435065674184\n",
      "\n",
      "Loss 1:  0.03439693935914516\n",
      "Loss 2:  0.034310553705722294\n",
      "Error:  8.638565342286575e-05\n",
      "\n",
      " 0.7529473424311293 0.9366369477572105\n",
      "\n",
      "Loss 1:  0.034310553705722294\n",
      "Loss 2:  0.03422475119807415\n",
      "Error:  8.580250764814168e-05\n",
      "\n",
      " 0.7527007102308482 0.9375273682561985\n",
      "\n",
      "Loss 1:  0.03422475119807415\n",
      "Loss 2:  0.03413952789967912\n",
      "Error:  8.522329839503323e-05\n",
      "\n",
      " 0.7524549118846896 0.9384147782772236\n",
      "\n",
      "Loss 1:  0.03413952789967912\n",
      "Loss 2:  0.03405487990058907\n",
      "Error:  8.4647999090047e-05\n",
      "\n",
      " 0.7522099445734245 0.9392991879985978\n",
      "\n",
      "Loss 1:  0.03405487990058907\n",
      "Loss 2:  0.033970803317249845\n",
      "Error:  8.407658333922652e-05\n",
      "\n",
      " 0.7519658054873553 0.9401806075642204\n",
      "\n",
      "Loss 1:  0.033970803317249845\n",
      "Loss 2:  0.03388729429232319\n",
      "Error:  8.350902492665346e-05\n",
      "\n",
      " 0.7517224918262838 0.9410590470836947\n",
      "\n",
      "Loss 1:  0.03388729429232319\n",
      "Loss 2:  0.03380434899450998\n",
      "Error:  8.294529781321253e-05\n",
      "\n",
      " 0.7514800007994796 0.9419345166324438\n",
      "\n",
      "Loss 1:  0.03380434899450998\n",
      "Loss 2:  0.033721963618374075\n",
      "Error:  8.238537613590446e-05\n",
      "\n",
      " 0.7512383296256475 0.9428070262518261\n",
      "\n",
      "Loss 1:  0.033721963618374075\n",
      "Loss 2:  0.03364013438416783\n",
      "Error:  8.182923420624322e-05\n",
      "\n",
      " 0.7509974755328955 0.9436765859492507\n",
      "\n",
      "Loss 1:  0.03364013438416783\n",
      "Loss 2:  0.03355885753765902\n",
      "Error:  8.127684650881262e-05\n",
      "\n",
      " 0.7507574357587035 0.944543205698292\n",
      "\n",
      "Loss 1:  0.03355885753765902\n",
      "Loss 2:  0.03347812934995812\n",
      "Error:  8.072818770089862e-05\n",
      "\n",
      " 0.7505182075498912 0.945406895438804\n",
      "\n",
      "Loss 1:  0.03347812934995812\n",
      "Loss 2:  0.03339794611734749\n",
      "Error:  8.01832326106297e-05\n",
      "\n",
      " 0.7502797881625869 0.9462676650770344\n",
      "\n",
      "Loss 1:  0.03339794611734749\n",
      "Loss 2:  0.033318304161111534\n",
      "Error:  7.964195623595682e-05\n",
      "\n",
      " 0.7500421748621957 0.9471255244857385\n",
      "\n",
      "Loss 1:  0.033318304161111534\n",
      "Loss 2:  0.03323919982736765\n",
      "Error:  7.91043337438832e-05\n",
      "\n",
      " 0.7498053649233684 0.947980483504292\n",
      "\n",
      "Loss 1:  0.03323919982736765\n",
      "Loss 2:  0.03316062948689882\n",
      "Error:  7.857034046883371e-05\n",
      "\n",
      " 0.7495693556299698 0.948832551938804\n",
      "\n",
      "Loss 1:  0.03316062948689882\n",
      "Loss 2:  0.03308258953498707\n",
      "Error:  7.803995191174584e-05\n",
      "\n",
      " 0.7493341442750482 0.9496817395622297\n",
      "\n",
      "Loss 1:  0.03308258953498707\n",
      "Loss 2:  0.03300507639124789\n",
      "Error:  7.751314373918156e-05\n",
      "\n",
      " 0.7490997281608038 0.9505280561144822\n",
      "\n",
      "Loss 1:  0.03300507639124789\n",
      "Loss 2:  0.03292808649946628\n",
      "Error:  7.698989178160642e-05\n",
      "\n",
      " 0.7488661045985581 0.9513715113025444\n",
      "\n",
      "Loss 1:  0.03292808649946628\n",
      "Loss 2:  0.03285161632743339\n",
      "Error:  7.647017203289003e-05\n",
      "\n",
      " 0.7486332709087227 0.95221211480058\n",
      "\n",
      "Loss 1:  0.03285161632743339\n",
      "Loss 2:  0.03277566236678469\n",
      "Error:  7.595396064870308e-05\n",
      "\n",
      " 0.7484012244207688 0.953049876250045\n",
      "\n",
      "Loss 1:  0.03277566236678469\n",
      "Loss 2:  0.03270022113283849\n",
      "Error:  7.544123394619823e-05\n",
      "\n",
      " 0.748169962473197 0.953884805259798\n",
      "\n",
      "Loss 1:  0.03270022113283849\n",
      "Loss 2:  0.03262528916443669\n",
      "Error:  7.49319684018035e-05\n",
      "\n",
      " 0.7479394824135058 0.9547169114062103\n",
      "\n",
      "Loss 1:  0.03262528916443669\n",
      "Loss 2:  0.032550863023785626\n",
      "Error:  7.442614065106268e-05\n",
      "\n",
      " 0.7477097815981619 0.9555462042332757\n",
      "\n",
      "Loss 1:  0.032550863023785626\n",
      "Loss 2:  0.03247693929629849\n",
      "Error:  7.392372748713655e-05\n",
      "\n",
      " 0.7474808573925698 0.9563726932527206\n",
      "\n",
      "Loss 1:  0.03247693929629849\n",
      "Loss 2:  0.03240351459043862\n",
      "Error:  7.34247058598661e-05\n",
      "\n",
      " 0.7472527071710412 0.957196387944112\n",
      "\n",
      "Loss 1:  0.03240351459043862\n",
      "Loss 2:  0.0323305855375638\n",
      "Error:  7.292905287482193e-05\n",
      "\n",
      " 0.7470253283167654 0.9580172977549672\n",
      "\n",
      "Loss 1:  0.0323305855375638\n",
      "Loss 2:  0.03225814879177193\n",
      "Error:  7.243674579186787e-05\n",
      "\n",
      " 0.7467987182217789 0.958835432100862\n",
      "\n",
      "Loss 1:  0.03225814879177193\n",
      "Loss 2:  0.03218620102974726\n",
      "Error:  7.194776202467529e-05\n",
      "\n",
      " 0.7465728742869359 0.959650800365538\n",
      "\n",
      "Loss 1:  0.03218620102974726\n",
      "Loss 2:  0.03211473895060816\n",
      "Error:  7.146207913909935e-05\n",
      "\n",
      " 0.7463477939218777 0.960463411901011\n",
      "\n",
      "Loss 1:  0.03211473895060816\n",
      "Loss 2:  0.03204375927575566\n",
      "Error:  7.097967485249906e-05\n",
      "\n",
      " 0.7461234745450039 0.9612732760276782\n",
      "\n",
      "Loss 1:  0.03204375927575566\n",
      "Loss 2:  0.03197325874872274\n",
      "Error:  7.050052703291843e-05\n",
      "\n",
      " 0.7458999135834423 0.9620804020344244\n",
      "\n",
      "Loss 1:  0.03197325874872274\n",
      "Loss 2:  0.03190323413502537\n",
      "Error:  7.002461369737256e-05\n",
      "\n",
      " 0.7456771084730195 0.9628847991787294\n",
      "\n",
      "Loss 1:  0.03190323413502537\n",
      "Loss 2:  0.031833682222013666\n",
      "Error:  6.9551913011702e-05\n",
      "\n",
      " 0.7454550566582314 0.9636864766867737\n",
      "\n",
      "Loss 1:  0.031833682222013666\n",
      "Loss 2:  0.03176459981872482\n",
      "Error:  6.908240328884485e-05\n",
      "\n",
      " 0.745233755592214 0.9644854437535443\n",
      "\n",
      "Loss 1:  0.03176459981872482\n",
      "Loss 2:  0.03169598375573658\n",
      "Error:  6.861606298824013e-05\n",
      "\n",
      " 0.7450132027367143 0.9652817095429406\n",
      "\n",
      "Loss 1:  0.03169598375573658\n",
      "Loss 2:  0.03162783088502203\n",
      "Error:  6.815287071455095e-05\n",
      "\n",
      " 0.7447933955620607 0.9660752831878789\n",
      "\n",
      "Loss 1:  0.03162783088502203\n",
      "Loss 2:  0.03156013807980469\n",
      "Error:  6.769280521733839e-05\n",
      "\n",
      " 0.7445743315471346 0.9668661737903977\n",
      "\n",
      "Loss 1:  0.03156013807980469\n",
      "Loss 2:  0.03149290223441548\n",
      "Error:  6.723584538920885e-05\n",
      "\n",
      " 0.7443560081793411 0.9676543904217617\n",
      "\n",
      "Loss 1:  0.03149290223441548\n",
      "Loss 2:  0.03142612026415019\n",
      "Error:  6.678197026529359e-05\n",
      "\n",
      " 0.7441384229545803 0.968439942122566\n",
      "\n",
      "Loss 1:  0.03142612026415019\n",
      "Loss 2:  0.0313597891051278\n",
      "Error:  6.633115902238834e-05\n",
      "\n",
      " 0.7439215733772186 0.9692228379028399\n",
      "\n",
      "Loss 1:  0.0313597891051278\n",
      "Loss 2:  0.03129390571415015\n",
      "Error:  6.588339097764878e-05\n",
      "\n",
      " 0.7437054569600602 0.97000308674215\n",
      "\n",
      "Loss 1:  0.03129390571415015\n",
      "Loss 2:  0.031228467068561933\n",
      "Error:  6.54386455882193e-05\n",
      "\n",
      " 0.743490071224318 0.9707806975897033\n",
      "\n",
      "Loss 1:  0.031228467068561933\n",
      "Loss 2:  0.03116347016611242\n",
      "Error:  6.499690244951215e-05\n",
      "\n",
      " 0.7432754136995858 0.9715556793644502\n",
      "\n",
      "Loss 1:  0.03116347016611242\n",
      "Loss 2:  0.031098912024817533\n",
      "Error:  6.455814129488827e-05\n",
      "\n",
      " 0.7430614819238099 0.972328040955186\n",
      "\n",
      "Loss 1:  0.031098912024817533\n",
      "Loss 2:  0.03103478968282299\n",
      "Error:  6.412234199454359e-05\n",
      "\n",
      " 0.7428482734432605 0.9730977912206537\n",
      "\n",
      "Loss 1:  0.03103478968282299\n",
      "Loss 2:  0.03097110019826853\n",
      "Error:  6.368948455445778e-05\n",
      "\n",
      " 0.742635785812504 0.973864938989645\n",
      "\n",
      "Loss 1:  0.03097110019826853\n",
      "Loss 2:  0.03090784064915289\n",
      "Error:  6.325954911564138e-05\n",
      "\n",
      " 0.7424240165943744 0.9746294930611018\n",
      "\n",
      "Loss 1:  0.03090784064915289\n",
      "Loss 2:  0.03084500813319991\n",
      "Error:  6.28325159529805e-05\n",
      "\n",
      " 0.7422129633599459 0.9753914622042174\n",
      "\n",
      "Loss 1:  0.03084500813319991\n",
      "Loss 2:  0.030782599767724933\n",
      "Error:  6.240836547497658e-05\n",
      "\n",
      " 0.7420026236885048 0.9761508551585363\n",
      "\n",
      "Loss 1:  0.030782599767724933\n",
      "Loss 2:  0.03072061268950302\n",
      "Error:  6.198707822191452e-05\n",
      "\n",
      " 0.7417929951675215 0.9769076806340553\n",
      "\n",
      "Loss 1:  0.03072061268950302\n",
      "Loss 2:  0.030659044054637496\n",
      "Error:  6.156863486552269e-05\n",
      "\n",
      " 0.7415840753926235 0.9776619473113229\n",
      "\n",
      "Loss 1:  0.030659044054637496\n",
      "Loss 2:  0.03059789103842913\n",
      "Error:  6.11530162083658e-05\n",
      "\n",
      " 0.7413758619675669 0.978413663841539\n",
      "\n",
      "Loss 1:  0.03059789103842913\n",
      "Loss 2:  0.03053715083524708\n",
      "Error:  6.0740203182051145e-05\n",
      "\n",
      " 0.7411683525042099 0.9791628388466542\n",
      "\n",
      "Loss 1:  0.03053715083524708\n",
      "Loss 2:  0.030476820658399746\n",
      "Error:  6.033017684733272e-05\n",
      "\n",
      " 0.7409615446224844 0.9799094809194685\n",
      "\n",
      "Loss 1:  0.030476820658399746\n",
      "Loss 2:  0.030416897740007116\n",
      "Error:  5.9922918392629754e-05\n",
      "\n",
      " 0.7407554359503697 0.98065359862373\n",
      "\n",
      "Loss 1:  0.030416897740007116\n",
      "Loss 2:  0.03035737933087366\n",
      "Error:  5.951840913345774e-05\n",
      "\n",
      " 0.7405500241238646 0.9813952004942332\n",
      "\n",
      "Loss 1:  0.03035737933087366\n",
      "Loss 2:  0.030298262700362382\n",
      "Error:  5.911663051127655e-05\n",
      "\n",
      " 0.7403453067869604 0.9821342950369167\n",
      "\n",
      "Loss 1:  0.030298262700362382\n",
      "Loss 2:  0.030239545136269315\n",
      "Error:  5.871756409306719e-05\n",
      "\n",
      " 0.7401412815916141 0.9828708907289607\n",
      "\n",
      "Loss 1:  0.030239545136269315\n",
      "Loss 2:  0.030181223944699402\n",
      "Error:  5.832119156991278e-05\n",
      "\n",
      " 0.7399379461977214 0.9836049960188846\n",
      "\n",
      "Loss 1:  0.030181223944699402\n",
      "Loss 2:  0.03012329644994255\n",
      "Error:  5.7927494756852826e-05\n",
      "\n",
      " 0.7397352982730896 0.9843366193266436\n",
      "\n",
      "Loss 1:  0.03012329644994255\n",
      "Loss 2:  0.03006575999435094\n",
      "Error:  5.753645559160997e-05\n",
      "\n",
      " 0.7395333354934113 0.9850657690437253\n",
      "\n",
      "Loss 1:  0.03006575999435094\n",
      "Loss 2:  0.030008611938217477\n",
      "Error:  5.714805613346238e-05\n",
      "\n",
      " 0.7393320555422372 0.9857924535332462\n",
      "\n",
      "Loss 1:  0.030008611938217477\n",
      "Loss 2:  0.029951849659654084\n",
      "Error:  5.676227856339297e-05\n",
      "\n",
      " 0.7391314561109502 0.986516681130047\n",
      "\n",
      "Loss 1:  0.029951849659654084\n",
      "Loss 2:  0.029895470554471885\n",
      "Error:  5.637910518219852e-05\n",
      "\n",
      " 0.7389315348987383 0.987238460140789\n",
      "\n",
      "Loss 1:  0.029895470554471885\n",
      "Loss 2:  0.029839472036061576\n",
      "Error:  5.5998518410309284e-05\n",
      "\n",
      " 0.7387322896125685 0.9879577988440489\n",
      "\n",
      "Loss 1:  0.029839472036061576\n",
      "Loss 2:  0.02978385153527468\n",
      "Error:  5.562050078689734e-05\n",
      "\n",
      " 0.7385337179671605 0.9886747054904138\n",
      "\n",
      "Loss 1:  0.02978385153527468\n",
      "Loss 2:  0.029728606500305853\n",
      "Error:  5.524503496882535e-05\n",
      "\n",
      " 0.7383358176849604 0.9893891883025759\n",
      "\n",
      "Loss 1:  0.029728606500305853\n",
      "Loss 2:  0.029673734396575436\n",
      "Error:  5.4872103730417565e-05\n",
      "\n",
      " 0.7381385864961145 0.9901012554754268\n",
      "\n",
      "Loss 1:  0.029673734396575436\n",
      "Loss 2:  0.029619232706613718\n",
      "Error:  5.450168996171817e-05\n",
      "\n",
      " 0.7379420221384437 0.9908109151761514\n",
      "\n",
      "Loss 1:  0.029619232706613718\n",
      "Loss 2:  0.029565098929944973\n",
      "Error:  5.4133776668744554e-05\n",
      "\n",
      " 0.737746122357417 0.9915181755443218\n",
      "\n",
      "Loss 1:  0.029565098929944973\n",
      "Loss 2:  0.029511330582973016\n",
      "Error:  5.376834697195729e-05\n",
      "\n",
      " 0.737550884906126 0.9922230446919903\n",
      "\n",
      "Loss 1:  0.029511330582973016\n",
      "Loss 2:  0.029457925198867134\n",
      "Error:  5.340538410588194e-05\n",
      "\n",
      " 0.7373563075452588 0.992925530703783\n",
      "\n",
      "Loss 1:  0.029457925198867134\n",
      "Loss 2:  0.029404880327448896\n",
      "Error:  5.304487141823827e-05\n",
      "\n",
      " 0.7371623880430749 0.9936256416369917\n",
      "\n",
      "Loss 1:  0.029404880327448896\n",
      "Loss 2:  0.02935219353507986\n",
      "Error:  5.2686792369034674e-05\n",
      "\n",
      " 0.7369691241753789 0.9943233855216674\n",
      "\n",
      "Loss 1:  0.02935219353507986\n",
      "Loss 2:  0.029299862404549827\n",
      "Error:  5.233113053003391e-05\n",
      "\n",
      " 0.7367765137254955 0.9950187703607114\n",
      "\n",
      "Loss 1:  0.029299862404549827\n",
      "Loss 2:  0.029247884534965858\n",
      "Error:  5.1977869583968994e-05\n",
      "\n",
      " 0.7365845544842438 0.9957118041299674\n",
      "\n",
      "Loss 1:  0.029247884534965858\n",
      "Loss 2:  0.029196257541642383\n",
      "Error:  5.162699332347462e-05\n",
      "\n",
      " 0.736393244249912 0.9964024947783134\n",
      "\n",
      "Loss 1:  0.029196257541642383\n",
      "Loss 2:  0.02914497905599143\n",
      "Error:  5.127848565095183e-05\n",
      "\n",
      " 0.7362025808282325 0.9970908502277525\n",
      "\n",
      "Loss 1:  0.02914497905599143\n",
      "Loss 2:  0.029094046725414463\n",
      "Error:  5.093233057696864e-05\n",
      "\n",
      " 0.7360125620323562 0.9977768783735035\n",
      "\n",
      "Loss 1:  0.029094046725414463\n",
      "Loss 2:  0.029043458213193825\n",
      "Error:  5.058851222063815e-05\n",
      "\n",
      " 0.7358231856828277 0.998460587084092\n",
      "\n",
      "Loss 1:  0.029043458213193825\n",
      "Loss 2:  0.02899321119838602\n",
      "Error:  5.024701480780408e-05\n",
      "\n",
      " 0.7356344496075601 0.9991419842014405\n",
      "\n",
      "Loss 1:  0.02899321119838602\n",
      "Loss 2:  0.028943303375715167\n",
      "Error:  4.990782267085339e-05\n",
      "\n",
      " 0.7354463516418104 0.9998210775409581\n",
      "\n",
      "Loss 1:  0.028943303375715167\n",
      "Loss 2:  0.028893732455466947\n",
      "Error:  4.957092024822016e-05\n",
      "\n",
      " 0.7352588896281546 1.0004978748916302\n",
      "\n",
      "Loss 1:  0.028893732455466947\n",
      "Loss 2:  0.02884449616338377\n",
      "Error:  4.92362920831782e-05\n",
      "\n",
      " 0.7350720614164628 1.0011723840161084\n",
      "\n",
      "Loss 1:  0.02884449616338377\n",
      "Loss 2:  0.028795592240560476\n",
      "Error:  4.890392282329292e-05\n",
      "\n",
      " 0.7348858648638744 1.0018446126507985\n",
      "\n",
      "Loss 1:  0.028795592240560476\n",
      "Loss 2:  0.028747018443340662\n",
      "Error:  4.857379721981414e-05\n",
      "\n",
      " 0.7347002978347741 1.00251456850595\n",
      "\n",
      "Loss 1:  0.028747018443340662\n",
      "Loss 2:  0.028698772543213562\n",
      "Error:  4.824590012710017e-05\n",
      "\n",
      " 0.7345153582007667 1.0031822592657444\n",
      "\n",
      "Loss 1:  0.028698772543213562\n",
      "Loss 2:  0.028650852326712162\n",
      "Error:  4.792021650140005e-05\n",
      "\n",
      " 0.7343310438406534 1.0038476925883835\n",
      "\n",
      "Loss 1:  0.028650852326712162\n",
      "Loss 2:  0.028603255595311173\n",
      "Error:  4.759673140098883e-05\n",
      "\n",
      " 0.7341473526404066 1.0045108761061765\n",
      "\n",
      "Loss 1:  0.028603255595311173\n",
      "Loss 2:  0.028555980165326768\n",
      "Error:  4.727542998440512e-05\n",
      "\n",
      " 0.7339642824931466 1.0051718174256286\n",
      "\n",
      "Loss 1:  0.028555980165326768\n",
      "Loss 2:  0.028509023867815682\n",
      "Error:  4.695629751108599e-05\n",
      "\n",
      " 0.7337818312991166 1.0058305241275272\n",
      "\n",
      "Loss 1:  0.028509023867815682\n",
      "Loss 2:  0.028462384548476494\n",
      "Error:  4.6639319339188134e-05\n",
      "\n",
      " 0.7335999969656593 1.0064870037670297\n",
      "\n",
      "Loss 1:  0.028462384548476494\n",
      "Loss 2:  0.02841606006755007\n",
      "Error:  4.632448092642405e-05\n",
      "\n",
      " 0.7334187774071924 1.0071412638737496\n",
      "\n",
      "Loss 1:  0.02841606006755007\n",
      "Loss 2:  0.028370048299721777\n",
      "Error:  4.601176782829258e-05\n",
      "\n",
      " 0.733238170545185 1.007793311951843\n",
      "\n",
      "Loss 1:  0.028370048299721777\n",
      "Loss 2:  0.028324347134024062\n",
      "Error:  4.570116569771465e-05\n",
      "\n",
      " 0.7330581743081337 1.008443155480095\n",
      "\n",
      "Loss 1:  0.028324347134024062\n",
      "Loss 2:  0.028278954473739255\n",
      "Error:  4.5392660284807734e-05\n",
      "\n",
      " 0.7328787866315386 1.009090801912005\n",
      "\n",
      "Loss 1:  0.028278954473739255\n",
      "Loss 2:  0.028233868236303618\n",
      "Error:  4.508623743563686e-05\n",
      "\n",
      " 0.7327000054578798 1.0097362586758727\n",
      "\n",
      "Loss 1:  0.028233868236303618\n",
      "Loss 2:  0.02818908635321179\n",
      "Error:  4.478188309182951e-05\n",
      "\n",
      " 0.7325218287365939 1.0103795331748824\n",
      "\n",
      "Loss 1:  0.02818908635321179\n",
      "Loss 2:  0.02814460676992176\n",
      "Error:  4.4479583290027436e-05\n",
      "\n",
      " 0.7323442544240503 1.0110206327871891\n",
      "\n",
      "Loss 1:  0.02814460676992176\n",
      "Loss 2:  0.0281004274457608\n",
      "Error:  4.417932416096032e-05\n",
      "\n",
      " 0.7321672804835279 1.0116595648660023\n",
      "\n",
      "Loss 1:  0.0281004274457608\n",
      "Loss 2:  0.028056546353831664\n",
      "Error:  4.3881091929137e-05\n",
      "\n",
      " 0.7319909048851916 1.0122963367396705\n",
      "\n",
      "Loss 1:  0.028056546353831664\n",
      "Loss 2:  0.02801296148091965\n",
      "Error:  4.3584872912012795e-05\n",
      "\n",
      " 0.7318151256060692 1.0129309557117656\n",
      "\n",
      "Loss 1:  0.02801296148091965\n",
      "Loss 2:  0.027969670827400317\n",
      "Error:  4.329065351933378e-05\n",
      "\n",
      " 0.731639940630028 1.0135634290611661\n",
      "\n",
      "Loss 1:  0.027969670827400317\n",
      "Loss 2:  0.027926672407147524\n",
      "Error:  4.2998420252793323e-05\n",
      "\n",
      " 0.7314653479477519 1.0141937640421412\n",
      "\n",
      "Loss 1:  0.027926672407147524\n",
      "Loss 2:  0.027883964247442643\n",
      "Error:  4.2708159704880205e-05\n",
      "\n",
      " 0.7312913455567179 1.0148219678844332\n",
      "\n",
      "Loss 1:  0.027883964247442643\n",
      "Loss 2:  0.027841544388883775\n",
      "Error:  4.2419858558868234e-05\n",
      "\n",
      " 0.731117931461174 1.0154480477933414\n",
      "\n",
      "Loss 1:  0.027841544388883775\n",
      "Loss 2:  0.027799410885295937\n",
      "Error:  4.213350358783785e-05\n",
      "\n",
      " 0.7309451036721152 1.016072010949804\n",
      "\n",
      "Loss 1:  0.027799410885295937\n",
      "Loss 2:  0.027757561803641806\n",
      "Error:  4.1849081654131426e-05\n",
      "\n",
      " 0.7307728602072616 1.016693864510481\n",
      "\n",
      "Loss 1:  0.027757561803641806\n",
      "Loss 2:  0.027715995223933133\n",
      "Error:  4.156657970867325e-05\n",
      "\n",
      " 0.7306011990910352 1.0173136156078357\n",
      "\n",
      "Loss 1:  0.027715995223933133\n",
      "Loss 2:  0.02767470923914229\n",
      "Error:  4.128598479084117e-05\n",
      "\n",
      " 0.7304301183545373 1.0179312713502169\n",
      "\n",
      "Loss 1:  0.02767470923914229\n",
      "Loss 2:  0.02763370195511524\n",
      "Error:  4.100728402705103e-05\n",
      "\n",
      " 0.730259616035526 1.0185468388219403\n",
      "\n",
      "Loss 1:  0.02763370195511524\n",
      "Loss 2:  0.027592971490484286\n",
      "Error:  4.073046463095448e-05\n",
      "\n",
      " 0.7300896901783939 1.0191603250833698\n",
      "\n",
      "Loss 1:  0.027592971490484286\n",
      "Loss 2:  0.02755251597658202\n",
      "Error:  4.045551390226623e-05\n",
      "\n",
      " 0.729920338834145 1.019771737170999\n",
      "\n",
      "Loss 1:  0.02755251597658202\n",
      "Loss 2:  0.027512333557355335\n",
      "Error:  4.0182419226684335e-05\n",
      "\n",
      " 0.7297515600603731 1.0203810820975303\n",
      "\n",
      "Loss 1:  0.027512333557355335\n",
      "Loss 2:  0.02747242238928051\n",
      "Error:  3.9911168074825004e-05\n",
      "\n",
      " 0.7295833519212392 1.0209883668519573\n",
      "\n",
      "Loss 1:  0.02747242238928051\n",
      "Loss 2:  0.02743278064127843\n",
      "Error:  3.9641748002080396e-05\n",
      "\n",
      " 0.7294157124874492 1.0215935983996438\n",
      "\n",
      "Loss 1:  0.02743278064127843\n",
      "Loss 2:  0.02739340649463065\n",
      "Error:  3.9374146647778996e-05\n",
      "\n",
      " 0.7292486398362318 1.022196783682404\n",
      "\n",
      "Loss 1:  0.02739340649463065\n",
      "Loss 2:  0.027354298142896128\n",
      "Error:  3.9108351734522956e-05\n",
      "\n",
      " 0.7290821320513166 1.022797929618582\n",
      "\n",
      "Loss 1:  0.027354298142896128\n",
      "Loss 2:  0.02731545379182797\n",
      "Error:  3.884435106815687e-05\n",
      "\n",
      " 0.728916187222912 1.0233970431031314\n",
      "\n",
      "Loss 1:  0.02731545379182797\n",
      "Loss 2:  0.027276871659291484\n",
      "Error:  3.858213253648754e-05\n",
      "\n",
      " 0.7287508034476834 1.023994131007694\n",
      "\n",
      "Loss 1:  0.027276871659291484\n",
      "Loss 2:  0.027238549975182318\n",
      "Error:  3.832168410916603e-05\n",
      "\n",
      " 0.7285859788287314 1.0245892001806791\n",
      "\n",
      "Loss 1:  0.027238549975182318\n",
      "Loss 2:  0.02720048698134503\n",
      "Error:  3.806299383728867e-05\n",
      "\n",
      " 0.7284217114755698 1.0251822574473417\n",
      "\n",
      "Loss 1:  0.02720048698134503\n",
      "Loss 2:  0.0271626809314926\n",
      "Error:  3.780604985242908e-05\n",
      "\n",
      " 0.7282579995041039 1.0257733096098607\n",
      "\n",
      "Loss 1:  0.0271626809314926\n",
      "Loss 2:  0.027125130091126454\n",
      "Error:  3.7550840366145505e-05\n",
      "\n",
      " 0.7280948410366094 1.0263623634474173\n",
      "\n",
      "Loss 1:  0.027125130091126454\n",
      "Loss 2:  0.027087832737456692\n",
      "Error:  3.729735366976225e-05\n",
      "\n",
      " 0.7279322342017103 1.0269494257162723\n",
      "\n",
      "Loss 1:  0.027087832737456692\n",
      "Loss 2:  0.027050787159323082\n",
      "Error:  3.704557813360987e-05\n",
      "\n",
      " 0.7277701771343577 1.0275345031498442\n",
      "\n",
      "Loss 1:  0.027050787159323082\n",
      "Loss 2:  0.027013991657116414\n",
      "Error:  3.67955022066678e-05\n",
      "\n",
      " 0.7276086679758083 1.028117602458786\n",
      "\n",
      "Loss 1:  0.027013991657116414\n",
      "Loss 2:  0.02697744454270095\n",
      "Error:  3.654711441546457e-05\n",
      "\n",
      " 0.7274477048736033 1.0286987303310617\n",
      "\n",
      "Loss 1:  0.02697744454270095\n",
      "Loss 2:  0.026941144139336553\n",
      "Error:  3.6300403364396966e-05\n",
      "\n",
      " 0.7272872859815469 1.0292778934320244\n",
      "\n",
      "Loss 1:  0.026941144139336553\n",
      "Loss 2:  0.026905088781601926\n",
      "Error:  3.605535773462676e-05\n",
      "\n",
      " 0.7271274094596851 1.029855098404491\n",
      "\n",
      "Loss 1:  0.026905088781601926\n",
      "Loss 2:  0.026869276815318165\n",
      "Error:  3.5811966283761515e-05\n",
      "\n",
      " 0.7269680734742849 1.03043035186882\n",
      "\n",
      "Loss 1:  0.026869276815318165\n",
      "Loss 2:  0.026833706597472844\n",
      "Error:  3.55702178453203e-05\n",
      "\n",
      " 0.726809276197813 1.0310036604229866\n",
      "\n",
      "Loss 1:  0.026833706597472844\n",
      "Loss 2:  0.026798376496144895\n",
      "Error:  3.533010132794959e-05\n",
      "\n",
      " 0.7266510158089149 1.031575030642658\n",
      "\n",
      "Loss 1:  0.026798376496144895\n",
      "Loss 2:  0.0267632848904293\n",
      "Error:  3.509160571559325e-05\n",
      "\n",
      " 0.7264932904923941 1.03214446908127\n",
      "\n",
      "Loss 1:  0.0267632848904293\n",
      "Loss 2:  0.02672843017036299\n",
      "Error:  3.485472006631296e-05\n",
      "\n",
      " 0.7263360984391912 1.032711982270101\n",
      "\n",
      "Loss 1:  0.02672843017036299\n",
      "Loss 2:  0.02669381073685107\n",
      "Error:  3.461943351191696e-05\n",
      "\n",
      " 0.7261794378463631 1.0332775767183475\n",
      "\n",
      "Loss 1:  0.02669381073685107\n",
      "Loss 2:  0.02665942500159304\n",
      "Error:  3.43857352580329e-05\n",
      "\n",
      " 0.7260233069170623 1.033841258913199\n",
      "\n",
      "Loss 1:  0.02665942500159304\n",
      "Loss 2:  0.026625271387010613\n",
      "Error:  3.415361458242519e-05\n",
      "\n",
      " 0.7258677038605167 1.0344030353199112\n",
      "\n",
      "Loss 1:  0.026625271387010613\n",
      "Loss 2:  0.02659134832617472\n",
      "Error:  3.3923060835893554e-05\n",
      "\n",
      " 0.7257126268920083 1.034962912381882\n",
      "\n",
      "Loss 1:  0.02659134832617472\n",
      "Loss 2:  0.02655765426273366\n",
      "Error:  3.369406344105874e-05\n",
      "\n",
      " 0.7255580742328536 1.0355208965207239\n",
      "\n",
      "Loss 1:  0.02655765426273366\n",
      "Loss 2:  0.0265241876508422\n",
      "Error:  3.346661189146047e-05\n",
      "\n",
      " 0.7254040441103823 1.0360769941363381\n",
      "\n",
      "Loss 1:  0.0265241876508422\n",
      "Loss 2:  0.026490946955090133\n",
      "Error:  3.324069575206742e-05\n",
      "\n",
      " 0.7252505347579179 1.0366312116069885\n",
      "\n",
      "Loss 1:  0.026490946955090133\n",
      "Loss 2:  0.02645793065043208\n",
      "Error:  3.301630465805255e-05\n",
      "\n",
      " 0.7250975444147566 1.0371835552893736\n",
      "\n",
      "Loss 1:  0.02645793065043208\n",
      "Loss 2:  0.02642513722211746\n",
      "Error:  3.2793428314619594e-05\n",
      "\n",
      " 0.7249450713261477 1.0377340315187007\n",
      "\n",
      "Loss 1:  0.02642513722211746\n",
      "Loss 2:  0.026392565165620975\n",
      "Error:  3.257205649648612e-05\n",
      "\n",
      " 0.7247931137432732 1.0382826466087578\n",
      "\n",
      "Loss 1:  0.026392565165620975\n",
      "Loss 2:  0.026360212986573733\n",
      "Error:  3.235217904724169e-05\n",
      "\n",
      " 0.7246416699232275 1.0388294068519863\n",
      "\n",
      "Loss 1:  0.026360212986573733\n",
      "Loss 2:  0.02632807920069441\n",
      "Error:  3.2133785879323584e-05\n",
      "\n",
      " 0.7244907381289983 1.039374318519553\n",
      "\n",
      "Loss 1:  0.02632807920069441\n",
      "Loss 2:  0.02629616233372143\n",
      "Error:  3.191686697297941e-05\n",
      "\n",
      " 0.7243403166294455 1.039917387861422\n",
      "\n",
      "Loss 1:  0.02629616233372143\n",
      "Loss 2:  0.026264460921345135\n",
      "Error:  3.170141237629487e-05\n",
      "\n",
      " 0.7241904036992822 1.0404586211064268\n",
      "\n",
      "Loss 1:  0.026264460921345135\n",
      "Loss 2:  0.02623297350914073\n",
      "Error:  3.1487412204406207e-05\n",
      "\n",
      " 0.7240409976190545 1.0409980244623414\n",
      "\n",
      "Loss 1:  0.02623297350914073\n",
      "Loss 2:  0.02620169865250151\n",
      "Error:  3.127485663921917e-05\n",
      "\n",
      " 0.723892096675122 1.0415356041159511\n",
      "\n",
      "Loss 1:  0.02620169865250151\n",
      "Loss 2:  0.026170634916572556\n",
      "Error:  3.1063735928954506e-05\n",
      "\n",
      " 0.7237436991596381 1.0420713662331247\n",
      "\n",
      "Loss 1:  0.026170634916572556\n",
      "Loss 2:  0.026139780876184838\n",
      "Error:  3.0854040387717774e-05\n",
      "\n",
      " 0.7235958033705302 1.0426053169588838\n",
      "\n",
      "Loss 1:  0.026139780876184838\n",
      "Loss 2:  0.026109135115790112\n",
      "Error:  3.0645760394725635e-05\n",
      "\n",
      " 0.7234484076114805 1.0431374624174743\n",
      "\n",
      "Loss 1:  0.026109135115790112\n",
      "Loss 2:  0.0260786962293957\n",
      "Error:  3.0438886394413417e-05\n",
      "\n",
      " 0.7233015101919064 1.043667808712436\n",
      "\n",
      "Loss 1:  0.0260786962293957\n",
      "Loss 2:  0.02604846282049994\n",
      "Error:  3.0233408895758568e-05\n",
      "\n",
      " 0.7231551094269408 1.044196361926673\n",
      "\n",
      "Loss 1:  0.02604846282049994\n",
      "Loss 2:  0.02601843350202841\n",
      "Error:  3.0029318471531258e-05\n",
      "\n",
      " 0.7230092036374135 1.044723128122523\n",
      "\n",
      "Loss 1:  0.02601843350202841\n",
      "Loss 2:  0.025988606896270132\n",
      "Error:  2.982660575827703e-05\n",
      "\n",
      " 0.7228637911498311 1.0452481133418279\n",
      "\n",
      "Loss 1:  0.025988606896270132\n",
      "Loss 2:  0.025958981634814138\n",
      "Error:  2.9625261455994145e-05\n",
      "\n",
      " 0.7227188702963586 1.0457713236060016\n",
      "\n",
      "Loss 1:  0.025958981634814138\n",
      "Loss 2:  0.025929556358487177\n",
      "Error:  2.9425276326960903e-05\n",
      "\n",
      " 0.7225744394147996 1.0462927649161\n",
      "\n",
      "Loss 1:  0.025929556358487177\n",
      "Loss 2:  0.025900329717291032\n",
      "Error:  2.9226641196145042e-05\n",
      "\n",
      " 0.7224304968485776 1.04681244325289\n",
      "\n",
      "Loss 1:  0.025900329717291032\n",
      "Loss 2:  0.025871300370340456\n",
      "Error:  2.902934695057577e-05\n",
      "\n",
      " 0.7222870409467171 1.0473303645769176\n",
      "\n",
      "Loss 1:  0.025871300370340456\n",
      "Loss 2:  0.025842466985802004\n",
      "Error:  2.8833384538452106e-05\n",
      "\n",
      " 0.7221440700638243 1.0478465348285761\n",
      "\n",
      "Loss 1:  0.025842466985802004\n",
      "Loss 2:  0.025813828240832705\n",
      "Error:  2.8638744969299024e-05\n",
      "\n",
      " 0.7220015825600684 1.0483609599281751\n",
      "\n",
      "Loss 1:  0.025813828240832705\n",
      "Loss 2:  0.025785382821519525\n",
      "Error:  2.844541931317987e-05\n",
      "\n",
      " 0.7218595768011629 1.0488736457760075\n",
      "\n",
      "Loss 1:  0.025785382821519525\n",
      "Loss 2:  0.02575712942281891\n",
      "Error:  2.8253398700616578e-05\n",
      "\n",
      " 0.7217180511583465 1.0493845982524175\n",
      "\n",
      "Loss 1:  0.02575712942281891\n",
      "Loss 2:  0.025729066748496898\n",
      "Error:  2.806267432201026e-05\n",
      "\n",
      " 0.7215770040083652 1.0498938232178683\n",
      "\n",
      "Loss 1:  0.025729066748496898\n",
      "Loss 2:  0.025701193511069954\n",
      "Error:  2.7873237426943864e-05\n",
      "\n",
      " 0.7214364337334528 1.050401326513009\n",
      "\n",
      "Loss 1:  0.025701193511069954\n",
      "Loss 2:  0.02567350843174554\n",
      "Error:  2.7685079324414608e-05\n",
      "\n",
      " 0.7212963387213126 1.0509071139587416\n",
      "\n",
      "Loss 1:  0.02567350843174554\n",
      "Loss 2:  0.02564601024036367\n",
      "Error:  2.7498191381869486e-05\n",
      "\n",
      " 0.7211567173650993 1.051411191356288\n",
      "\n",
      "Loss 1:  0.02564601024036367\n",
      "Loss 2:  0.02561869767533854\n",
      "Error:  2.7312565025128938e-05\n",
      "\n",
      " 0.7210175680634002 1.0519135644872564\n",
      "\n",
      "Loss 1:  0.02561869767533854\n",
      "Loss 2:  0.025591569483600633\n",
      "Error:  2.7128191737908064e-05\n",
      "\n",
      " 0.7208788892202168 1.0524142391137072\n",
      "\n",
      "Loss 1:  0.025591569483600633\n",
      "Loss 2:  0.025564624420539344\n",
      "Error:  2.694506306128927e-05\n",
      "\n",
      " 0.7207406792449467 1.0529132209782202\n",
      "\n",
      "Loss 1:  0.025564624420539344\n",
      "Loss 2:  0.025537861249945715\n",
      "Error:  2.6763170593628594e-05\n",
      "\n",
      " 0.7206029365523652 1.053410515803959\n",
      "\n",
      "Loss 1:  0.025537861249945715\n",
      "Loss 2:  0.025511278743955916\n",
      "Error:  2.658250598979936e-05\n",
      "\n",
      " 0.7204656595626073 1.053906129294738\n",
      "\n",
      "Loss 1:  0.025511278743955916\n",
      "Loss 2:  0.02548487568299475\n",
      "Error:  2.6403060961164432e-05\n",
      "\n",
      " 0.7203288467011494 1.0544000671350868\n",
      "\n",
      "Loss 1:  0.02548487568299475\n",
      "Loss 2:  0.0254586508557198\n",
      "Error:  2.6224827274951706e-05\n",
      "\n",
      " 0.7201924963987913 1.054892334990316\n",
      "\n",
      "Loss 1:  0.0254586508557198\n",
      "Loss 2:  0.02543260305896562\n",
      "Error:  2.6047796754181257e-05\n",
      "\n",
      " 0.7200566070916383 1.0553829385065823\n",
      "\n",
      "Loss 1:  0.02543260305896562\n",
      "Loss 2:  0.025406731097689005\n",
      "Error:  2.587196127661409e-05\n",
      "\n",
      " 0.719921177221083 1.0558718833109524\n",
      "\n",
      "Loss 1:  0.025406731097689005\n",
      "Loss 2:  0.025381033784913586\n",
      "Error:  2.5697312775418285e-05\n",
      "\n",
      " 0.7197862052337876 1.0563591750114683\n",
      "\n",
      "Loss 1:  0.025381033784913586\n",
      "Loss 2:  0.02535550994167603\n",
      "Error:  2.5523843237555688e-05\n",
      "\n",
      " 0.7196516895816663 1.0568448191972117\n",
      "\n",
      "Loss 1:  0.02535550994167603\n",
      "Loss 2:  0.025330158396971232\n",
      "Error:  2.5351544704798473e-05\n",
      "\n",
      " 0.719517628721867 1.0573288214383676\n",
      "\n",
      "Loss 1:  0.025330158396971232\n",
      "Loss 2:  0.02530497798769915\n",
      "Error:  2.518040927208115e-05\n",
      "\n",
      " 0.7193840211167541 1.0578111872862883\n",
      "\n",
      "Loss 1:  0.02530497798769915\n",
      "Loss 2:  0.025279967558611182\n",
      "Error:  2.501042908796894e-05\n",
      "\n",
      " 0.7192508652338909 1.0582919222735574\n",
      "\n",
      "Loss 1:  0.025279967558611182\n",
      "Loss 2:  0.025255125962257256\n",
      "Error:  2.4841596353925716e-05\n",
      "\n",
      " 0.7191181595460214 1.0587710319140529\n",
      "\n",
      "Loss 1:  0.025255125962257256\n",
      "Loss 2:  0.025230452058933085\n",
      "Error:  2.467390332417177e-05\n",
      "\n",
      " 0.7189859025310535 1.0592485217030105\n",
      "\n",
      "Loss 1:  0.025230452058933085\n",
      "Loss 2:  0.025205944716628004\n",
      "Error:  2.4507342305080115e-05\n",
      "\n",
      " 0.7188540926720411 1.059724397117087\n",
      "\n",
      "Loss 1:  0.025205944716628004\n",
      "Loss 2:  0.025181602810973\n",
      "Error:  2.434190565500302e-05\n",
      "\n",
      " 0.7187227284571669 1.060198663614423\n",
      "\n",
      "Loss 1:  0.025181602810973\n",
      "Loss 2:  0.025157425225189167\n",
      "Error:  2.417758578383486e-05\n",
      "\n",
      " 0.7185918083797248 1.0606713266347045\n",
      "\n",
      "Loss 1:  0.025157425225189167\n",
      "Loss 2:  0.0251334108500361\n",
      "Error:  2.401437515306762e-05\n",
      "\n",
      " 0.718461330938103 1.0611423915992269\n",
      "\n",
      "Loss 1:  0.0251334108500361\n",
      "Loss 2:  0.025109558583761692\n",
      "Error:  2.385226627440659e-05\n",
      "\n",
      " 0.7183312946357667 1.0616118639109562\n",
      "\n",
      "Loss 1:  0.025109558583761692\n",
      "Loss 2:  0.025085867332050933\n",
      "Error:  2.369125171075917e-05\n",
      "\n",
      " 0.7182016979812407 1.062079748954591\n",
      "\n",
      "Loss 1:  0.025085867332050933\n",
      "Loss 2:  0.025062336007976204\n",
      "Error:  2.3531324074729104e-05\n",
      "\n",
      " 0.7180725394880922 1.0625460520966248\n",
      "\n",
      "Loss 1:  0.025062336007976204\n",
      "Loss 2:  0.02503896353194705\n",
      "Error:  2.3372476029154265e-05\n",
      "\n",
      " 0.7179438176749144 1.0630107786854068\n",
      "\n",
      "Loss 1:  0.02503896353194705\n",
      "Loss 2:  0.0250157488316607\n",
      "Error:  2.321470028635031e-05\n",
      "\n",
      " 0.7178155310653088 1.0634739340512038\n",
      "\n",
      "Loss 1:  0.0250157488316607\n",
      "Loss 2:  0.024992690842053158\n",
      "Error:  2.3057989607541685e-05\n",
      "\n",
      " 0.7176876781878686 1.0639355235062613\n",
      "\n",
      "Loss 1:  0.024992690842053158\n",
      "Loss 2:  0.024969788505250005\n",
      "Error:  2.2902336803153067e-05\n",
      "\n",
      " 0.7175602575761618 1.064395552344864\n",
      "\n",
      "Loss 1:  0.024969788505250005\n",
      "Loss 2:  0.02494704077051803\n",
      "Error:  2.2747734731973224e-05\n",
      "\n",
      " 0.7174332677687144 1.0648540258433972\n",
      "\n",
      "Loss 1:  0.02494704077051803\n",
      "Loss 2:  0.024924446594216963\n",
      "Error:  2.2594176301068275e-05\n",
      "\n",
      " 0.7173067073089934 1.0653109492604063\n",
      "\n",
      "Loss 1:  0.024924446594216963\n",
      "Loss 2:  0.02490200493975169\n",
      "Error:  2.2441654465271688e-05\n",
      "\n",
      " 0.7171805747453904 1.0657663278366585\n",
      "\n",
      "Loss 1:  0.02490200493975169\n",
      "Loss 2:  0.02487971477752455\n",
      "Error:  2.229016222714264e-05\n",
      "\n",
      " 0.717054868631205 1.0662201667952018\n",
      "\n",
      "Loss 1:  0.02487971477752455\n",
      "Loss 2:  0.024857575084888218\n",
      "Error:  2.2139692636331115e-05\n",
      "\n",
      " 0.7169295875246278 1.0666724713414255\n",
      "\n",
      "Loss 1:  0.024857575084888218\n",
      "Loss 2:  0.024835584846098695\n",
      "Error:  2.1990238789522387e-05\n",
      "\n",
      " 0.7168047299887241 1.0671232466631193\n",
      "\n",
      "Loss 1:  0.024835584846098695\n",
      "Loss 2:  0.024813743052268893\n",
      "Error:  2.1841793829802114e-05\n",
      "\n",
      " 0.7166802945914177 1.0675724979305334\n",
      "\n",
      "Loss 1:  0.024813743052268893\n",
      "Loss 2:  0.024792048701321966\n",
      "Error:  2.1694350946926955e-05\n",
      "\n",
      " 0.7165562799054738 1.0680202302964377\n",
      "\n",
      "Loss 1:  0.024792048701321966\n",
      "Loss 2:  0.024770500797945808\n",
      "Error:  2.1547903376158833e-05\n",
      "\n",
      " 0.7164326845084833 1.0684664488961806\n",
      "\n",
      "Loss 1:  0.024770500797945808\n",
      "Loss 2:  0.02474909835354707\n",
      "Error:  2.1402444398736786e-05\n",
      "\n",
      " 0.7163095069828461 1.068911158847748\n",
      "\n",
      "Loss 1:  0.02474909835354707\n",
      "Loss 2:  0.024727840386205843\n",
      "Error:  2.1257967341228173e-05\n",
      "\n",
      " 0.716186745915755 1.0693543652518223\n",
      "\n",
      "Loss 1:  0.024727840386205843\n",
      "Loss 2:  0.024706725920630744\n",
      "Error:  2.1114465575098468e-05\n",
      "\n",
      " 0.7160643998991796 1.0697960731918406\n",
      "\n",
      "Loss 1:  0.024706725920630744\n",
      "Loss 2:  0.024685753988114165\n",
      "Error:  2.0971932516579417e-05\n",
      "\n",
      " 0.7159424675298497 1.070236287734053\n",
      "\n",
      "Loss 1:  0.024685753988114165\n",
      "Loss 2:  0.024664923626487416\n",
      "Error:  2.083036162674884e-05\n",
      "\n",
      " 0.7158209474092396 1.070675013927581\n",
      "\n",
      "Loss 1:  0.024664923626487416\n",
      "Loss 2:  0.024644233880077433\n",
      "Error:  2.068974640998325e-05\n",
      "\n",
      " 0.715699838143552 1.0711122568044749\n",
      "\n",
      "Loss 1:  0.024644233880077433\n",
      "Loss 2:  0.02462368379966189\n",
      "Error:  2.0550080415543404e-05\n",
      "\n",
      " 0.715579138343702 1.0715480213797723\n",
      "\n",
      "Loss 1:  0.02462368379966189\n",
      "Loss 2:  0.02460327244242655\n",
      "Error:  2.041135723533996e-05\n",
      "\n",
      " 0.7154588466253012 1.0719823126515549\n",
      "\n",
      "Loss 1:  0.02460327244242655\n",
      "Loss 2:  0.024582998871921592\n",
      "Error:  2.0273570504956984e-05\n",
      "\n",
      " 0.7153389616086416 1.0724151356010057\n",
      "\n",
      "Loss 1:  0.024582998871921592\n",
      "Loss 2:  0.02456286215801844\n",
      "Error:  2.013671390315233e-05\n",
      "\n",
      " 0.7152194819186801 1.072846495192467\n",
      "\n",
      "Loss 1:  0.02456286215801844\n",
      "Loss 2:  0.02454286137686769\n",
      "Error:  2.0000781150750907e-05\n",
      "\n",
      " 0.7151004061850225 1.0732763963734968\n",
      "\n",
      "Loss 1:  0.02454286137686769\n",
      "Loss 2:  0.024522995610856052\n",
      "Error:  1.986576601163692e-05\n",
      "\n",
      " 0.7149817330419077 1.0737048440749255\n",
      "\n",
      "Loss 1:  0.024522995610856052\n",
      "Loss 2:  0.024503263948564773\n",
      "Error:  1.9731662291279373e-05\n",
      "\n",
      " 0.7148634611281924 1.0741318432109126\n",
      "\n",
      "Loss 1:  0.024503263948564773\n",
      "Loss 2:  0.024483665484727673\n",
      "Error:  1.9598463837099817e-05\n",
      "\n",
      " 0.7147455890873353 1.074557398679003\n",
      "\n",
      "Loss 1:  0.024483665484727673\n",
      "Loss 2:  0.02446419932018935\n",
      "Error:  1.9466164538323172e-05\n",
      "\n",
      " 0.7146281155673814 1.0749815153601827\n",
      "\n",
      "Loss 1:  0.02446419932018935\n",
      "Loss 2:  0.024444864561864482\n",
      "Error:  1.93347583248675e-05\n",
      "\n",
      " 0.7145110392209465 1.0754041981189362\n",
      "\n",
      "Loss 1:  0.024444864561864482\n",
      "Loss 2:  0.02442566032269606\n",
      "Error:  1.920423916842301e-05\n",
      "\n",
      " 0.7143943587052021 1.0758254518033006\n",
      "\n",
      "Loss 1:  0.02442566032269606\n",
      "Loss 2:  0.02440658572161554\n",
      "Error:  1.907460108051956e-05\n",
      "\n",
      " 0.7142780726818596 1.0762452812449224\n",
      "\n",
      "Loss 1:  0.02440658572161554\n",
      "Loss 2:  0.024387639883501847\n",
      "Error:  1.894583811369241e-05\n",
      "\n",
      " 0.7141621798171551 1.0766636912591123\n",
      "\n",
      "Loss 1:  0.024387639883501847\n",
      "Loss 2:  0.02436882193914144\n",
      "Error:  1.881794436040668e-05\n",
      "\n",
      " 0.7140466787818343 1.0770806866449008\n",
      "\n",
      "Loss 1:  0.02436882193914144\n",
      "Loss 2:  0.024350131025188373\n",
      "Error:  1.8690913953067767e-05\n",
      "\n",
      " 0.7139315682511367 1.0774962721850927\n",
      "\n",
      "Loss 1:  0.024350131025188373\n",
      "Loss 2:  0.024331566284124705\n",
      "Error:  1.8564741063667456e-05\n",
      "\n",
      " 0.7138168469047811 1.0779104526463226\n",
      "\n",
      "Loss 1:  0.024331566284124705\n",
      "Loss 2:  0.024313126864221293\n",
      "Error:  1.843941990341269e-05\n",
      "\n",
      " 0.7137025134269499 1.0783232327791092\n",
      "\n",
      "Loss 1:  0.024313126864221293\n",
      "Loss 2:  0.024294811919498373\n",
      "Error:  1.8314944722919863e-05\n",
      "\n",
      " 0.7135885665062743 1.07873461731791\n",
      "\n",
      "Loss 1:  0.024294811919498373\n",
      "Loss 2:  0.024276620609687157\n",
      "Error:  1.819130981121561e-05\n",
      "\n",
      " 0.7134750048358194 1.0791446109811753\n",
      "\n",
      "Loss 1:  0.024276620609687157\n",
      "Loss 2:  0.02425855210019099\n",
      "Error:  1.8068509496167035e-05\n",
      "\n",
      " 0.7133618271130686 1.0795532184714027\n",
      "\n",
      "Loss 1:  0.02425855210019099\n",
      "Loss 2:  0.024240605562047077\n",
      "Error:  1.79465381439127e-05\n",
      "\n",
      " 0.7132490320399093 1.0799604444751905\n",
      "\n",
      "Loss 1:  0.024240605562047077\n",
      "Loss 2:  0.024222780171888697\n",
      "Error:  1.782539015838039e-05\n",
      "\n",
      " 0.7131366183226178 1.080366293663292\n",
      "\n",
      "Loss 1:  0.024222780171888697\n",
      "Loss 2:  0.02420507511190722\n",
      "Error:  1.7705059981477922e-05\n",
      "\n",
      " 0.7130245846718443 1.080770770690669\n",
      "\n",
      "Loss 1:  0.02420507511190722\n",
      "Loss 2:  0.024187489569814518\n",
      "Error:  1.7585542092701106e-05\n",
      "\n",
      " 0.7129129298025983 1.081173880196545\n",
      "\n",
      "Loss 1:  0.024187489569814518\n",
      "Loss 2:  0.024170022738805953\n",
      "Error:  1.7466831008564748e-05\n",
      "\n",
      " 0.712801652434234 1.081575626804458\n",
      "\n",
      "Loss 1:  0.024170022738805953\n",
      "Loss 2:  0.024152673817523077\n",
      "Error:  1.734892128287674e-05\n",
      "\n",
      " 0.712690751290435 1.0819760151223148\n",
      "\n",
      "Loss 1:  0.024152673817523077\n",
      "Loss 2:  0.02413544201001716\n",
      "Error:  1.7231807505915797e-05\n",
      "\n",
      " 0.7125802250992004 1.0823750497424425\n",
      "\n",
      "Loss 1:  0.02413544201001716\n",
      "Loss 2:  0.024118326525712327\n",
      "Error:  1.7115484304833922e-05\n",
      "\n",
      " 0.7124700725928297 1.0827727352416416\n",
      "\n",
      "Loss 1:  0.024118326525712327\n",
      "Loss 2:  0.02410132657936962\n",
      "Error:  1.699994634270577e-05\n",
      "\n",
      " 0.7123602925079087 1.083169076181239\n",
      "\n",
      "Loss 1:  0.02410132657936962\n",
      "Loss 2:  0.024084441391050884\n",
      "Error:  1.688518831873681e-05\n",
      "\n",
      " 0.7122508835852944 1.0835640771071395\n",
      "\n",
      "Loss 1:  0.024084441391050884\n",
      "Loss 2:  0.02406767018608274\n",
      "Error:  1.677120496814538e-05\n",
      "\n",
      " 0.7121418445701013 1.083957742549879\n",
      "\n",
      "Loss 1:  0.02406767018608274\n",
      "Loss 2:  0.024051012195021454\n",
      "Error:  1.6657991061284905e-05\n",
      "\n",
      " 0.7120331742116863 1.0843500770246752\n",
      "\n",
      "Loss 1:  0.024051012195021454\n",
      "Loss 2:  0.024034466653617182\n",
      "Error:  1.6545541404271863e-05\n",
      "\n",
      " 0.7119248712636348 1.0847410850314805\n",
      "\n",
      "Loss 1:  0.024034466653617182\n",
      "Loss 2:  0.024018032802779372\n",
      "Error:  1.6433850837809655e-05\n",
      "\n",
      " 0.7118169344837463 1.0851307710550329\n",
      "\n",
      "Loss 1:  0.024018032802779372\n",
      "Loss 2:  0.024001709888541476\n",
      "Error:  1.6322914237896363e-05\n",
      "\n",
      " 0.7117093626340201 1.0855191395649075\n",
      "\n",
      "Loss 1:  0.024001709888541476\n",
      "Loss 2:  0.023985497162026914\n",
      "Error:  1.6212726514561876e-05\n",
      "\n",
      " 0.7116021544806412 1.0859061950155682\n",
      "\n",
      "Loss 1:  0.023985497162026914\n",
      "Loss 2:  0.023969393879414\n",
      "Error:  1.610328261291566e-05\n",
      "\n",
      " 0.711495308793966 1.0862919418464183\n",
      "\n",
      "Loss 1:  0.023969393879414\n",
      "Loss 2:  0.023953399301902524\n",
      "Error:  1.5994577511474484e-05\n",
      "\n",
      " 0.7113888243485084 1.0866763844818519\n",
      "\n",
      "Loss 1:  0.023953399301902524\n",
      "Loss 2:  0.023937512695679404\n",
      "Error:  1.5886606223119992e-05\n",
      "\n",
      " 0.7112826999229254 1.0870595273313044\n",
      "\n",
      "Loss 1:  0.023937512695679404\n",
      "Loss 2:  0.023921733331885218\n",
      "Error:  1.5779363794186235e-05\n",
      "\n",
      " 0.7111769343000035 1.0874413747893028\n",
      "\n",
      "Loss 1:  0.023921733331885218\n",
      "Loss 2:  0.02390606048658058\n",
      "Error:  1.5672845304636612e-05\n",
      "\n",
      " 0.7110715262666445 1.0878219312355166\n",
      "\n",
      "Loss 1:  0.02390606048658058\n",
      "Loss 2:  0.023890493440713156\n",
      "Error:  1.5567045867425494e-05\n",
      "\n",
      " 0.7109664746138517 1.0882012010348077\n",
      "\n",
      "Loss 1:  0.023890493440713156\n",
      "Loss 2:  0.02387503148008461\n",
      "Error:  1.5461960628546795e-05\n",
      "\n",
      " 0.7108617781367158 1.0885791885372804\n",
      "\n",
      "Loss 1:  0.02387503148008461\n",
      "Loss 2:  0.023859673895317762\n",
      "Error:  1.535758476684662e-05\n",
      "\n",
      " 0.7107574356344015 1.0889558980783318\n",
      "\n",
      "Loss 1:  0.023859673895317762\n",
      "Loss 2:  0.023844419981823944\n",
      "Error:  1.5253913493818577e-05\n",
      "\n",
      " 0.7106534459101332 1.0893313339787012\n",
      "\n",
      "Loss 1:  0.023844419981823944\n",
      "Loss 2:  0.023829269039771016\n",
      "Error:  1.5150942052927219e-05\n",
      "\n",
      " 0.7105498077711818 1.089705500544519\n",
      "\n",
      "Loss 1:  0.023829269039771016\n",
      "Loss 2:  0.02381422037405091\n",
      "Error:  1.5048665720107657e-05\n",
      "\n",
      " 0.7104465200288507 1.0900784020673577\n",
      "\n",
      "Loss 1:  0.02381422037405091\n",
      "Loss 2:  0.023799273294247945\n",
      "Error:  1.4947079802964114e-05\n",
      "\n",
      " 0.710343581498462 1.0904500428242796\n",
      "\n",
      "Loss 1:  0.023799273294247945\n",
      "Loss 2:  0.023784427114607036\n",
      "Error:  1.4846179640908702e-05\n",
      "\n",
      " 0.7102409909993436 1.0908204270778863\n",
      "\n",
      "Loss 1:  0.023784427114607036\n",
      "Loss 2:  0.023769681154002416\n",
      "Error:  1.474596060462019e-05\n",
      "\n",
      " 0.7101387473548147 1.091189559076368\n",
      "\n",
      "Loss 1:  0.023769681154002416\n",
      "Loss 2:  0.023755034735906032\n",
      "Error:  1.4646418096384006e-05\n",
      "\n",
      " 0.7100368493921734 1.0915574430535517\n",
      "\n",
      "Loss 1:  0.023755034735906032\n",
      "Loss 2:  0.0237404871883569\n",
      "Error:  1.4547547549131207e-05\n",
      "\n",
      " 0.7099352959426821 1.0919240832289503\n",
      "\n",
      "Loss 1:  0.0237404871883569\n",
      "Loss 2:  0.023726037843930146\n",
      "Error:  1.444934442675419e-05\n",
      "\n",
      " 0.709834085841555 1.0922894838078103\n",
      "\n",
      "Loss 1:  0.023726037843930146\n",
      "Loss 2:  0.023711686039706054\n",
      "Error:  1.4351804224092823e-05\n",
      "\n",
      " 0.7097332179279443 1.092653648981161\n",
      "\n",
      "Loss 1:  0.023711686039706054\n",
      "Loss 2:  0.023697431117240264\n",
      "Error:  1.4254922465789521e-05\n",
      "\n",
      " 0.7096326910449269 1.0930165829258611\n",
      "\n",
      "Loss 1:  0.023697431117240264\n",
      "Loss 2:  0.023683272422533125\n",
      "Error:  1.4158694707139263e-05\n",
      "\n",
      " 0.7095325040394913 1.0933782898046482\n",
      "\n",
      "Loss 1:  0.023683272422533125\n",
      "Loss 2:  0.02366920930599968\n",
      "Error:  1.4063116533444275e-05\n",
      "\n",
      " 0.7094326557625243 1.093738773766186\n",
      "\n",
      "Loss 1:  0.02366920930599968\n",
      "Loss 2:  0.023655241122440242\n",
      "Error:  1.3968183559438102e-05\n",
      "\n",
      " 0.7093331450687979 1.0940980389451107\n",
      "\n",
      "Loss 1:  0.023655241122440242\n",
      "Loss 2:  0.023641367231010364\n",
      "Error:  1.3873891429878882e-05\n",
      "\n",
      " 0.7092339708169556 1.0944560894620805\n",
      "\n",
      "Loss 1:  0.023641367231010364\n",
      "Loss 2:  0.02362758699519161\n",
      "Error:  1.3780235818754843e-05\n",
      "\n",
      " 0.7091351318695005 1.0948129294238216\n",
      "\n",
      "Loss 1:  0.02362758699519161\n",
      "Loss 2:  0.023613899782762498\n",
      "Error:  1.3687212429110834e-05\n",
      "\n",
      " 0.709036627092781 1.095168562923175\n",
      "\n",
      "Loss 1:  0.023613899782762498\n",
      "Loss 2:  0.023600304965769137\n",
      "Error:  1.359481699336057e-05\n",
      "\n",
      " 0.7089384553569786 1.0955229940391447\n",
      "\n",
      "Loss 1:  0.023600304965769137\n",
      "Loss 2:  0.02358680192049691\n",
      "Error:  1.3503045272228453e-05\n",
      "\n",
      " 0.7088406155360947 1.095876226836943\n",
      "\n",
      "Loss 1:  0.02358680192049691\n",
      "Loss 2:  0.023573390027441264\n",
      "Error:  1.3411893055644691e-05\n",
      "\n",
      " 0.7087431065079373 1.0962282653680386\n",
      "\n",
      "Loss 1:  0.023573390027441264\n",
      "Loss 2:  0.0235600686712799\n",
      "Error:  1.3321356161364456e-05\n",
      "\n",
      " 0.7086459271541088 1.0965791136702017\n",
      "\n",
      "Loss 1:  0.0235600686712799\n",
      "Loss 2:  0.02354683724084404\n",
      "Error:  1.3231430435859531e-05\n",
      "\n",
      " 0.7085490763599928 1.0969287757675512\n",
      "\n",
      "Loss 1:  0.02354683724084404\n",
      "Loss 2:  0.023533695129090745\n",
      "Error:  1.3142111753294827e-05\n",
      "\n",
      " 0.7084525530147413 1.0972772556706005\n",
      "\n",
      "Loss 1:  0.023533695129090745\n",
      "Loss 2:  0.023520641733074797\n",
      "Error:  1.3053396015948182e-05\n",
      "\n",
      " 0.7083563560112621 1.097624557376304\n",
      "\n",
      "Loss 1:  0.023520641733074797\n",
      "Loss 2:  0.02350767645392115\n",
      "Error:  1.2965279153648313e-05\n",
      "\n",
      " 0.7082604842462062 1.0979706848681021\n",
      "\n",
      "Loss 1:  0.02350767645392115\n",
      "Loss 2:  0.023494798696797686\n",
      "Error:  1.2877757123462563e-05\n",
      "\n",
      " 0.7081649366199547 1.0983156421159677\n",
      "\n",
      "Loss 1:  0.023494798696797686\n",
      "Loss 2:  0.023482007870887323\n",
      "Error:  1.279082591036304e-05\n",
      "\n",
      " 0.7080697120366066 1.098659433076451\n",
      "\n",
      "Loss 1:  0.023482007870887323\n",
      "Loss 2:  0.023469303389361634\n",
      "Error:  1.2704481525689648e-05\n",
      "\n",
      " 0.7079748094039661 1.0990020616927256\n",
      "\n",
      "Loss 1:  0.023469303389361634\n",
      "Loss 2:  0.023456684669353366\n",
      "Error:  1.2618720008267248e-05\n",
      "\n",
      " 0.70788022763353 1.0993435318946332\n",
      "\n",
      "Loss 1:  0.023456684669353366\n",
      "Loss 2:  0.023444151131930047\n",
      "Error:  1.2533537423319724e-05\n",
      "\n",
      " 0.7077859656404754 1.0996838475987287\n",
      "\n",
      "Loss 1:  0.023444151131930047\n",
      "Loss 2:  0.023431702202067084\n",
      "Error:  1.2448929862962643e-05\n",
      "\n",
      " 0.707692022343647 1.1000230127083257\n",
      "\n",
      "Loss 1:  0.023431702202067084\n",
      "Loss 2:  0.023419337308621745\n",
      "Error:  1.2364893445339364e-05\n",
      "\n",
      " 0.7075983966655451 1.1003610311135403\n",
      "\n",
      "Loss 1:  0.023419337308621745\n",
      "Loss 2:  0.023407055884306853\n",
      "Error:  1.2281424314891654e-05\n",
      "\n",
      " 0.7075050875323128 1.1006979066913367\n",
      "\n",
      "Loss 1:  0.023407055884306853\n",
      "Loss 2:  0.02339485736566447\n",
      "Error:  1.2198518642383971e-05\n",
      "\n",
      " 0.7074120938737237 1.1010336433055712\n",
      "\n",
      "Loss 1:  0.02339485736566447\n",
      "Loss 2:  0.023382741193040554\n",
      "Error:  1.2116172623914678e-05\n",
      "\n",
      " 0.7073194146231703 1.1013682448070363\n",
      "\n",
      "Loss 1:  0.023382741193040554\n",
      "Loss 2:  0.023370706810558715\n",
      "Error:  1.2034382481838912e-05\n",
      "\n",
      " 0.7072270487176506 1.1017017150335053\n",
      "\n",
      "Loss 1:  0.023370706810558715\n",
      "Loss 2:  0.023358753666095196\n",
      "Error:  1.1953144463519583e-05\n",
      "\n",
      " 0.7071349950977571 1.1020340578097763\n",
      "\n",
      "Loss 1:  0.023358753666095196\n",
      "Loss 2:  0.02334688121125331\n",
      "Error:  1.1872454841885954e-05\n",
      "\n",
      " 0.707043252707664 1.1023652769477152\n",
      "\n",
      "Loss 1:  0.02334688121125331\n",
      "Loss 2:  0.023335088901338372\n",
      "Error:  1.1792309914937515e-05\n",
      "\n",
      " 0.706951820495115 1.1026953762463012\n",
      "\n",
      "Loss 1:  0.023335088901338372\n",
      "Loss 2:  0.02332337619533245\n",
      "Error:  1.171270600592092e-05\n",
      "\n",
      " 0.7068606974114116 1.1030243594916682\n",
      "\n",
      "Loss 1:  0.02332337619533245\n",
      "Loss 2:  0.023311742555869958\n",
      "Error:  1.163363946249385e-05\n",
      "\n",
      " 0.7067698824114009 1.1033522304571501\n",
      "\n",
      "Loss 1:  0.023311742555869958\n",
      "Loss 2:  0.023300187449212757\n",
      "Error:  1.1555106657200331e-05\n",
      "\n",
      " 0.7066793744534637 1.103678992903323\n",
      "\n",
      "Loss 1:  0.023300187449212757\n",
      "Loss 2:  0.023288710345225706\n",
      "Error:  1.147710398705093e-05\n",
      "\n",
      " 0.7065891724995023 1.1040046505780488\n",
      "\n",
      "Loss 1:  0.023288710345225706\n",
      "Loss 2:  0.023277310717352156\n",
      "Error:  1.1399627873550505e-05\n",
      "\n",
      " 0.7064992755149289 1.1043292072165176\n",
      "\n",
      "Loss 1:  0.023277310717352156\n",
      "Loss 2:  0.023265988042590245\n",
      "Error:  1.132267476191065e-05\n",
      "\n",
      " 0.7064096824686534 1.1046526665412915\n",
      "\n",
      "Loss 1:  0.023265988042590245\n",
      "Loss 2:  0.0232547418014684\n",
      "Error:  1.1246241121844192e-05\n",
      "\n",
      " 0.7063203923330722 1.1049750322623464\n",
      "\n",
      "Loss 1:  0.0232547418014684\n",
      "Loss 2:  0.023243571478021998\n",
      "Error:  1.1170323446402924e-05\n",
      "\n",
      " 0.7062314040840555 1.1052963080771152\n",
      "\n",
      "Loss 1:  0.023243571478021998\n",
      "Loss 2:  0.023232476559769163\n",
      "Error:  1.1094918252834568e-05\n",
      "\n",
      " 0.7061427167009363 1.1056164976705296\n",
      "\n",
      "Loss 1:  0.023232476559769163\n",
      "Loss 2:  0.023221456537687698\n",
      "Error:  1.1020022081465602e-05\n",
      "\n",
      " 0.7060543291664986 1.1059356047150628\n",
      "\n",
      "Loss 1:  0.023221456537687698\n",
      "Loss 2:  0.0232105109061914\n",
      "Error:  1.0945631496298014e-05\n",
      "\n",
      " 0.7059662404669651 1.1062536328707717\n",
      "\n",
      "Loss 1:  0.0232105109061914\n",
      "Loss 2:  0.023199639163107244\n",
      "Error:  1.087174308415581e-05\n",
      "\n",
      " 0.7058784495919864 1.1065705857853383\n",
      "\n",
      "Loss 1:  0.023199639163107244\n",
      "Loss 2:  0.023188840809652025\n",
      "Error:  1.0798353455219317e-05\n",
      "\n",
      " 0.7057909555346291 1.1068864670941123\n",
      "\n",
      "Loss 1:  0.023188840809652025\n",
      "Loss 2:  0.023178115350409343\n",
      "Error:  1.07254592426817e-05\n",
      "\n",
      " 0.7057037572913639 1.1072012804201523\n",
      "\n",
      "Loss 1:  0.023178115350409343\n",
      "Loss 2:  0.02316746229330752\n",
      "Error:  1.0653057101822627e-05\n",
      "\n",
      " 0.7056168538620547 1.1075150293742675\n",
      "\n",
      "Loss 1:  0.02316746229330752\n",
      "Loss 2:  0.023156881149596315\n",
      "Error:  1.0581143711205221e-05\n",
      "\n",
      " 0.7055302442499467 1.1078277175550588\n",
      "\n",
      "Loss 1:  0.023156881149596315\n",
      "Loss 2:  0.02314637143382482\n",
      "Error:  1.0509715771496453e-05\n",
      "\n",
      " 0.7054439274616549 1.1081393485489608\n",
      "\n",
      "Loss 1:  0.02314637143382482\n",
      "Loss 2:  0.023135932663819213\n",
      "Error:  1.0438770005605919e-05\n",
      "\n",
      " 0.7053579025071531 1.1084499259302822\n",
      "\n",
      "Loss 1:  0.023135932663819213\n",
      "Loss 2:  0.023125564360660662\n",
      "Error:  1.036830315855053e-05\n",
      "\n",
      " 0.7052721683997625 1.1087594532612475\n",
      "\n",
      "Loss 1:  0.023125564360660662\n",
      "Loss 2:  0.02311526604866306\n",
      "Error:  1.0298311997603699e-05\n",
      "\n",
      " 0.7051867241561399 1.1090679340920369\n",
      "\n",
      "Loss 1:  0.02311526604866306\n",
      "Loss 2:  0.02310503725535165\n",
      "Error:  1.0228793311407164e-05\n",
      "\n",
      " 0.705101568796267 1.1093753719608277\n",
      "\n",
      "Loss 1:  0.02310503725535165\n",
      "Loss 2:  0.02309487751144097\n",
      "Error:  1.0159743910682223e-05\n",
      "\n",
      " 0.7050167013434385 1.109681770393835\n",
      "\n",
      "Loss 1:  0.02309487751144097\n",
      "Loss 2:  0.023084786350813513\n",
      "Error:  1.0091160627456047e-05\n",
      "\n",
      " 0.7049321208242519 1.1099871329053521\n",
      "\n",
      "Loss 1:  0.023084786350813513\n",
      "Loss 2:  0.02307476331049827\n",
      "Error:  1.0023040315242093e-05\n",
      "\n",
      " 0.7048478262685954 1.11029146299779\n",
      "\n",
      "Loss 1:  0.02307476331049827\n",
      "Loss 2:  0.023064807930649543\n",
      "Error:  9.955379848727852e-06\n",
      "\n",
      " 0.7047638167096371 1.1105947641617184\n",
      "\n",
      "Loss 1:  0.023064807930649543\n",
      "Loss 2:  0.023054919754525817\n",
      "Error:  9.888176123726278e-06\n",
      "\n",
      " 0.7046800911838138 1.110897039875906\n",
      "\n",
      "Loss 1:  0.023054919754525817\n",
      "Loss 2:  0.023045098328468763\n",
      "Error:  9.821426057054355e-06\n",
      "\n",
      " 0.7045966487308204 1.111198293607359\n",
      "\n",
      "Loss 1:  0.023045098328468763\n",
      "Loss 2:  0.023035343201882504\n",
      "Error:  9.755126586259016e-06\n",
      "\n",
      " 0.7045134883935984 1.1114985288113626\n",
      "\n",
      "Loss 1:  0.023035343201882504\n",
      "Loss 2:  0.02302565392721291\n",
      "Error:  9.689274669592851e-06\n",
      "\n",
      " 0.704430609218325 1.1117977489315194\n",
      "\n",
      "Loss 1:  0.02302565392721291\n",
      "Loss 2:  0.023016030059927053\n",
      "Error:  9.623867285857984e-06\n",
      "\n",
      " 0.7043480102544023 1.1120959573997895\n",
      "\n",
      "Loss 1:  0.023016030059927053\n",
      "Loss 2:  0.02300647115849285\n",
      "Error:  9.558901434201378e-06\n",
      "\n",
      " 0.7042656905544464 1.1123931576365296\n",
      "\n",
      "Loss 1:  0.02300647115849285\n",
      "Loss 2:  0.02299697678435877\n",
      "Error:  9.494374134080136e-06\n",
      "\n",
      " 0.7041836491742764 1.1126893530505322\n",
      "\n",
      "Loss 1:  0.02299697678435877\n",
      "Loss 2:  0.022987546501933714\n",
      "Error:  9.430282425056807e-06\n",
      "\n",
      " 0.7041018851729037 1.112984547039065\n",
      "\n",
      "Loss 1:  0.022987546501933714\n",
      "Loss 2:  0.02297817987856696\n",
      "Error:  9.366623366754284e-06\n",
      "\n",
      " 0.704020397612521 1.1132787429879094\n",
      "\n",
      "Loss 1:  0.02297817987856696\n",
      "Loss 2:  0.022968876484528524\n",
      "Error:  9.303394038435997e-06\n",
      "\n",
      " 0.7039391855584918 1.1135719442714\n",
      "\n",
      "Loss 1:  0.022968876484528524\n",
      "Loss 2:  0.02295963589298918\n",
      "Error:  9.240591539342452e-06\n",
      "\n",
      " 0.7038582480793396 1.1138641542524625\n",
      "\n",
      "Loss 1:  0.02295963589298918\n",
      "Loss 2:  0.022950457680001153\n",
      "Error:  9.178212988028567e-06\n",
      "\n",
      " 0.7037775842467371 1.1141553762826528\n",
      "\n",
      "Loss 1:  0.022950457680001153\n",
      "Loss 2:  0.02294134142447839\n",
      "Error:  9.116255522762656e-06\n",
      "\n",
      " 0.7036971931354957 1.1144456137021956\n",
      "\n",
      "Loss 1:  0.02294134142447839\n",
      "Loss 2:  0.0229322867081775\n",
      "Error:  9.054716300891524e-06\n",
      "\n",
      " 0.7036170738235549 1.114734869840022\n",
      "\n",
      "Loss 1:  0.0229322867081775\n",
      "Loss 2:  0.02292329311567834\n",
      "Error:  8.993592499159653e-06\n",
      "\n",
      " 0.7035372253919715 1.1150231480138082\n",
      "\n",
      "Loss 1:  0.02292329311567834\n",
      "Loss 2:  0.02291436023436514\n",
      "Error:  8.932881313199192e-06\n",
      "\n",
      " 0.7034576469249093 1.1153104515300138\n",
      "\n",
      "Loss 1:  0.02291436023436514\n",
      "Loss 2:  0.02290548765440734\n",
      "Error:  8.87257995780058e-06\n",
      "\n",
      " 0.7033783375096284 1.115596783683919\n",
      "\n",
      "Loss 1:  0.02290548765440734\n",
      "Loss 2:  0.022896674968741197\n",
      "Error:  8.812685666142323e-06\n",
      "\n",
      " 0.703299296236475 1.1158821477596628\n",
      "\n",
      "Loss 1:  0.022896674968741197\n",
      "Loss 2:  0.0228879217730505\n",
      "Error:  8.753195690696519e-06\n",
      "\n",
      " 0.7032205221988708 1.116166547030281\n",
      "\n",
      "Loss 1:  0.0228879217730505\n",
      "Loss 2:  0.02287922766574877\n",
      "Error:  8.694107301730064e-06\n",
      "\n",
      " 0.7031420144933023 1.1164499847577432\n",
      "\n",
      "Loss 1:  0.02287922766574877\n",
      "Loss 2:  0.0228705922479601\n",
      "Error:  8.635417788671607e-06\n",
      "\n",
      " 0.7030637722193112 1.11673246419299\n",
      "\n",
      "Loss 1:  0.0228705922479601\n",
      "Loss 2:  0.022862015123501354\n",
      "Error:  8.57712445874459e-06\n",
      "\n",
      " 0.7029857944794833 1.1170139885759716\n",
      "\n",
      "Loss 1:  0.022862015123501354\n",
      "Loss 2:  0.022853495898863874\n",
      "Error:  8.519224637480727e-06\n",
      "\n",
      " 0.7029080803794386 1.117294561135683\n",
      "\n",
      "Loss 1:  0.022853495898863874\n",
      "Loss 2:  0.022845034183195174\n",
      "Error:  8.461715668699188e-06\n",
      "\n",
      " 0.7028306290278211 1.117574185090203\n",
      "\n",
      "Loss 1:  0.022845034183195174\n",
      "Loss 2:  0.022836629588281445\n",
      "Error:  8.40459491372944e-06\n",
      "\n",
      " 0.7027534395362883 1.1178528636467298\n",
      "\n",
      "Loss 1:  0.022836629588281445\n",
      "Loss 2:  0.022828281728529416\n",
      "Error:  8.347859752028813e-06\n",
      "\n",
      " 0.7026765110195011 1.1181306000016178\n",
      "\n",
      "Loss 1:  0.022828281728529416\n",
      "Loss 2:  0.02281999022094868\n",
      "Error:  8.291507580734936e-06\n",
      "\n",
      " 0.7025998425951138 1.1184073973404154\n",
      "\n",
      "Loss 1:  0.02281999022094868\n",
      "Loss 2:  0.02281175468513434\n",
      "Error:  8.235535814339612e-06\n",
      "\n",
      " 0.7025234333837638 1.1186832588379003\n",
      "\n",
      "Loss 1:  0.02281175468513434\n",
      "Loss 2:  0.022803574743249337\n",
      "Error:  8.179941885004538e-06\n",
      "\n",
      " 0.7024472825090617 1.1189581876581165\n",
      "\n",
      "Loss 1:  0.022803574743249337\n",
      "Loss 2:  0.022795450020007255\n",
      "Error:  8.124723242082521e-06\n",
      "\n",
      " 0.7023713890975811 1.1192321869544104\n",
      "\n",
      "Loss 1:  0.022795450020007255\n",
      "Loss 2:  0.022787380142654974\n",
      "Error:  8.069877352280541e-06\n",
      "\n",
      " 0.7022957522788487 1.1195052598694673\n",
      "\n",
      "Loss 1:  0.022787380142654974\n",
      "Loss 2:  0.02277936474095567\n",
      "Error:  8.015401699302399e-06\n",
      "\n",
      " 0.7022203711853339 1.119777409535347\n",
      "\n",
      "Loss 1:  0.02277936474095567\n",
      "Loss 2:  0.022771403447171913\n",
      "Error:  7.96129378375851e-06\n",
      "\n",
      " 0.7021452449524396 1.12004863907352\n",
      "\n",
      "Loss 1:  0.022771403447171913\n",
      "Loss 2:  0.02276349589604849\n",
      "Error:  7.907551123422646e-06\n",
      "\n",
      " 0.7020703727184916 1.1203189515949032\n",
      "\n",
      "Loss 1:  0.02276349589604849\n",
      "Loss 2:  0.02275564172479598\n",
      "Error:  7.854171252510284e-06\n",
      "\n",
      " 0.7019957536247292 1.1205883501998957\n",
      "\n",
      "Loss 1:  0.02275564172479598\n",
      "Loss 2:  0.02274784057307388\n",
      "Error:  7.801151722101884e-06\n",
      "\n",
      " 0.701921386815295 1.120856837978414\n",
      "\n",
      "Loss 1:  0.02274784057307388\n",
      "Loss 2:  0.022740092082974218\n",
      "Error:  7.748490099660638e-06\n",
      "\n",
      " 0.7018472714372253 1.121124418009928\n",
      "\n",
      "Loss 1:  0.022740092082974218\n",
      "Loss 2:  0.022732395899005074\n",
      "Error:  7.696183969143483e-06\n",
      "\n",
      " 0.70177340664044 1.1213910933634958\n",
      "\n",
      "Loss 1:  0.022732395899005074\n",
      "Loss 2:  0.022724751668074257\n",
      "Error:  7.64423093081723e-06\n",
      "\n",
      " 0.7016997915777334 1.1216568670977995\n",
      "\n",
      "Loss 1:  0.022724751668074257\n",
      "Loss 2:  0.02271715903947313\n",
      "Error:  7.592628601126722e-06\n",
      "\n",
      " 0.701626425404764 1.1219217422611796\n",
      "\n",
      "Loss 1:  0.02271715903947313\n",
      "Loss 2:  0.022709617664860522\n",
      "Error:  7.541374612608093e-06\n",
      "\n",
      " 0.7015533072800452 1.1221857218916702\n",
      "\n",
      "Loss 1:  0.022709617664860522\n",
      "Loss 2:  0.022702127198246692\n",
      "Error:  7.490466613829794e-06\n",
      "\n",
      " 0.7014804363649351 1.1224488090170341\n",
      "\n",
      "Loss 1:  0.022702127198246692\n",
      "Loss 2:  0.022694687295977567\n",
      "Error:  7.439902269125442e-06\n",
      "\n",
      " 0.7014078118236273 1.1227110066547974\n",
      "\n",
      "Loss 1:  0.022694687295977567\n",
      "Loss 2:  0.02268729761671893\n",
      "Error:  7.3896792586354565e-06\n",
      "\n",
      " 0.7013354328231415 1.122972317812284\n",
      "\n",
      "Loss 1:  0.02268729761671893\n",
      "Loss 2:  0.02267995782144059\n",
      "Error:  7.339795278341749e-06\n",
      "\n",
      " 0.7012632985333133 1.1232327454866498\n",
      "\n",
      "Loss 1:  0.02267995782144059\n",
      "Loss 2:  0.022672667573401063\n",
      "Error:  7.290248039526492e-06\n",
      "\n",
      " 0.7011914081267854 1.123492292664918\n",
      "\n",
      "Loss 1:  0.022672667573401063\n",
      "Loss 2:  0.02266542653813216\n",
      "Error:  7.2410352689039614e-06\n",
      "\n",
      " 0.7011197607789975 1.1237509623240125\n",
      "\n",
      "Loss 1:  0.02266542653813216\n",
      "Loss 2:  0.02265823438342332\n",
      "Error:  7.192154708839105e-06\n",
      "\n",
      " 0.7010483556681774 1.1240087574307924\n",
      "\n",
      "Loss 1:  0.02265823438342332\n",
      "Loss 2:  0.02265109077930664\n",
      "Error:  7.143604116681412e-06\n",
      "\n",
      " 0.7009771919753308 1.124265680942086\n",
      "\n",
      "Loss 1:  0.02265109077930664\n",
      "Loss 2:  0.022643995398041745\n",
      "Error:  7.095381264893286e-06\n",
      "\n",
      " 0.7009062688842329 1.1245217358047244\n",
      "\n",
      "Loss 1:  0.022643995398041745\n",
      "Loss 2:  0.02263694791410053\n",
      "Error:  7.04748394121657e-06\n",
      "\n",
      " 0.7008355855814182 1.124776924955576\n",
      "\n",
      "Loss 1:  0.02263694791410053\n",
      "Loss 2:  0.022629948004152422\n",
      "Error:  6.999909948107036e-06\n",
      "\n",
      " 0.7007651412561716 1.1250312513215792\n",
      "\n",
      "Loss 1:  0.022629948004152422\n",
      "Loss 2:  0.022622995347049604\n",
      "Error:  6.952657102817644e-06\n",
      "\n",
      " 0.7006949351005191 1.1252847178197773\n",
      "\n",
      "Loss 1:  0.022622995347049604\n",
      "Loss 2:  0.02261608962381193\n",
      "Error:  6.905723237672634e-06\n",
      "\n",
      " 0.7006249663092182 1.1255373273573506\n",
      "\n",
      "Loss 1:  0.02261608962381193\n",
      "Loss 2:  0.022609230517612725\n",
      "Error:  6.859106199207099e-06\n",
      "\n",
      " 0.7005552340797492 1.1257890828316504\n",
      "\n",
      "Loss 1:  0.022609230517612725\n",
      "Loss 2:  0.022602417713763957\n",
      "Error:  6.8128038487672016e-06\n",
      "\n",
      " 0.7004857376123054 1.1260399871302325\n",
      "\n",
      "Loss 1:  0.022602417713763957\n",
      "Loss 2:  0.02259565089970196\n",
      "Error:  6.7668140619966954e-06\n",
      "\n",
      " 0.7004164761097842 1.1262900431308895\n",
      "\n",
      "Loss 1:  0.02259565089970196\n",
      "Loss 2:  0.02258892976497291\n",
      "Error:  6.721134729052031e-06\n",
      "\n",
      " 0.7003474487777783 1.1265392537016847\n",
      "\n",
      "Loss 1:  0.02258892976497291\n",
      "Loss 2:  0.02258225400121886\n",
      "Error:  6.6757637540472425e-06\n",
      "\n",
      " 0.700278654824566 1.1267876217009842\n",
      "\n",
      "Loss 1:  0.02258225400121886\n",
      "Loss 2:  0.022575623302163336\n",
      "Error:  6.630699055525796e-06\n",
      "\n",
      " 0.7002100934611024 1.1270351499774907\n",
      "\n",
      "Loss 1:  0.022575623302163336\n",
      "Loss 2:  0.02256903736359731\n",
      "Error:  6.585938566026905e-06\n",
      "\n",
      " 0.7001417639010105 1.1272818413702748\n",
      "\n",
      "Loss 1:  0.02256903736359731\n",
      "Loss 2:  0.022562495883365487\n",
      "Error:  6.541480231821856e-06\n",
      "\n",
      " 0.7000736653605717 1.1275276987088085\n",
      "\n",
      "Loss 1:  0.022562495883365487\n",
      "Loss 2:  0.0225559985613522\n",
      "Error:  6.497322013285234e-06\n",
      "\n",
      " 0.7000057970587173 1.127772724812998\n",
      "\n",
      "Loss 1:  0.0225559985613522\n",
      "Loss 2:  0.022549545099467556\n",
      "Error:  6.453461884645129e-06\n",
      "\n",
      " 0.6999381582170197 1.128016922493215\n",
      "\n",
      "Loss 1:  0.022549545099467556\n",
      "Loss 2:  0.022543135201634222\n",
      "Error:  6.409897833334344e-06\n",
      "\n",
      " 0.6998707480596824 1.1282602945503295\n",
      "\n",
      "Loss 1:  0.022543135201634222\n",
      "Loss 2:  0.022536768573773232\n",
      "Error:  6.366627860989599e-06\n",
      "\n",
      " 0.6998035658135325 1.128502843775742\n",
      "\n",
      "Loss 1:  0.022536768573773232\n",
      "Loss 2:  0.022530444923790992\n",
      "Error:  6.323649982240692e-06\n",
      "\n",
      " 0.6997366107080109 1.1287445729514152\n",
      "\n",
      "Loss 1:  0.022530444923790992\n",
      "Loss 2:  0.02252416396156558\n",
      "Error:  6.2809622254113295e-06\n",
      "\n",
      " 0.6996698819751636 1.1289854848499061\n",
      "\n",
      "Loss 1:  0.02252416396156558\n",
      "Loss 2:  0.022517925398933592\n",
      "Error:  6.238562631988298e-06\n",
      "\n",
      " 0.6996033788496332 1.1292255822343982\n",
      "\n",
      "Loss 1:  0.022517925398933592\n",
      "Loss 2:  0.02251172894967685\n",
      "Error:  6.1964492567428975e-06\n",
      "\n",
      " 0.6995371005686499 1.1294648678587322\n",
      "\n",
      "Loss 1:  0.02251172894967685\n",
      "Loss 2:  0.02250557432950933\n",
      "Error:  6.1546201675193035e-06\n",
      "\n",
      " 0.6994710463720231 1.1297033444674387\n",
      "\n",
      "Loss 1:  0.02250557432950933\n",
      "Loss 2:  0.022499461256064005\n",
      "Error:  6.113073445324774e-06\n",
      "\n",
      " 0.6994052155021316 1.1299410147957685\n",
      "\n",
      "Loss 1:  0.022499461256064005\n",
      "Loss 2:  0.022493389448880033\n",
      "Error:  6.071807183972294e-06\n",
      "\n",
      " 0.6993396072039165 1.1301778815697252\n",
      "\n",
      "Loss 1:  0.022493389448880033\n",
      "Loss 2:  0.02248735862938981\n",
      "Error:  6.030819490222827e-06\n",
      "\n",
      " 0.6992742207248713 1.1304139475060957\n",
      "\n",
      "Loss 1:  0.02248735862938981\n",
      "Loss 2:  0.02248136852090609\n",
      "Error:  5.990108483719392e-06\n",
      "\n",
      " 0.6992090553150339 1.1306492153124814\n",
      "\n",
      "Loss 1:  0.02248136852090609\n",
      "Loss 2:  0.022475418848609614\n",
      "Error:  5.949672296477054e-06\n",
      "\n",
      " 0.6991441102269775 1.1308836876873298\n",
      "\n",
      "Loss 1:  0.022475418848609614\n",
      "Loss 2:  0.022469509339536082\n",
      "Error:  5.909509073531716e-06\n",
      "\n",
      " 0.6990793847158027 1.1311173673199646\n",
      "\n",
      "Loss 1:  0.022469509339536082\n",
      "Loss 2:  0.02246363972256402\n",
      "Error:  5.8696169720623415e-06\n",
      "\n",
      " 0.6990148780391282 1.131350256890617\n",
      "\n",
      "Loss 1:  0.02246363972256402\n",
      "Loss 2:  0.022457809728402042\n",
      "Error:  5.829994161977298e-06\n",
      "\n",
      " 0.698950589457083 1.131582359070457\n",
      "\n",
      "Loss 1:  0.022457809728402042\n",
      "Loss 2:  0.022452019089576527\n",
      "Error:  5.790638825515365e-06\n",
      "\n",
      " 0.6988865182322973 1.131813676521623\n",
      "\n",
      "Loss 1:  0.022452019089576527\n",
      "Loss 2:  0.022446267540419652\n",
      "Error:  5.751549156874508e-06\n",
      "\n",
      " 0.6988226636298945 1.1320442118972527\n",
      "\n",
      "Loss 1:  0.022446267540419652\n",
      "Loss 2:  0.022440554817056823\n",
      "Error:  5.712723362829436e-06\n",
      "\n",
      " 0.6987590249174825 1.132273967841514\n",
      "\n",
      "Loss 1:  0.022440554817056823\n",
      "Loss 2:  0.02243488065739476\n",
      "Error:  5.6741596620620005e-06\n",
      "\n",
      " 0.6986956013651455 1.1325029469896346\n",
      "\n",
      "Loss 1:  0.02243488065739476\n",
      "Loss 2:  0.022429244801109548\n",
      "Error:  5.6358562852132366e-06\n",
      "\n",
      " 0.6986323922454354 1.1327311519679333\n",
      "\n",
      "Loss 1:  0.022429244801109548\n",
      "Loss 2:  0.022423646989634373\n",
      "Error:  5.5978114751747965e-06\n",
      "\n",
      " 0.6985693968333636 1.1329585853938484\n",
      "\n",
      "Loss 1:  0.022423646989634373\n",
      "Loss 2:  0.022418086966148065\n",
      "Error:  5.560023486308324e-06\n",
      "\n",
      " 0.6985066144063927 1.1331852498759696\n",
      "\n",
      "Loss 1:  0.022418086966148065\n",
      "Loss 2:  0.02241256447556305\n",
      "Error:  5.5224905850144446e-06\n",
      "\n",
      " 0.6984440442444282 1.1334111480140667\n",
      "\n",
      "Loss 1:  0.02241256447556305\n",
      "Loss 2:  0.02240707926451383\n",
      "Error:  5.485211049219285e-06\n",
      "\n",
      " 0.69838168562981 1.1336362823991197\n",
      "\n",
      "Loss 1:  0.02240707926451383\n",
      "Loss 2:  0.02240163108134499\n",
      "Error:  5.448183168839382e-06\n",
      "\n",
      " 0.6983195378473046 1.1338606556133488\n",
      "\n",
      "Loss 1:  0.02240163108134499\n",
      "Loss 2:  0.022396219676100122\n",
      "Error:  5.411405244869216e-06\n",
      "\n",
      " 0.6982576001840967 1.1340842702302436\n",
      "\n",
      "Loss 1:  0.022396219676100122\n",
      "Loss 2:  0.022390844800510158\n",
      "Error:  5.374875589964079e-06\n",
      "\n",
      " 0.6981958719297807 1.134307128814593\n",
      "\n",
      "Loss 1:  0.022390844800510158\n",
      "Loss 2:  0.022385506207981822\n",
      "Error:  5.338592528335989e-06\n",
      "\n",
      " 0.6981343523763534 1.1345292339225141\n",
      "\n",
      "Loss 1:  0.022385506207981822\n",
      "Loss 2:  0.022380203653586585\n",
      "Error:  5.302554395236747e-06\n",
      "\n",
      " 0.6980730408182048 1.1347505881014825\n",
      "\n",
      "Loss 1:  0.022380203653586585\n",
      "Loss 2:  0.022374936894049284\n",
      "Error:  5.2667595373014076e-06\n",
      "\n",
      " 0.6980119365521108 1.1349711938903606\n",
      "\n",
      "Loss 1:  0.022374936894049284\n",
      "Loss 2:  0.02236970568773696\n",
      "Error:  5.231206312322767e-06\n",
      "\n",
      " 0.6979510388772248 1.1351910538194268\n",
      "\n",
      "Loss 1:  0.02236970568773696\n",
      "Loss 2:  0.02236450979464782\n",
      "Error:  5.195893089140341e-06\n",
      "\n",
      " 0.6978903470950697 1.1354101704104047\n",
      "\n",
      "Loss 1:  0.02236450979464782\n",
      "Loss 2:  0.02235934897640015\n",
      "Error:  5.160818247671589e-06\n",
      "\n",
      " 0.6978298605095301 1.1356285461764923\n",
      "\n",
      "Loss 1:  0.02235934897640015\n",
      "Loss 2:  0.02235422299622152\n",
      "Error:  5.12598017863089e-06\n",
      "\n",
      " 0.697769578426844 1.1358461836223908\n",
      "\n",
      "Loss 1:  0.02235422299622152\n",
      "Loss 2:  0.022349131618937687\n",
      "Error:  5.091377283831383e-06\n",
      "\n",
      " 0.6977095001555949 1.1360630852443323\n",
      "\n",
      "Loss 1:  0.022349131618937687\n",
      "Loss 2:  0.02234407461096219\n",
      "Error:  5.057007975498018e-06\n",
      "\n",
      " 0.697649625006704 1.13627925353011\n",
      "\n",
      "Loss 1:  0.02234407461096219\n",
      "Loss 2:  0.0223390517402851\n",
      "Error:  5.0228706770898135e-06\n",
      "\n",
      " 0.6975899522934226 1.1364946909591056\n",
      "\n",
      "Loss 1:  0.0223390517402851\n",
      "Loss 2:  0.022334062776462896\n",
      "Error:  4.988963822203513e-06\n",
      "\n",
      " 0.6975304813313232 1.1367094000023181\n",
      "\n",
      "Loss 1:  0.022334062776462896\n",
      "Loss 2:  0.022329107490607528\n",
      "Error:  4.955285855368086e-06\n",
      "\n",
      " 0.697471211438293 1.1369233831223924\n",
      "\n",
      "Loss 1:  0.022329107490607528\n",
      "Loss 2:  0.022324185655376135\n",
      "Error:  4.921835231392474e-06\n",
      "\n",
      " 0.697412141934525 1.137136642773647\n",
      "\n",
      "Loss 1:  0.022324185655376135\n",
      "Loss 2:  0.02231929704496053\n",
      "Error:  4.8886104156049826e-06\n",
      "\n",
      " 0.6973532721425107 1.1373491814021024\n",
      "\n",
      "Loss 1:  0.02231929704496053\n",
      "Loss 2:  0.022314441435076805\n",
      "Error:  4.8556098837249095e-06\n",
      "\n",
      " 0.6972946013870323 1.1375610014455098\n",
      "\n",
      "Loss 1:  0.022314441435076805\n",
      "Loss 2:  0.02230961860295499\n",
      "Error:  4.822832121813975e-06\n",
      "\n",
      " 0.6972361289951545 1.1377721053333776\n",
      "\n",
      "Loss 1:  0.02230961860295499\n",
      "Loss 2:  0.02230482832732917\n",
      "Error:  4.7902756258218215e-06\n",
      "\n",
      " 0.6971778542962178 1.1379824954870008\n",
      "\n",
      "Loss 1:  0.02230482832732917\n",
      "Loss 2:  0.022300070388426865\n",
      "Error:  4.757938902304193e-06\n",
      "\n",
      " 0.6971197766218298 1.1381921743194878\n",
      "\n",
      "Loss 1:  0.022300070388426865\n",
      "Loss 2:  0.022295344567959265\n",
      "Error:  4.725820467600672e-06\n",
      "\n",
      " 0.6970618953058579 1.1384011442357882\n",
      "\n",
      "Loss 1:  0.022295344567959265\n",
      "Loss 2:  0.022290650649111034\n",
      "Error:  4.6939188482302e-06\n",
      "\n",
      " 0.6970042096844219 1.138609407632721\n",
      "\n",
      "Loss 1:  0.022290650649111034\n",
      "Loss 2:  0.022285988416530594\n",
      "Error:  4.6622325804400455e-06\n",
      "\n",
      " 0.6969467190958858 1.1388169668990011\n",
      "\n",
      "Loss 1:  0.022285988416530594\n",
      "Loss 2:  0.022281357656319924\n",
      "Error:  4.630760210670715e-06\n",
      "\n",
      " 0.6968894228808509 1.139023824415268\n",
      "\n",
      "Loss 1:  0.022281357656319924\n",
      "Loss 2:  0.02227675815602507\n",
      "Error:  4.599500294855119e-06\n",
      "\n",
      " 0.6968323203821476 1.1392299825541115\n",
      "\n",
      "Loss 1:  0.02227675815602507\n",
      "Loss 2:  0.022272189704626084\n",
      "Error:  4.568451398984097e-06\n",
      "\n",
      " 0.6967754109448284 1.1394354436801004\n",
      "\n",
      "Loss 1:  0.022272189704626084\n",
      "Loss 2:  0.022267652092527762\n",
      "Error:  4.537612098322319e-06\n",
      "\n",
      " 0.6967186939161601 1.1396402101498087\n",
      "\n",
      "Loss 1:  0.022267652092527762\n",
      "Loss 2:  0.022263145111549455\n",
      "Error:  4.506980978306874e-06\n",
      "\n",
      " 0.6966621686456164 1.1398442843118428\n",
      "\n",
      "Loss 1:  0.022263145111549455\n",
      "Loss 2:  0.022258668554916042\n",
      "Error:  4.476556633412759e-06\n",
      "\n",
      " 0.6966058344848701 1.140047668506869\n",
      "\n",
      "Loss 1:  0.022258668554916042\n",
      "Loss 2:  0.022254222217248217\n",
      "Error:  4.446337667825956e-06\n",
      "\n",
      " 0.6965496907877865 1.1402503650676394\n",
      "\n",
      "Loss 1:  0.022254222217248217\n",
      "Loss 2:  0.022249805894553044\n",
      "Error:  4.4163226951728085e-06\n",
      "\n",
      " 0.696493736910415 1.1404523763190195\n",
      "\n",
      "Loss 1:  0.022249805894553044\n",
      "Loss 2:  0.02224541938421462\n",
      "Error:  4.386510338422883e-06\n",
      "\n",
      " 0.6964379722109826 1.1406537045780143\n",
      "\n",
      "Loss 1:  0.02224541938421462\n",
      "Loss 2:  0.02224106248498484\n",
      "Error:  4.3568992297814135e-06\n",
      "\n",
      " 0.6963823960498856 1.140854352153795\n",
      "\n",
      "Loss 1:  0.02224106248498484\n",
      "Loss 2:  0.02223673499697413\n",
      "Error:  4.327488010710118e-06\n",
      "\n",
      " 0.696327007789683 1.141054321347726\n",
      "\n",
      "Loss 1:  0.02223673499697413\n",
      "Loss 2:  0.022232436721642275\n",
      "Error:  4.29827533185434e-06\n",
      "\n",
      " 0.6962718067950893 1.1412536144533905\n",
      "\n",
      "Loss 1:  0.022232436721642275\n",
      "Loss 2:  0.022228167461789183\n",
      "Error:  4.269259853091623e-06\n",
      "\n",
      " 0.6962167924329662 1.1414522337566173\n",
      "\n",
      "Loss 1:  0.022228167461789183\n",
      "Loss 2:  0.02222392702154625\n",
      "Error:  4.240440242934962e-06\n",
      "\n",
      " 0.6961619640723166 1.141650181535507\n",
      "\n",
      "Loss 1:  0.02222392702154625\n",
      "Loss 2:  0.022219715206366713\n",
      "Error:  4.2118151795354775e-06\n",
      "\n",
      " 0.6961073210842765 1.1418474600604578\n",
      "\n",
      "Loss 1:  0.022219715206366713\n",
      "Loss 2:  0.022215531823017273\n",
      "Error:  4.1833833494403505e-06\n",
      "\n",
      " 0.6960528628421082 1.142044071594192\n",
      "\n",
      "Loss 1:  0.022215531823017273\n",
      "Loss 2:  0.022211376679569204\n",
      "Error:  4.155143448068138e-06\n",
      "\n",
      " 0.6959985887211929 1.1422400183917816\n",
      "\n",
      "Loss 1:  0.022211376679569204\n",
      "Loss 2:  0.022207249585389135\n",
      "Error:  4.127094180069596e-06\n",
      "\n",
      " 0.6959444980990236 1.1424353027006744\n",
      "\n",
      "Loss 1:  0.022207249585389135\n",
      "Loss 2:  0.022203150351130675\n",
      "Error:  4.099234258460316e-06\n",
      "\n",
      " 0.695890590355198 1.1426299267607194\n",
      "\n",
      "Loss 1:  0.022203150351130675\n",
      "Loss 2:  0.02219907878872556\n",
      "Error:  4.071562405113388e-06\n",
      "\n",
      " 0.6958368648714113 1.1428238928041932\n",
      "\n",
      "Loss 1:  0.02219907878872556\n",
      "Loss 2:  0.022195034711375246\n",
      "Error:  4.0440773503153116e-06\n",
      "\n",
      " 0.6957833210314491 1.1430172030558245\n",
      "\n",
      "Loss 1:  0.022195034711375246\n",
      "Loss 2:  0.022191017933541994\n",
      "Error:  4.016777833251717e-06\n",
      "\n",
      " 0.6957299582211809 1.143209859732821\n",
      "\n",
      "Loss 1:  0.022191017933541994\n",
      "Loss 2:  0.022187028270940552\n",
      "Error:  3.989662601441846e-06\n",
      "\n",
      " 0.6956767758285518 1.1434018650448938\n",
      "\n",
      "Loss 1:  0.022187028270940552\n",
      "Loss 2:  0.022183065540529824\n",
      "Error:  3.962730410728144e-06\n",
      "\n",
      " 0.6956237732435767 1.1435932211942827\n",
      "\n",
      "Loss 1:  0.022183065540529824\n",
      "Loss 2:  0.022179129560504173\n",
      "Error:  3.935980025650959e-06\n",
      "\n",
      " 0.6955709498583329 1.1437839303757824\n",
      "\n",
      "Loss 1:  0.022179129560504173\n",
      "Loss 2:  0.022175220150285363\n",
      "Error:  3.9094102188101665e-06\n",
      "\n",
      " 0.6955183050669527 1.1439739947767669\n",
      "\n",
      "Loss 1:  0.022175220150285363\n",
      "Loss 2:  0.022171337130514012\n",
      "Error:  3.883019771350887e-06\n",
      "\n",
      " 0.695465838265617 1.1441634165772143\n",
      "\n",
      "Loss 1:  0.022171337130514012\n",
      "Loss 2:  0.022167480323041545\n",
      "Error:  3.856807472467361e-06\n",
      "\n",
      " 0.6954135488525485 1.144352197949733\n",
      "\n",
      "Loss 1:  0.022167480323041545\n",
      "Loss 2:  0.022163649550922156\n",
      "Error:  3.830772119389064e-06\n",
      "\n",
      " 0.6953614362280038 1.1445403410595856\n",
      "\n",
      "Loss 1:  0.022163649550922156\n",
      "Loss 2:  0.02215984463840432\n",
      "Error:  3.8049125178352128e-06\n",
      "\n",
      " 0.6953094997942678 1.1447278480647136\n",
      "\n",
      "Loss 1:  0.02215984463840432\n",
      "Loss 2:  0.022156065410922927\n",
      "Error:  3.7792274813937266e-06\n",
      "\n",
      " 0.6952577389556461 1.1449147211157633\n",
      "\n",
      "Loss 1:  0.022156065410922927\n",
      "Loss 2:  0.022152311695091305\n",
      "Error:  3.7537158316218455e-06\n",
      "\n",
      " 0.6952061531184581 1.1451009623561093\n",
      "\n",
      "Loss 1:  0.022152311695091305\n",
      "Loss 2:  0.022148583318693287\n",
      "Error:  3.7283763980183737e-06\n",
      "\n",
      " 0.6951547416910308 1.1452865739218796\n",
      "\n",
      "Loss 1:  0.022148583318693287\n",
      "Loss 2:  0.022144880110675162\n",
      "Error:  3.7032080181242932e-06\n",
      "\n",
      " 0.6951035040836911 1.14547155794198\n",
      "\n",
      "Loss 1:  0.022144880110675162\n",
      "Loss 2:  0.02214120190113796\n",
      "Error:  3.678209537203575e-06\n",
      "\n",
      " 0.6950524397087603 1.145655916538119\n",
      "\n",
      "Loss 1:  0.02214120190113796\n",
      "Loss 2:  0.022137548521329646\n",
      "Error:  3.653379808312568e-06\n",
      "\n",
      " 0.6950015479805459 1.145839651824831\n",
      "\n",
      "Loss 1:  0.022137548521329646\n",
      "Loss 2:  0.02213391980363713\n",
      "Error:  3.6287176925151043e-06\n",
      "\n",
      " 0.6949508283153359 1.1460227659095017\n",
      "\n",
      "Loss 1:  0.02213391980363713\n",
      "Loss 2:  0.02213031558157917\n",
      "Error:  3.6042220579596274e-06\n",
      "\n",
      " 0.6949002801313919 1.1462052608923916\n",
      "\n",
      "Loss 1:  0.02213031558157917\n",
      "Loss 2:  0.022126735689798057\n",
      "Error:  3.579891781114314e-06\n",
      "\n",
      " 0.6948499028489422 1.1463871388666602\n",
      "\n",
      "Loss 1:  0.022126735689798057\n",
      "Loss 2:  0.022123179964052504\n",
      "Error:  3.555725745552768e-06\n",
      "\n",
      " 0.6947996958901753 1.1465684019183904\n",
      "\n",
      "Loss 1:  0.022123179964052504\n",
      "Loss 2:  0.02211964824120972\n",
      "Error:  3.5317228427832192e-06\n",
      "\n",
      " 0.6947496586792333 1.1467490521266122\n",
      "\n",
      "Loss 1:  0.02211964824120972\n",
      "Loss 2:  0.022116140359238277\n",
      "Error:  3.5078819714436105e-06\n",
      "\n",
      " 0.6946997906422052 1.146929091563326\n",
      "\n",
      "Loss 1:  0.022116140359238277\n",
      "Loss 2:  0.02211265615720064\n",
      "Error:  3.4842020376381344e-06\n",
      "\n",
      " 0.6946500912071205 1.147108522293527\n",
      "\n",
      "Loss 1:  0.02211265615720064\n",
      "Loss 2:  0.022109195475245542\n",
      "Error:  3.460681955096828e-06\n",
      "\n",
      " 0.6946005598039424 1.1472873463752293\n",
      "\n",
      "Loss 1:  0.022109195475245542\n",
      "Loss 2:  0.022105758154600738\n",
      "Error:  3.4373206448043425e-06\n",
      "\n",
      " 0.6945511958645613 1.1474655658594881\n",
      "\n",
      "Loss 1:  0.022105758154600738\n",
      "Loss 2:  0.022102344037565995\n",
      "Error:  3.4141170347432026e-06\n",
      "\n",
      " 0.6945019988227885 1.1476431827904248\n",
      "\n",
      "Loss 1:  0.022102344037565995\n",
      "Loss 2:  0.022098952967505348\n",
      "Error:  3.391070060646678e-06\n",
      "\n",
      " 0.6944529681143495 1.147820199205249\n",
      "\n",
      "Loss 1:  0.022098952967505348\n",
      "Loss 2:  0.022095584788840505\n",
      "Error:  3.3681786648434575e-06\n",
      "\n",
      " 0.6944041031768776 1.147996617134283\n",
      "\n",
      "Loss 1:  0.022095584788840505\n",
      "Loss 2:  0.022092239347043113\n",
      "Error:  3.345441797392157e-06\n",
      "\n",
      " 0.6943554034499075 1.1481724386009846\n",
      "\n",
      "Loss 1:  0.022092239347043113\n",
      "Loss 2:  0.022088916488628187\n",
      "Error:  3.3228584149259943e-06\n",
      "\n",
      " 0.6943068683748688 1.1483476656219704\n",
      "\n",
      "Loss 1:  0.022088916488628187\n",
      "Loss 2:  0.02208561606114679\n",
      "Error:  3.3004274813952517e-06\n",
      "\n",
      " 0.6942584973950794 1.1485223002070388\n",
      "\n",
      "Loss 1:  0.02208561606114679\n",
      "Loss 2:  0.022082337913178887\n",
      "Error:  3.2781479679042103e-06\n",
      "\n",
      " 0.6942102899557396 1.1486963443591933\n",
      "\n",
      "Loss 1:  0.022082337913178887\n",
      "Loss 2:  0.022079081894326936\n",
      "Error:  3.2560188519513422e-06\n",
      "\n",
      " 0.6941622455039252 1.148869800074665\n",
      "\n",
      "Loss 1:  0.022079081894326936\n",
      "Loss 2:  0.02207584785520847\n",
      "Error:  3.234039118466675e-06\n",
      "\n",
      " 0.6941143634885818 1.1490426693429363\n",
      "\n",
      "Loss 1:  0.02207584785520847\n",
      "Loss 2:  0.022072635647449365\n",
      "Error:  3.2122077591040243e-06\n",
      "\n",
      " 0.6940666433605176 1.1492149541467627\n",
      "\n",
      "Loss 1:  0.022072635647449365\n",
      "Loss 2:  0.02206944512367723\n",
      "Error:  3.190523772133441e-06\n",
      "\n",
      " 0.6940190845723979 1.1493866564621964\n",
      "\n",
      "Loss 1:  0.02206944512367723\n",
      "Loss 2:  0.022066276137514447\n",
      "Error:  3.168986162784687e-06\n",
      "\n",
      " 0.6939716865787385 1.1495577782586086\n",
      "\n",
      "Loss 1:  0.022066276137514447\n",
      "Loss 2:  0.02206312854357156\n",
      "Error:  3.147593942886412e-06\n",
      "\n",
      " 0.6939244488358995 1.1497283214987122\n",
      "\n",
      "Loss 1:  0.02206312854357156\n",
      "Loss 2:  0.022060002197440445\n",
      "Error:  3.1263461311159535e-06\n",
      "\n",
      " 0.6938773708020789 1.149898288138584\n",
      "\n",
      "Loss 1:  0.022060002197440445\n",
      "Loss 2:  0.022056896955687973\n",
      "Error:  3.105241752471982e-06\n",
      "\n",
      " 0.6938304519373065 1.1500676801276875\n",
      "\n",
      "Loss 1:  0.022056896955687973\n",
      "Loss 2:  0.022053812675849136\n",
      "Error:  3.084279838836551e-06\n",
      "\n",
      " 0.6937836917034378 1.1502364994088954\n",
      "\n",
      "Loss 1:  0.022053812675849136\n",
      "Loss 2:  0.02205074921642075\n",
      "Error:  3.06345942838529e-06\n",
      "\n",
      " 0.6937370895641477 1.150404747918511\n",
      "\n",
      "Loss 1:  0.02205074921642075\n",
      "Loss 2:  0.022047706436854643\n",
      "Error:  3.0427795661078227e-06\n",
      "\n",
      " 0.6936906449849245 1.150572427586292\n",
      "\n",
      "Loss 1:  0.022047706436854643\n",
      "Loss 2:  0.022044684197551623\n",
      "Error:  3.022239303020202e-06\n",
      "\n",
      " 0.6936443574330636 1.1507395403354708\n",
      "\n",
      "Loss 1:  0.022044684197551623\n",
      "Loss 2:  0.02204168235985483\n",
      "Error:  3.0018376967928806e-06\n",
      "\n",
      " 0.6935982263776613 1.1509060880827775\n",
      "\n",
      "Loss 1:  0.02204168235985483\n",
      "Loss 2:  0.022038700786043218\n",
      "Error:  2.9815738116119317e-06\n",
      "\n",
      " 0.6935522512896092 1.1510720727384622\n",
      "\n",
      "Loss 1:  0.022038700786043218\n",
      "Loss 2:  0.022035739339325715\n",
      "Error:  2.9614467175025083e-06\n",
      "\n",
      " 0.6935064316415874 1.1512374962063165\n",
      "\n",
      "Loss 1:  0.022035739339325715\n",
      "Loss 2:  0.022032797883834405\n",
      "Error:  2.941455491310696e-06\n",
      "\n",
      " 0.6934607669080592 1.151402360383695\n",
      "\n",
      "Loss 1:  0.022032797883834405\n",
      "Loss 2:  0.02202987628461872\n",
      "Error:  2.9215992156834958e-06\n",
      "\n",
      " 0.6934152565652645 1.1515666671615374\n",
      "\n",
      "Loss 1:  0.02202987628461872\n",
      "Loss 2:  0.022026974407638955\n",
      "Error:  2.9018769797661825e-06\n",
      "\n",
      " 0.693369900091214 1.1517304184243908\n",
      "\n",
      "Loss 1:  0.022026974407638955\n",
      "Loss 2:  0.022024092119760322\n",
      "Error:  2.882287878633316e-06\n",
      "\n",
      " 0.6933246969656834 1.1518936160504303\n",
      "\n",
      "Loss 1:  0.022024092119760322\n",
      "Loss 2:  0.022021229288746693\n",
      "Error:  2.862831013628747e-06\n",
      "\n",
      " 0.6932796466702073 1.1520562619114807\n",
      "\n",
      "Loss 1:  0.022021229288746693\n",
      "Loss 2:  0.022018385783254567\n",
      "Error:  2.843505492126225e-06\n",
      "\n",
      " 0.6932347486880728 1.1522183578730387\n",
      "\n",
      "Loss 1:  0.022018385783254567\n",
      "Loss 2:  0.022015561472827315\n",
      "Error:  2.8243104272518416e-06\n",
      "\n",
      " 0.6931900025043144 1.1523799057942936\n",
      "\n",
      "Loss 1:  0.022015561472827315\n",
      "Loss 2:  0.02201275622788868\n",
      "Error:  2.8052449386334333e-06\n",
      "\n",
      " 0.6931454076057076 1.152540907528149\n",
      "\n",
      "Loss 1:  0.02201275622788868\n",
      "Loss 2:  0.022009969919737166\n",
      "Error:  2.7863081515158705e-06\n",
      "\n",
      " 0.693100963480763 1.1527013649212434\n",
      "\n",
      "Loss 1:  0.022009969919737166\n",
      "Loss 2:  0.022007202420540186\n",
      "Error:  2.7674991969796336e-06\n",
      "\n",
      " 0.6930566696197206 1.1528612798139728\n",
      "\n",
      "Loss 1:  0.022007202420540186\n",
      "Loss 2:  0.022004453603328\n",
      "Error:  2.7488172121871435e-06\n",
      "\n",
      " 0.6930125255145436 1.1530206540405101\n",
      "\n",
      "Loss 1:  0.022004453603328\n",
      "Loss 2:  0.02200172334198794\n",
      "Error:  2.730261340060103e-06\n",
      "\n",
      " 0.6929685306589134 1.1531794894288272\n",
      "\n",
      "Loss 1:  0.02200172334198794\n",
      "Loss 2:  0.02199901151125886\n",
      "Error:  2.7118307290782684e-06\n",
      "\n",
      " 0.6929246845482228 1.1533377878007158\n",
      "\n",
      "Loss 1:  0.02199901151125886\n",
      "Loss 2:  0.02199631798672489\n",
      "Error:  2.693524533969871e-06\n",
      "\n",
      " 0.6928809866795708 1.1534955509718081\n",
      "\n",
      "Loss 1:  0.02199631798672489\n",
      "Loss 2:  0.021993642644810258\n",
      "Error:  2.6753419146326174e-06\n",
      "\n",
      " 0.6928374365517567 1.1536527807515977\n",
      "\n",
      "Loss 1:  0.021993642644810258\n",
      "Loss 2:  0.02199098536277331\n",
      "Error:  2.6572820369490102e-06\n",
      "\n",
      " 0.6927940336652744 1.1538094789434603\n",
      "\n",
      "Loss 1:  0.02199098536277331\n",
      "Loss 2:  0.02198834601870098\n",
      "Error:  2.639344072328381e-06\n",
      "\n",
      " 0.6927507775223064 1.1539656473446747\n",
      "\n",
      "Loss 1:  0.02198834601870098\n",
      "Loss 2:  0.0219857244915031\n",
      "Error:  2.6215271978803634e-06\n",
      "\n",
      " 0.6927076676267185 1.1541212877464428\n",
      "\n",
      "Loss 1:  0.0219857244915031\n",
      "Loss 2:  0.021983120660907032\n",
      "Error:  2.6038305960679464e-06\n",
      "\n",
      " 0.6926647034840538 1.154276401933911\n",
      "\n",
      "Loss 1:  0.021983120660907032\n",
      "Loss 2:  0.021980534407451888\n",
      "Error:  2.586253455144627e-06\n",
      "\n",
      " 0.6926218846015273 1.1544309916861895\n",
      "\n",
      "Loss 1:  0.021980534407451888\n",
      "Loss 2:  0.02197796561248336\n",
      "Error:  2.568794968526439e-06\n",
      "\n",
      " 0.69257921048802 1.154585058776374\n",
      "\n",
      "Loss 1:  0.02197796561248336\n",
      "Loss 2:  0.021975414158148184\n",
      "Error:  2.5514543351770613e-06\n",
      "\n",
      " 0.6925366806540731 1.1547386049715653\n",
      "\n",
      "Loss 1:  0.021975414158148184\n",
      "Loss 2:  0.02197287992738832\n",
      "Error:  2.5342307598645586e-06\n",
      "\n",
      " 0.6924942946118832 1.1548916320328897\n",
      "\n",
      "Loss 1:  0.02197287992738832\n",
      "Loss 2:  0.021970362803936223\n",
      "Error:  2.5171234520962593e-06\n",
      "\n",
      " 0.6924520518752955 1.1550441417155188\n",
      "\n",
      "Loss 1:  0.021970362803936223\n",
      "Loss 2:  0.021967862672309157\n",
      "Error:  2.5001316270659157e-06\n",
      "\n",
      " 0.6924099519597994 1.1551961357686906\n",
      "\n",
      "Loss 1:  0.021967862672309157\n",
      "Loss 2:  0.02196537941780392\n",
      "Error:  2.48325450523737e-06\n",
      "\n",
      " 0.6923679943825221 1.1553476159357288\n",
      "\n",
      "Loss 1:  0.02196537941780392\n",
      "Loss 2:  0.02196291292649153\n",
      "Error:  2.466491312389657e-06\n",
      "\n",
      " 0.6923261786622235 1.1554985839540628\n",
      "\n",
      "Loss 1:  0.02196291292649153\n",
      "Loss 2:  0.02196046308521225\n",
      "Error:  2.449841279280468e-06\n",
      "\n",
      " 0.6922845043192906 1.155649041555248\n",
      "\n",
      "Loss 1:  0.02196046308521225\n",
      "Loss 2:  0.02195802978157007\n",
      "Error:  2.4333036421804455e-06\n",
      "\n",
      " 0.6922429708757317 1.1557989904649857\n",
      "\n",
      "Loss 1:  0.02195802978157007\n",
      "Loss 2:  0.021955612903927883\n",
      "Error:  2.4168776421862326e-06\n",
      "\n",
      " 0.6922015778551716 1.1559484324031422\n",
      "\n",
      "Loss 1:  0.021955612903927883\n",
      "Loss 2:  0.02195321234140201\n",
      "Error:  2.4005625258727292e-06\n",
      "\n",
      " 0.6921603247828453 1.156097369083769\n",
      "\n",
      "Loss 1:  0.02195321234140201\n",
      "Loss 2:  0.021950827983857387\n",
      "Error:  2.384357544623489e-06\n",
      "\n",
      " 0.6921192111855932 1.156245802215123\n",
      "\n",
      "Loss 1:  0.021950827983857387\n",
      "Loss 2:  0.021948459721902413\n",
      "Error:  2.3682619549741935e-06\n",
      "\n",
      " 0.6920782365918553 1.156393733499685\n",
      "\n",
      "Loss 1:  0.021948459721902413\n",
      "Loss 2:  0.021946107446883852\n",
      "Error:  2.3522750185606123e-06\n",
      "\n",
      " 0.6920374005316661 1.1565411646341799\n",
      "\n",
      "Loss 1:  0.021946107446883852\n",
      "Loss 2:  0.021943771050882112\n",
      "Error:  2.3363960017404317e-06\n",
      "\n",
      " 0.6919967025366487 1.1566880973095963\n",
      "\n",
      "Loss 1:  0.021943771050882112\n",
      "Loss 2:  0.02194145042670591\n",
      "Error:  2.3206241762004087e-06\n",
      "\n",
      " 0.6919561421400102 1.1568345332112056\n",
      "\n",
      "Loss 1:  0.02194145042670591\n",
      "Loss 2:  0.02193914546788765\n",
      "Error:  2.3049588182624814e-06\n",
      "\n",
      " 0.6919157188765356 1.1569804740185807\n",
      "\n",
      "Loss 1:  0.02193914546788765\n",
      "Loss 2:  0.021936856068678425\n",
      "Error:  2.2893992092237747e-06\n",
      "\n",
      " 0.6918754322825829 1.1571259214056169\n",
      "\n",
      "Loss 1:  0.021936856068678425\n",
      "Loss 2:  0.021934582124043266\n",
      "Error:  2.273944635158842e-06\n",
      "\n",
      " 0.6918352818960776 1.1572708770405495\n",
      "\n",
      "Loss 1:  0.021934582124043266\n",
      "Loss 2:  0.021932323529656135\n",
      "Error:  2.258594387131302e-06\n",
      "\n",
      " 0.6917952672565075 1.157415342585974\n",
      "\n",
      "Loss 1:  0.021932323529656135\n",
      "Loss 2:  0.021930080181895302\n",
      "Error:  2.2433477608330143e-06\n",
      "\n",
      " 0.6917553879049174 1.157559319698864\n",
      "\n",
      "Loss 1:  0.021930080181895302\n",
      "Loss 2:  0.021927851977838517\n",
      "Error:  2.22820405678531e-06\n",
      "\n",
      " 0.6917156433839038 1.1577028100305917\n",
      "\n",
      "Loss 1:  0.021927851977838517\n",
      "Loss 2:  0.021925638815258195\n",
      "Error:  2.2131625803216426e-06\n",
      "\n",
      " 0.6916760332376094 1.1578458152269457\n",
      "\n",
      "Loss 1:  0.021925638815258195\n",
      "Loss 2:  0.021923440592617083\n",
      "Error:  2.198222641112274e-06\n",
      "\n",
      " 0.6916365570117186 1.1579883369281503\n",
      "\n",
      "Loss 1:  0.021923440592617083\n",
      "Loss 2:  0.021921257209063252\n",
      "Error:  2.183383553830409e-06\n",
      "\n",
      " 0.6915972142534514 1.1581303767688842\n",
      "\n",
      "Loss 1:  0.021921257209063252\n",
      "Loss 2:  0.021919088564425364\n",
      "Error:  2.168644637888517e-06\n",
      "\n",
      " 0.691558004511559 1.1582719363782994\n",
      "\n",
      "Loss 1:  0.021919088564425364\n",
      "Loss 2:  0.02191693455920867\n",
      "Error:  2.1540052166924006e-06\n",
      "\n",
      " 0.691518927336318 1.1584130173800398\n",
      "\n",
      "Loss 1:  0.02191693455920867\n",
      "Loss 2:  0.021914795094589736\n",
      "Error:  2.1394646189352995e-06\n",
      "\n",
      " 0.6914799822795257 1.1585536213922598\n",
      "\n",
      "Loss 1:  0.021914795094589736\n",
      "Loss 2:  0.02191267007241238\n",
      "Error:  2.1250221773558287e-06\n",
      "\n",
      " 0.6914411688944945 1.158693750027643\n",
      "\n",
      "Loss 1:  0.02191267007241238\n",
      "Loss 2:  0.021910559395183042\n",
      "Error:  2.1106772293381926e-06\n",
      "\n",
      " 0.6914024867360471 1.1588334048934206\n",
      "\n",
      "Loss 1:  0.021910559395183042\n",
      "Loss 2:  0.021908462966066137\n",
      "Error:  2.0964291169052462e-06\n",
      "\n",
      " 0.6913639353605114 1.1589725875913894\n",
      "\n",
      "Loss 1:  0.021908462966066137\n",
      "Loss 2:  0.021906380688880008\n",
      "Error:  2.0822771861286893e-06\n",
      "\n",
      " 0.6913255143257155 1.159111299717931\n",
      "\n",
      "Loss 1:  0.021906380688880008\n",
      "Loss 2:  0.021904312468092\n",
      "Error:  2.068220788006836e-06\n",
      "\n",
      " 0.6912872231909822 1.1592495428640293\n",
      "\n",
      "Loss 1:  0.021904312468092\n",
      "Loss 2:  0.021902258208814557\n",
      "Error:  2.054259277444598e-06\n",
      "\n",
      " 0.6912490615171244 1.1593873186152897\n",
      "\n",
      "Loss 1:  0.021902258208814557\n",
      "Loss 2:  0.021900217816800675\n",
      "Error:  2.0403920138814535e-06\n",
      "\n",
      " 0.6912110288664396 1.1595246285519565\n",
      "\n",
      "Loss 1:  0.021900217816800675\n",
      "Loss 2:  0.021898191198439367\n",
      "Error:  2.0266183613087962e-06\n",
      "\n",
      " 0.6911731248027054 1.159661474248931\n",
      "\n",
      "Loss 1:  0.021898191198439367\n",
      "Loss 2:  0.021896178260751745\n",
      "Error:  2.012937687621147e-06\n",
      "\n",
      " 0.6911353488911743 1.15979785727579\n",
      "\n",
      "Loss 1:  0.021896178260751745\n",
      "Loss 2:  0.021894178911386508\n",
      "Error:  1.999349365237185e-06\n",
      "\n",
      " 0.6910977006985686 1.1599337791968038\n",
      "\n",
      "Loss 1:  0.021894178911386508\n",
      "Loss 2:  0.02189219305861578\n",
      "Error:  1.985852770728519e-06\n",
      "\n",
      " 0.6910601797930752 1.1600692415709537\n",
      "\n",
      "Loss 1:  0.02189219305861578\n",
      "Loss 2:  0.0218902206113309\n",
      "Error:  1.9724472848786645e-06\n",
      "\n",
      " 0.6910227857443414 1.1602042459519502\n",
      "\n",
      "Loss 1:  0.0218902206113309\n",
      "Loss 2:  0.02188826147903814\n",
      "Error:  1.9591322927593746e-06\n",
      "\n",
      " 0.6909855181234693 1.1603387938882506\n",
      "\n",
      "Loss 1:  0.02188826147903814\n",
      "Loss 2:  0.021886315571854855\n",
      "Error:  1.9459071832865493e-06\n",
      "\n",
      " 0.690948376503011 1.1604728869230774\n",
      "\n",
      "Loss 1:  0.021886315571854855\n",
      "Loss 2:  0.021884382800504927\n",
      "Error:  1.932771349928003e-06\n",
      "\n",
      " 0.6909113604569639 1.1606065265944352\n",
      "\n",
      "Loss 1:  0.021884382800504927\n",
      "Loss 2:  0.021882463076315053\n",
      "Error:  1.9197241898742667e-06\n",
      "\n",
      " 0.6908744695607657 1.1607397144351286\n",
      "\n",
      "Loss 1:  0.021882463076315053\n",
      "Loss 2:  0.021880556311210532\n",
      "Error:  1.9067651045208411e-06\n",
      "\n",
      " 0.6908377033912895 1.16087245197278\n",
      "\n",
      "Loss 1:  0.021880556311210532\n",
      "Loss 2:  0.02187866241771102\n",
      "Error:  1.8938934995132994e-06\n",
      "\n",
      " 0.690801061526839 1.161004740729847\n",
      "\n",
      "Loss 1:  0.02187866241771102\n",
      "Loss 2:  0.021876781308926892\n",
      "Error:  1.8811087841262564e-06\n",
      "\n",
      " 0.6907645435471436 1.1611365822236397\n",
      "\n",
      "Loss 1:  0.021876781308926892\n",
      "Loss 2:  0.02187491289855497\n",
      "Error:  1.868410371922563e-06\n",
      "\n",
      " 0.6907281490333536 1.1612679779663382\n",
      "\n",
      "Loss 1:  0.02187491289855497\n",
      "Loss 2:  0.021873057100874803\n",
      "Error:  1.8557976801669707e-06\n",
      "\n",
      " 0.6906918775680355 1.1613989294650102\n",
      "\n",
      "Loss 1:  0.021873057100874803\n",
      "Loss 2:  0.021871213830744474\n",
      "Error:  1.8432701303291998e-06\n",
      "\n",
      " 0.6906557287351671 1.161529438221628\n",
      "\n",
      "Loss 1:  0.021871213830744474\n",
      "Loss 2:  0.021869383003596775\n",
      "Error:  1.8308271476988325e-06\n",
      "\n",
      " 0.6906197021201327 1.1616595057330854\n",
      "\n",
      "Loss 1:  0.021869383003596775\n",
      "Loss 2:  0.021867564535435476\n",
      "Error:  1.8184681612985754e-06\n",
      "\n",
      " 0.6905837973097183 1.1617891334912158\n",
      "\n",
      "Loss 1:  0.021867564535435476\n",
      "Loss 2:  0.02186575834283129\n",
      "Error:  1.806192604186102e-06\n",
      "\n",
      " 0.6905480138921073 1.1619183229828085\n",
      "\n",
      "Loss 1:  0.02186575834283129\n",
      "Loss 2:  0.02186396434291818\n",
      "Error:  1.7939999131105777e-06\n",
      "\n",
      " 0.6905123514568752 1.162047075689626\n",
      "\n",
      "Loss 1:  0.02186396434291818\n",
      "Loss 2:  0.021862182453389507\n",
      "Error:  1.7818895286722536e-06\n",
      "\n",
      " 0.690476809594985 1.1621753930884209\n",
      "\n",
      "Loss 1:  0.021862182453389507\n",
      "Loss 2:  0.021860412592494174\n",
      "Error:  1.7698608953328754e-06\n",
      "\n",
      " 0.6904413878987831 1.1623032766509533\n",
      "\n",
      "Loss 1:  0.021860412592494174\n",
      "Loss 2:  0.02185865467903293\n",
      "Error:  1.7579134612456804e-06\n",
      "\n",
      " 0.6904060859619936 1.1624307278440074\n",
      "\n",
      "Loss 1:  0.02185865467903293\n",
      "Loss 2:  0.021856908632354698\n",
      "Error:  1.7460466782311113e-06\n",
      "\n",
      " 0.6903709033797145 1.1625577481294076\n",
      "\n",
      "Loss 1:  0.021856908632354698\n",
      "Loss 2:  0.021855174372352897\n",
      "Error:  1.7342600018011023e-06\n",
      "\n",
      " 0.6903358397484128 1.1626843389640367\n",
      "\n",
      "Loss 1:  0.021855174372352897\n",
      "Loss 2:  0.021853451819461613\n",
      "Error:  1.7225528912839794e-06\n",
      "\n",
      " 0.6903008946659198 1.1628105017998511\n",
      "\n",
      "Loss 1:  0.021853451819461613\n",
      "Loss 2:  0.021851740894652104\n",
      "Error:  1.7109248095087404e-06\n",
      "\n",
      " 0.6902660677314264 1.162936238083899\n",
      "\n",
      "Loss 1:  0.021851740894652104\n",
      "Loss 2:  0.02185004151942906\n",
      "Error:  1.699375223044447e-06\n",
      "\n",
      " 0.6902313585454787 1.1630615492583354\n",
      "\n",
      "Loss 1:  0.02185004151942906\n",
      "Loss 2:  0.021848353615827043\n",
      "Error:  1.687903602016344e-06\n",
      "\n",
      " 0.6901967667099732 1.1631864367604399\n",
      "\n",
      "Loss 1:  0.021848353615827043\n",
      "Loss 2:  0.021846677106407038\n",
      "Error:  1.6765094200052455e-06\n",
      "\n",
      " 0.6901622918281527 1.1633109020226327\n",
      "\n",
      "Loss 1:  0.021846677106407038\n",
      "Loss 2:  0.021845011914252643\n",
      "Error:  1.6651921543944792e-06\n",
      "\n",
      " 0.6901279335046011 1.163434946472491\n",
      "\n",
      "Loss 1:  0.021845011914252643\n",
      "Loss 2:  0.021843357962966718\n",
      "Error:  1.6539512859257977e-06\n",
      "\n",
      " 0.6900936913452393 1.163558571532765\n",
      "\n",
      "Loss 1:  0.021843357962966718\n",
      "Loss 2:  0.02184171517666788\n",
      "Error:  1.6427862988381559e-06\n",
      "\n",
      " 0.6900595649573208 1.1636817786213953\n",
      "\n",
      "Loss 1:  0.02184171517666788\n",
      "Loss 2:  0.02184008347998687\n",
      "Error:  1.6316966810099587e-06\n",
      "\n",
      " 0.6900255539494264 1.1638045691515282\n",
      "\n",
      "Loss 1:  0.02184008347998687\n",
      "Loss 2:  0.021838462798063403\n",
      "Error:  1.6206819234663994e-06\n",
      "\n",
      " 0.6899916579314609 1.1639269445315321\n",
      "\n",
      "Loss 1:  0.021838462798063403\n",
      "Loss 2:  0.02183685305654248\n",
      "Error:  1.6097415209241628e-06\n",
      "\n",
      " 0.6899578765146476 1.1640489061650139\n",
      "\n",
      "Loss 1:  0.02183685305654248\n",
      "Loss 2:  0.02183525418157084\n",
      "Error:  1.5988749716387696e-06\n",
      "\n",
      " 0.6899242093115242 1.1641704554508348\n",
      "\n",
      "Loss 1:  0.02183525418157084\n",
      "Loss 2:  0.021833666099794\n",
      "Error:  1.5880817768390565e-06\n",
      "\n",
      " 0.6898906559359388 1.1642915937831266\n",
      "\n",
      "Loss 1:  0.021833666099794\n",
      "Loss 2:  0.02183208873835258\n",
      "Error:  1.5773614414210657e-06\n",
      "\n",
      " 0.6898572160030446 1.1644123225513077\n",
      "\n",
      "Loss 1:  0.02183208873835258\n",
      "Loss 2:  0.02183052202487903\n",
      "Error:  1.5667134735490584e-06\n",
      "\n",
      " 0.6898238891292964 1.1645326431400989\n",
      "\n",
      "Loss 1:  0.02183052202487903\n",
      "Loss 2:  0.021828965887494247\n",
      "Error:  1.5561373847838844e-06\n",
      "\n",
      " 0.6897906749324453 1.1646525569295392\n",
      "\n",
      "Loss 1:  0.021828965887494247\n",
      "Loss 2:  0.021827420254804455\n",
      "Error:  1.5456326897915484e-06\n",
      "\n",
      " 0.689757573031535 1.1647720652950018\n",
      "\n",
      "Loss 1:  0.021827420254804455\n",
      "Loss 2:  0.02182588505589777\n",
      "Error:  1.5351989066866856e-06\n",
      "\n",
      " 0.6897245830468971 1.1648911696072097\n",
      "\n",
      "Loss 1:  0.02182588505589777\n",
      "Loss 2:  0.021824360220341024\n",
      "Error:  1.524835556744597e-06\n",
      "\n",
      " 0.6896917046001472 1.1650098712322516\n",
      "\n",
      "Loss 1:  0.021824360220341024\n",
      "Loss 2:  0.021822845678176488\n",
      "Error:  1.5145421645365587e-06\n",
      "\n",
      " 0.6896589373141797 1.1651281715315978\n",
      "\n",
      "Loss 1:  0.021822845678176488\n",
      "Loss 2:  0.021821341359918728\n",
      "Error:  1.504318257759818e-06\n",
      "\n",
      " 0.6896262808131642 1.165246071862115\n",
      "\n",
      "Loss 1:  0.021821341359918728\n",
      "Loss 2:  0.021819847196551282\n",
      "Error:  1.494163367445761e-06\n",
      "\n",
      " 0.6895937347225413 1.1653635735760828\n",
      "\n",
      "Loss 1:  0.021819847196551282\n",
      "Loss 2:  0.02181836311952362\n",
      "Error:  1.48407702766154e-06\n",
      "\n",
      " 0.6895612986690172 1.1654806780212086\n",
      "\n",
      "Loss 1:  0.02181836311952362\n",
      "Loss 2:  0.021816889060747958\n",
      "Error:  1.4740587756627288e-06\n",
      "\n",
      " 0.6895289722805609 1.1655973865406435\n",
      "\n",
      "Loss 1:  0.021816889060747958\n",
      "Loss 2:  0.021815424952596252\n",
      "Error:  1.4641081517059729e-06\n",
      "\n",
      " 0.6894967551863989 1.165713700472997\n",
      "\n",
      "Loss 1:  0.021815424952596252\n",
      "Loss 2:  0.02181397072789678\n",
      "Error:  1.4542246994722619e-06\n",
      "\n",
      " 0.6894646470170113 1.1658296211523531\n",
      "\n",
      "Loss 1:  0.02181397072789678\n",
      "Loss 2:  0.021812526319931372\n",
      "Error:  1.4444079654077346e-06\n",
      "\n",
      " 0.6894326474041276 1.1659451499082853\n",
      "\n",
      "Loss 1:  0.021812526319931372\n",
      "Loss 2:  0.021811091662432343\n",
      "Error:  1.4346574990289906e-06\n",
      "\n",
      " 0.6894007559807224 1.166060288065872\n",
      "\n",
      "Loss 1:  0.021811091662432343\n",
      "Loss 2:  0.02180966668957906\n",
      "Error:  1.4249728532839123e-06\n",
      "\n",
      " 0.6893689723810111 1.1661750369457111\n",
      "\n",
      "Loss 1:  0.02180966668957906\n",
      "Loss 2:  0.021808251335995565\n",
      "Error:  1.4153535834934838e-06\n",
      "\n",
      " 0.689337296240446 1.1662893978639362\n",
      "\n",
      "Loss 1:  0.021808251335995565\n",
      "Loss 2:  0.021806845536746923\n",
      "Error:  1.4057992486424253e-06\n",
      "\n",
      " 0.6893057271957117 1.1664033721322307\n",
      "\n",
      "Loss 1:  0.021806845536746923\n",
      "Loss 2:  0.02180544922733664\n",
      "Error:  1.3963094102828477e-06\n",
      "\n",
      " 0.6892742648847213 1.1665169610578434\n",
      "\n",
      "Loss 1:  0.02180544922733664\n",
      "Loss 2:  0.021804062343703738\n",
      "Error:  1.386883632902014e-06\n",
      "\n",
      " 0.689242908946612 1.1666301659436034\n",
      "\n",
      "Loss 1:  0.021804062343703738\n",
      "Loss 2:  0.02180268482221944\n",
      "Error:  1.3775214842970396e-06\n",
      "\n",
      " 0.6892116590217412 1.1667429880879345\n",
      "\n",
      "Loss 1:  0.02180268482221944\n",
      "Loss 2:  0.021801316599684824\n",
      "Error:  1.368222534617325e-06\n",
      "\n",
      " 0.6891805147516821 1.1668554287848714\n",
      "\n",
      "Loss 1:  0.021801316599684824\n",
      "Loss 2:  0.021799957613327165\n",
      "Error:  1.3589863576586592e-06\n",
      "\n",
      " 0.6891494757792197 1.166967489324073\n",
      "\n",
      "Loss 1:  0.021799957613327165\n",
      "Loss 2:  0.021798607800797815\n",
      "Error:  1.3498125293505414e-06\n",
      "\n",
      " 0.689118541748347 1.1670791709908384\n",
      "\n",
      "Loss 1:  0.021798607800797815\n",
      "Loss 2:  0.021797267100168872\n",
      "Error:  1.3407006289427315e-06\n",
      "\n",
      " 0.6890877123042604 1.1671904750661208\n",
      "\n",
      "Loss 1:  0.021797267100168872\n",
      "Loss 2:  0.021795935449930626\n",
      "Error:  1.331650238245441e-06\n",
      "\n",
      " 0.6890569870933558 1.1673014028265427\n",
      "\n",
      "Loss 1:  0.021795935449930626\n",
      "Loss 2:  0.021794612788988373\n",
      "Error:  1.3226609422538338e-06\n",
      "\n",
      " 0.689026365763225 1.1674119555444105\n",
      "\n",
      "Loss 1:  0.021794612788988373\n",
      "Loss 2:  0.021793299056659946\n",
      "Error:  1.3137323284263813e-06\n",
      "\n",
      " 0.6889958479626508 1.1675221344877287\n",
      "\n",
      "Loss 1:  0.021793299056659946\n",
      "Loss 2:  0.021791994192672755\n",
      "Error:  1.3048639871914014e-06\n",
      "\n",
      " 0.6889654333416039 1.1676319409202152\n",
      "\n",
      "Loss 1:  0.021791994192672755\n",
      "Loss 2:  0.02179069813716116\n",
      "Error:  1.2960555115931749e-06\n",
      "\n",
      " 0.6889351215512381 1.1677413761013147\n",
      "\n",
      "Loss 1:  0.02179069813716116\n",
      "Loss 2:  0.0217894108306637\n",
      "Error:  1.2873064974619486e-06\n",
      "\n",
      " 0.6889049122438868 1.167850441286214\n",
      "\n",
      "Loss 1:  0.0217894108306637\n",
      "Loss 2:  0.021788132214120008\n",
      "Error:  1.278616543691491e-06\n",
      "\n",
      " 0.6888748050730589 1.1679591377258565\n",
      "\n",
      "Loss 1:  0.021788132214120008\n",
      "Loss 2:  0.021786862228868904\n",
      "Error:  1.2699852511045828e-06\n",
      "\n",
      " 0.6888447996934345 1.1680674666669557\n",
      "\n",
      "Loss 1:  0.021786862228868904\n",
      "Loss 2:  0.021785600816644587\n",
      "Error:  1.2614122243161108e-06\n",
      "\n",
      " 0.6888148957608615 1.1681754293520106\n",
      "\n",
      "Loss 1:  0.021785600816644587\n",
      "Loss 2:  0.0217843479195751\n",
      "Error:  1.2528970694883346e-06\n",
      "\n",
      " 0.6887850929323514 1.1682830270193187\n",
      "\n",
      "Loss 1:  0.0217843479195751\n",
      "Loss 2:  0.02178310348017889\n",
      "Error:  1.2444393962078582e-06\n",
      "\n",
      " 0.688755390866075 1.1683902609029913\n",
      "\n",
      "Loss 1:  0.02178310348017889\n",
      "Loss 2:  0.021781867441362464\n",
      "Error:  1.2360388164274483e-06\n",
      "\n",
      " 0.688725789221359 1.168497132232967\n",
      "\n",
      "Loss 1:  0.021781867441362464\n",
      "Loss 2:  0.021780639746417748\n",
      "Error:  1.2276949447158347e-06\n",
      "\n",
      " 0.688696287658682 1.168603642235026\n",
      "\n",
      "Loss 1:  0.021780639746417748\n",
      "Loss 2:  0.0217794203390196\n",
      "Error:  1.219407398146688e-06\n",
      "\n",
      " 0.6886668858396704 1.1687097921308047\n",
      "\n",
      "Loss 1:  0.0217794203390196\n",
      "Loss 2:  0.021778209163222883\n",
      "Error:  1.2111757967184222e-06\n",
      "\n",
      " 0.6886375834270946 1.1688155831378084\n",
      "\n",
      "Loss 1:  0.021778209163222883\n",
      "Loss 2:  0.021777006163460347\n",
      "Error:  1.202999762535406e-06\n",
      "\n",
      " 0.6886083800848652 1.1689210164694266\n",
      "\n",
      "Loss 1:  0.021777006163460347\n",
      "Loss 2:  0.02177581128453957\n",
      "Error:  1.194878920775938e-06\n",
      "\n",
      " 0.6885792754780292 1.1690260933349461\n",
      "\n",
      "Loss 1:  0.02177581128453957\n",
      "Loss 2:  0.021774624471640976\n",
      "Error:  1.1868128985959014e-06\n",
      "\n",
      " 0.688550269272766 1.1691308149395654\n",
      "\n",
      "Loss 1:  0.021774624471640976\n",
      "Loss 2:  0.0217734456703149\n",
      "Error:  1.1788013260759234e-06\n",
      "\n",
      " 0.6885213611363835 1.169235182484408\n",
      "\n",
      "Loss 1:  0.0217734456703149\n",
      "Loss 2:  0.021772274826479233\n",
      "Error:  1.1708438356662632e-06\n",
      "\n",
      " 0.6884925507373146 1.1693391971665368\n",
      "\n",
      "Loss 1:  0.021772274826479233\n",
      "Loss 2:  0.021771111886417116\n",
      "Error:  1.1629400621174235e-06\n",
      "\n",
      " 0.6884638377451132 1.1694428601789673\n",
      "\n",
      "Loss 1:  0.021771111886417116\n",
      "Loss 2:  0.021769956796774063\n",
      "Error:  1.1550896430526092e-06\n",
      "\n",
      " 0.6884352218304503 1.169546172710681\n",
      "\n",
      "Loss 1:  0.021769956796774063\n",
      "Loss 2:  0.02176880950455586\n",
      "Error:  1.1472922182044487e-06\n",
      "\n",
      " 0.6884067026651103 1.1696491359466403\n",
      "\n",
      "Loss 1:  0.02176880950455586\n",
      "Loss 2:  0.021767669957126135\n",
      "Error:  1.139547429723775e-06\n",
      "\n",
      " 0.6883782799219876 1.1697517510678008\n",
      "\n",
      "Loss 1:  0.021767669957126135\n",
      "Loss 2:  0.021766538102203727\n",
      "Error:  1.1318549224086094e-06\n",
      "\n",
      " 0.6883499532750823 1.1698540192511255\n",
      "\n",
      "Loss 1:  0.021766538102203727\n",
      "Loss 2:  0.021765413887860376\n",
      "Error:  1.1242143433502771e-06\n",
      "\n",
      " 0.6883217223994966 1.1699559416695982\n",
      "\n",
      "Loss 1:  0.021765413887860376\n",
      "Loss 2:  0.02176429726251841\n",
      "Error:  1.1166253419646333e-06\n",
      "\n",
      " 0.6882935869714315 1.1700575194922365\n",
      "\n",
      "Loss 1:  0.02176429726251841\n",
      "Loss 2:  0.02176318817494827\n",
      "Error:  1.1090875701412484e-06\n",
      "\n",
      " 0.6882655466681824 1.1701587538841058\n",
      "\n",
      "Loss 1:  0.02176318817494827\n",
      "Loss 2:  0.02176208657426641\n",
      "Error:  1.1016006818617696e-06\n",
      "\n",
      " 0.6882376011681359 1.1702596460063328\n",
      "\n",
      "Loss 1:  0.02176208657426641\n",
      "Loss 2:  0.021760992409932633\n",
      "Error:  1.0941643337758489e-06\n",
      "\n",
      " 0.688209750150766 1.170360197016118\n",
      "\n",
      "Loss 1:  0.021760992409932633\n",
      "Loss 2:  0.02175990563174777\n",
      "Error:  1.0867781848611369e-06\n",
      "\n",
      " 0.6881819932966304 1.1704604080667496\n",
      "\n",
      "Loss 1:  0.02175990563174777\n",
      "Loss 2:  0.021758826189851803\n",
      "Error:  1.0794418959687857e-06\n",
      "\n",
      " 0.6881543302873667 1.1705602803076167\n",
      "\n",
      "Loss 1:  0.021758826189851803\n",
      "Loss 2:  0.02175775403472112\n",
      "Error:  1.0721551306838717e-06\n",
      "\n",
      " 0.688126760805689 1.1706598148842224\n",
      "\n",
      "Loss 1:  0.02175775403472112\n",
      "Loss 2:  0.021756689117166435\n",
      "Error:  1.0649175546835477e-06\n",
      "\n",
      " 0.688099284535384 1.1707590129381966\n",
      "\n",
      "Loss 1:  0.021756689117166435\n",
      "Loss 2:  0.021755631388330594\n",
      "Error:  1.0577288358411263e-06\n",
      "\n",
      " 0.6880719011613078 1.1708578756073096\n",
      "\n",
      "Loss 1:  0.021755631388330594\n",
      "Loss 2:  0.021754580799686212\n",
      "Error:  1.0505886443822054e-06\n",
      "\n",
      " 0.6880446103693815 1.170956404025485\n",
      "\n",
      "Loss 1:  0.021754580799686212\n",
      "Loss 2:  0.0217535373030334\n",
      "Error:  1.0434966528118095e-06\n",
      "\n",
      " 0.6880174118465885 1.1710545993228123\n",
      "\n",
      "Loss 1:  0.0217535373030334\n",
      "Loss 2:  0.021752500850497687\n",
      "Error:  1.0364525357131615e-06\n",
      "\n",
      " 0.6879903052809703 1.1711524626255607\n",
      "\n",
      "Loss 1:  0.021752500850497687\n",
      "Loss 2:  0.021751471394527967\n",
      "Error:  1.029455969719928e-06\n",
      "\n",
      " 0.6879632903616232 1.1712499950561912\n",
      "\n",
      "Loss 1:  0.021751471394527967\n",
      "Loss 2:  0.021750448887893882\n",
      "Error:  1.0225066340852074e-06\n",
      "\n",
      " 0.6879363667786946 1.17134719773337\n",
      "\n",
      "Loss 1:  0.021750448887893882\n",
      "Loss 2:  0.02174943328368393\n",
      "Error:  1.0156042099529472e-06\n",
      "\n",
      " 0.6879095342233796 1.171444071771981\n",
      "\n",
      "Loss 1:  0.02174943328368393\n",
      "Loss 2:  0.021748424535303405\n",
      "Error:  1.0087483805244768e-06\n",
      "\n",
      " 0.6878827923879173 1.1715406182831385\n",
      "\n",
      "Loss 1:  0.021748424535303405\n",
      "Loss 2:  0.021747422596472065\n",
      "Error:  1.0019388313395328e-06\n",
      "\n",
      " 0.6878561409655871 1.1716368383742006\n",
      "\n",
      "Loss 1:  0.021747422596472065\n",
      "Loss 2:  0.021746427421222125\n",
      "Error:  9.951752499397226e-07\n",
      "\n",
      " 0.6878295796507059 1.1717327331487815\n",
      "\n",
      "Loss 1:  0.021746427421222125\n",
      "Loss 2:  0.021745438963895986\n",
      "Error:  9.884573261391416e-07\n",
      "\n",
      " 0.6878031081386237 1.1718283037067634\n",
      "\n",
      "Loss 1:  0.021745438963895986\n",
      "Loss 2:  0.021744457179144423\n",
      "Error:  9.817847515629363e-07\n",
      "\n",
      " 0.6877767261257206 1.1719235511443107\n",
      "\n",
      "Loss 1:  0.021744457179144423\n",
      "Loss 2:  0.021743482021924304\n",
      "Error:  9.751572201191494e-07\n",
      "\n",
      " 0.6877504333094034 1.1720184765538812\n",
      "\n",
      "Loss 1:  0.021743482021924304\n",
      "Loss 2:  0.021742513447496385\n",
      "Error:  9.685744279189223e-07\n",
      "\n",
      " 0.6877242293881018 1.1721130810242395\n",
      "\n",
      "Loss 1:  0.021742513447496385\n",
      "Loss 2:  0.021741551411423733\n",
      "Error:  9.62036072651995e-07\n",
      "\n",
      " 0.687698114061265 1.1722073656404686\n",
      "\n",
      "Loss 1:  0.021741551411423733\n",
      "Loss 2:  0.021740595869569054\n",
      "Error:  9.555418546795813e-07\n",
      "\n",
      " 0.6876720870293586 1.1723013314839832\n",
      "\n",
      "Loss 1:  0.021740595869569054\n",
      "Loss 2:  0.021739646778093327\n",
      "Error:  9.49091475726388e-07\n",
      "\n",
      " 0.6876461479938607 1.172394979632542\n",
      "\n",
      "Loss 1:  0.021739646778093327\n",
      "Loss 2:  0.02173870409345327\n",
      "Error:  9.426846400567568e-07\n",
      "\n",
      " 0.6876202966572588 1.1724883111602595\n",
      "\n",
      "Loss 1:  0.02173870409345327\n",
      "Loss 2:  0.021737767772399528\n",
      "Error:  9.363210537426114e-07\n",
      "\n",
      " 0.6875945327230463 1.1725813271376189\n",
      "\n",
      "Loss 1:  0.021737767772399528\n",
      "Loss 2:  0.021736837771974764\n",
      "Error:  9.300004247640714e-07\n",
      "\n",
      " 0.6875688558957189 1.1726740286314836\n",
      "\n",
      "Loss 1:  0.021736837771974764\n",
      "Loss 2:  0.021735914049511692\n",
      "Error:  9.237224630719021e-07\n",
      "\n",
      " 0.6875432658807717 1.1727664167051108\n",
      "\n",
      "Loss 1:  0.021735914049511692\n",
      "Loss 2:  0.02173499656263092\n",
      "Error:  9.174868807713954e-07\n",
      "\n",
      " 0.6875177623846953 1.1728584924181624\n",
      "\n",
      "Loss 1:  0.02173499656263092\n",
      "Loss 2:  0.021734085269239145\n",
      "Error:  9.112933917754251e-07\n",
      "\n",
      " 0.6874923451149726 1.1729502568267174\n",
      "\n",
      "Loss 1:  0.021734085269239145\n",
      "Loss 2:  0.021733180127527327\n",
      "Error:  9.051417118183247e-07\n",
      "\n",
      " 0.6874670137800756 1.1730417109832847\n",
      "\n",
      "Loss 1:  0.021733180127527327\n",
      "Loss 2:  0.02173228109596855\n",
      "Error:  8.990315587750763e-07\n",
      "\n",
      " 0.6874417680894619 1.1731328559368144\n",
      "\n",
      "Loss 1:  0.02173228109596855\n",
      "Loss 2:  0.021731388133316334\n",
      "Error:  8.929626522172218e-07\n",
      "\n",
      " 0.6874166077535714 1.1732236927327104\n",
      "\n",
      "Loss 1:  0.021731388133316334\n",
      "Loss 2:  0.021730501198602446\n",
      "Error:  8.869347138881767e-07\n",
      "\n",
      " 0.687391532483823 1.173314222412842\n",
      "\n",
      "Loss 1:  0.021730501198602446\n",
      "Loss 2:  0.02172962025113545\n",
      "Error:  8.809474669954631e-07\n",
      "\n",
      " 0.6873665419926114 1.1734044460155557\n",
      "\n",
      "Loss 1:  0.02172962025113545\n",
      "Loss 2:  0.021728745250498466\n",
      "Error:  8.750006369843966e-07\n",
      "\n",
      " 0.6873416359933036 1.173494364575688\n",
      "\n",
      "Loss 1:  0.021728745250498466\n",
      "Loss 2:  0.021727876156547383\n",
      "Error:  8.690939510835882e-07\n",
      "\n",
      " 0.6873168142002355 1.173583979124576\n",
      "\n",
      "Loss 1:  0.021727876156547383\n",
      "Loss 2:  0.021727012929409168\n",
      "Error:  8.632271382147394e-07\n",
      "\n",
      " 0.6872920763287091 1.1736732906900702\n",
      "\n",
      "Loss 1:  0.021727012929409168\n",
      "Loss 2:  0.02172615552947999\n",
      "Error:  8.573999291765222e-07\n",
      "\n",
      " 0.6872674220949889 1.1737623002965463\n",
      "\n",
      "Loss 1:  0.02172615552947999\n",
      "Loss 2:  0.021725303917423288\n",
      "Error:  8.516120567035601e-07\n",
      "\n",
      " 0.6872428512162986 1.173851008964916\n",
      "\n",
      "Loss 1:  0.021725303917423288\n",
      "Loss 2:  0.021724458054168123\n",
      "Error:  8.458632551645862e-07\n",
      "\n",
      " 0.6872183634108179 1.1739394177126397\n",
      "\n",
      "Loss 1:  0.021724458054168123\n",
      "Loss 2:  0.02172361790090716\n",
      "Error:  8.401532609648987e-07\n",
      "\n",
      " 0.6871939583976796 1.1740275275537377\n",
      "\n",
      "Loss 1:  0.02172361790090716\n",
      "Loss 2:  0.02172278341909512\n",
      "Error:  8.344818120398223e-07\n",
      "\n",
      " 0.6871696358969658 1.1741153394988022\n",
      "\n",
      "Loss 1:  0.02172278341909512\n",
      "Loss 2:  0.02172195457044699\n",
      "Error:  8.288486481287938e-07\n",
      "\n",
      " 0.6871453956297052 1.1742028545550083\n",
      "\n",
      "Loss 1:  0.02172195457044699\n",
      "Loss 2:  0.021721131316936076\n",
      "Error:  8.232535109141403e-07\n",
      "\n",
      " 0.6871212373178696 1.1742900737261257\n",
      "\n",
      "Loss 1:  0.021721131316936076\n",
      "Loss 2:  0.021720313620792554\n",
      "Error:  8.176961435214791e-07\n",
      "\n",
      " 0.6870971606843707 1.174376998012531\n",
      "\n",
      "Loss 1:  0.021720313620792554\n",
      "Loss 2:  0.02171950144450132\n",
      "Error:  8.121762912344233e-07\n",
      "\n",
      " 0.6870731654530572 1.174463628411218\n",
      "\n",
      "Loss 1:  0.02171950144450132\n",
      "Loss 2:  0.02171869475080066\n",
      "Error:  8.066937006584451e-07\n",
      "\n",
      " 0.6870492513487115 1.1745499659158103\n",
      "\n",
      "Loss 1:  0.02171869475080066\n",
      "Loss 2:  0.021717893502680503\n",
      "Error:  8.012481201580268e-07\n",
      "\n",
      " 0.6870254180970464 1.1746360115165715\n",
      "\n",
      "Loss 1:  0.021717893502680503\n",
      "Loss 2:  0.021717097663380387\n",
      "Error:  7.958393001168684e-07\n",
      "\n",
      " 0.6870016654247019 1.1747217662004172\n",
      "\n",
      "Loss 1:  0.021717097663380387\n",
      "Loss 2:  0.021716307196388073\n",
      "Error:  7.904669923133878e-07\n",
      "\n",
      " 0.6869779930592425 1.1748072309509268\n",
      "\n",
      "Loss 1:  0.021716307196388073\n",
      "Loss 2:  0.021715522065437944\n",
      "Error:  7.851309501288872e-07\n",
      "\n",
      " 0.6869544007291535 1.1748924067483537\n",
      "\n",
      "Loss 1:  0.021715522065437944\n",
      "Loss 2:  0.021714742234509095\n",
      "Error:  7.798309288493954e-07\n",
      "\n",
      " 0.6869308881638385 1.1749772945696375\n",
      "\n",
      "Loss 1:  0.021714742234509095\n",
      "Loss 2:  0.021713967667823658\n",
      "Error:  7.745666854366839e-07\n",
      "\n",
      " 0.6869074550936158 1.1750618953884144\n",
      "\n",
      "Loss 1:  0.021713967667823658\n",
      "Loss 2:  0.021713198329845383\n",
      "Error:  7.693379782749976e-07\n",
      "\n",
      " 0.6868841012497154 1.1751462101750292\n",
      "\n",
      "Loss 1:  0.021713198329845383\n",
      "Loss 2:  0.021712434185278004\n",
      "Error:  7.641445673792213e-07\n",
      "\n",
      " 0.6868608263642763 1.1752302398965457\n",
      "\n",
      "Loss 1:  0.021712434185278004\n",
      "Loss 2:  0.02171167519906344\n",
      "Error:  7.589862145648829e-07\n",
      "\n",
      " 0.6868376301703427 1.1753139855167583\n",
      "\n",
      "Loss 1:  0.02171167519906344\n",
      "Loss 2:  0.021710921336380203\n",
      "Error:  7.53862683236517e-07\n",
      "\n",
      " 0.6868145124018619 1.1753974479962026\n",
      "\n",
      "Loss 1:  0.021710921336380203\n",
      "Loss 2:  0.02171017256264202\n",
      "Error:  7.487737381829673e-07\n",
      "\n",
      " 0.6867914727936801 1.1754806282921668\n",
      "\n",
      "Loss 1:  0.02171017256264202\n",
      "Loss 2:  0.02170942884349591\n",
      "Error:  7.437191461082127e-07\n",
      "\n",
      " 0.6867685110815405 1.1755635273587026\n",
      "\n",
      "Loss 1:  0.02170942884349591\n",
      "Loss 2:  0.021708690144820905\n",
      "Error:  7.386986750068658e-07\n",
      "\n",
      " 0.6867456270020794 1.175646146146636\n",
      "\n",
      "Loss 1:  0.021708690144820905\n",
      "Loss 2:  0.021707956432726373\n",
      "Error:  7.337120945319353e-07\n",
      "\n",
      " 0.6867228202928238 1.1757284856035786\n",
      "\n",
      "Loss 1:  0.021707956432726373\n",
      "Loss 2:  0.021707227673550357\n",
      "Error:  7.28759176015642e-07\n",
      "\n",
      " 0.6867000906921878 1.1758105466739375\n",
      "\n",
      "Loss 1:  0.021707227673550357\n",
      "Loss 2:  0.021706503833858366\n",
      "Error:  7.238396919906354e-07\n",
      "\n",
      " 0.6866774379394702 1.1758923302989275\n",
      "\n",
      "Loss 1:  0.021706503833858366\n",
      "Loss 2:  0.021705784880441295\n",
      "Error:  7.189534170712331e-07\n",
      "\n",
      " 0.6866548617748511 1.1759738374165807\n",
      "\n",
      "Loss 1:  0.021705784880441295\n",
      "Loss 2:  0.02170507078031455\n",
      "Error:  7.141001267460534e-07\n",
      "\n",
      " 0.686632361939389 1.176055068961758\n",
      "\n",
      "Loss 1:  0.02170507078031455\n",
      "Loss 2:  0.021704361500715807\n",
      "Error:  7.092795987415079e-07\n",
      "\n",
      " 0.6866099381750179 1.1761360258661595\n",
      "\n",
      "Loss 1:  0.021704361500715807\n",
      "Loss 2:  0.0217036570091043\n",
      "Error:  7.044916115091227e-07\n",
      "\n",
      " 0.6865875902245444 1.1762167090583353\n",
      "\n",
      "Loss 1:  0.0217036570091043\n",
      "Loss 2:  0.021702957273158678\n",
      "Error:  6.997359456202557e-07\n",
      "\n",
      " 0.6865653178316445 1.176297119463696\n",
      "\n",
      "Loss 1:  0.021702957273158678\n",
      "Loss 2:  0.021702262260775873\n",
      "Error:  6.950123828050603e-07\n",
      "\n",
      " 0.686543120740861 1.1763772580045233\n",
      "\n",
      "Loss 1:  0.021702262260775873\n",
      "Loss 2:  0.021701571940069588\n",
      "Error:  6.903207062855521e-07\n",
      "\n",
      " 0.6865209986976002 1.1764571255999812\n",
      "\n",
      "Loss 1:  0.021701571940069588\n",
      "Loss 2:  0.021700886279368475\n",
      "Error:  6.856607011121452e-07\n",
      "\n",
      " 0.6864989514481292 1.1765367231661255\n",
      "\n",
      "Loss 1:  0.021700886279368475\n",
      "Loss 2:  0.021700205247215387\n",
      "Error:  6.810321530881236e-07\n",
      "\n",
      " 0.6864769787395733 1.1766160516159152\n",
      "\n",
      "Loss 1:  0.021700205247215387\n",
      "Loss 2:  0.021699528812365306\n",
      "Error:  6.764348500810924e-07\n",
      "\n",
      " 0.6864550803199122 1.1766951118592226\n",
      "\n",
      "Loss 1:  0.021699528812365306\n",
      "Loss 2:  0.02169885694378413\n",
      "Error:  6.718685811764324e-07\n",
      "\n",
      " 0.6864332559379782 1.1767739048028434\n",
      "\n",
      "Loss 1:  0.02169885694378413\n",
      "Loss 2:  0.021698189610647366\n",
      "Error:  6.673331367640367e-07\n",
      "\n",
      " 0.6864115053434524 1.1768524313505078\n",
      "\n",
      "Loss 1:  0.021698189610647366\n",
      "Loss 2:  0.0216975267823384\n",
      "Error:  6.628283089650522e-07\n",
      "\n",
      " 0.6863898282868625 1.1769306924028904\n",
      "\n",
      "Loss 1:  0.0216975267823384\n",
      "Loss 2:  0.02169686842844746\n",
      "Error:  6.583538909414599e-07\n",
      "\n",
      " 0.6863682245195792 1.1770086888576208\n",
      "\n",
      "Loss 1:  0.02169686842844746\n",
      "Loss 2:  0.02169621451877009\n",
      "Error:  6.539096773679198e-07\n",
      "\n",
      " 0.6863466937938145 1.1770864216092936\n",
      "\n",
      "Loss 1:  0.02169621451877009\n",
      "Loss 2:  0.021695565023305722\n",
      "Error:  6.494954643693207e-07\n",
      "\n",
      " 0.6863252358626177 1.1771638915494789\n",
      "\n",
      "Loss 1:  0.021695565023305722\n",
      "Loss 2:  0.02169491991225598\n",
      "Error:  6.451110497428247e-07\n",
      "\n",
      " 0.6863038504798731 1.1772410995667322\n",
      "\n",
      "Loss 1:  0.02169491991225598\n",
      "Loss 2:  0.021694279156024118\n",
      "Error:  6.407562318615223e-07\n",
      "\n",
      " 0.6862825374002971 1.177318046546605\n",
      "\n",
      "Loss 1:  0.021694279156024118\n",
      "Loss 2:  0.021693642725212927\n",
      "Error:  6.364308111905803e-07\n",
      "\n",
      " 0.6862612963794354 1.1773947333716552\n",
      "\n",
      "Loss 1:  0.021693642725212927\n",
      "Loss 2:  0.02169301059062363\n",
      "Error:  6.321345892984498e-07\n",
      "\n",
      " 0.6862401271736603 1.177471160921456\n",
      "\n",
      "Loss 1:  0.02169301059062363\n",
      "Loss 2:  0.02169238272325465\n",
      "Error:  6.278673689782965e-07\n",
      "\n",
      " 0.6862190295401677 1.1775473300726074\n",
      "\n",
      "Loss 1:  0.02169238272325465\n",
      "Loss 2:  0.021691759094300184\n",
      "Error:  6.236289544665763e-07\n",
      "\n",
      " 0.6861980032369743 1.177623241698745\n",
      "\n",
      "Loss 1:  0.021691759094300184\n",
      "Loss 2:  0.02169113967514876\n",
      "Error:  6.19419151422218e-07\n",
      "\n",
      " 0.6861770480229152 1.1776988966705517\n",
      "\n",
      "Loss 1:  0.02169113967514876\n",
      "Loss 2:  0.02169052443738216\n",
      "Error:  6.15237766600496e-07\n",
      "\n",
      " 0.6861561636576408 1.1777742958557658\n",
      "\n",
      "Loss 1:  0.02169052443738216\n",
      "Loss 2:  0.021689913352774016\n",
      "Error:  6.110846081444632e-07\n",
      "\n",
      " 0.6861353499016138 1.177849440119192\n",
      "\n",
      "Loss 1:  0.021689913352774016\n",
      "Loss 2:  0.021689306393288383\n",
      "Error:  6.069594856335236e-07\n",
      "\n",
      " 0.6861146065161072 1.1779243303227112\n",
      "\n",
      "Loss 1:  0.021689306393288383\n",
      "Loss 2:  0.02168870353107871\n",
      "Error:  6.028622096740377e-07\n",
      "\n",
      " 0.6860939332632009 1.1779989673252904\n",
      "\n",
      "Loss 1:  0.02168870353107871\n",
      "Loss 2:  0.021688104738486366\n",
      "Error:  5.987925923434112e-07\n",
      "\n",
      " 0.6860733299057793 1.1780733519829925\n",
      "\n",
      "Loss 1:  0.021688104738486366\n",
      "Loss 2:  0.021687509988039408\n",
      "Error:  5.947504469576426e-07\n",
      "\n",
      " 0.6860527962075282 1.178147485148986\n",
      "\n",
      "Loss 1:  0.021687509988039408\n",
      "Loss 2:  0.021686919252451337\n",
      "Error:  5.907355880713228e-07\n",
      "\n",
      " 0.6860323319329329 1.1782213676735545\n",
      "\n",
      "Loss 1:  0.021686919252451337\n",
      "Loss 2:  0.021686332504619866\n",
      "Error:  5.867478314706964e-07\n",
      "\n",
      " 0.6860119368472744 1.1782950004041073\n",
      "\n",
      "Loss 1:  0.021686332504619866\n",
      "Loss 2:  0.021685749717625734\n",
      "Error:  5.827869941320285e-07\n",
      "\n",
      " 0.6859916107166275 1.1783683841851886\n",
      "\n",
      "Loss 1:  0.021685749717625734\n",
      "Loss 2:  0.021685170864731276\n",
      "Error:  5.788528944575266e-07\n",
      "\n",
      " 0.6859713533078581 1.1784415198584872\n",
      "\n",
      "Loss 1:  0.021685170864731276\n",
      "Loss 2:  0.02168459591937944\n",
      "Error:  5.749453518347214e-07\n",
      "\n",
      " 0.68595116438862 1.178514408262846\n",
      "\n",
      "Loss 1:  0.02168459591937944\n",
      "Loss 2:  0.021684024855192382\n",
      "Error:  5.710641870597388e-07\n",
      "\n",
      " 0.6859310437273528 1.178587050234272\n",
      "\n",
      "Loss 1:  0.021684024855192382\n",
      "Loss 2:  0.021683457645970235\n",
      "Error:  5.672092221464808e-07\n",
      "\n",
      " 0.6859109910932789 1.1786594466059452\n",
      "\n",
      "Loss 1:  0.021683457645970235\n",
      "Loss 2:  0.021682894265690183\n",
      "Error:  5.633802800525389e-07\n",
      "\n",
      " 0.6858910062564009 1.1787315982082296\n",
      "\n",
      "Loss 1:  0.021682894265690183\n",
      "Loss 2:  0.02168233468850491\n",
      "Error:  5.595771852724696e-07\n",
      "\n",
      " 0.6858710889874989 1.178803505868681\n",
      "\n",
      "Loss 1:  0.02168233468850491\n",
      "Loss 2:  0.021681778888741683\n",
      "Error:  5.557997632271716e-07\n",
      "\n",
      " 0.6858512390581283 1.1788751704120575\n",
      "\n",
      "Loss 1:  0.021681778888741683\n",
      "Loss 2:  0.021681226840901034\n",
      "Error:  5.520478406489948e-07\n",
      "\n",
      " 0.6858314562406166 1.1789465926603286\n",
      "\n",
      "Loss 1:  0.021681226840901034\n",
      "Loss 2:  0.02168067851965564\n",
      "Error:  5.483212453943898e-07\n",
      "\n",
      " 0.6858117403080612 1.179017773432685\n",
      "\n",
      "Loss 1:  0.02168067851965564\n",
      "Loss 2:  0.02168013389984911\n",
      "Error:  5.44619806530644e-07\n",
      "\n",
      " 0.6857920910343267 1.1790887135455477\n",
      "\n",
      "Loss 1:  0.02168013389984911\n",
      "Loss 2:  0.021679592956494975\n",
      "Error:  5.409433541346542e-07\n",
      "\n",
      " 0.6857725081940419 1.1791594138125772\n",
      "\n",
      "Loss 1:  0.021679592956494975\n",
      "Loss 2:  0.02167905566477529\n",
      "Error:  5.372917196849736e-07\n",
      "\n",
      " 0.6857529915625981 1.179229875044683\n",
      "\n",
      "Loss 1:  0.02167905566477529\n",
      "Loss 2:  0.021678522000039814\n",
      "Error:  5.336647354754753e-07\n",
      "\n",
      " 0.6857335409161455 1.1793000980500334\n",
      "\n",
      "Loss 1:  0.021678522000039814\n",
      "Loss 2:  0.02167799193780453\n",
      "Error:  5.30062235284956e-07\n",
      "\n",
      " 0.6857141560315915 1.1793700836340641\n",
      "\n",
      "Loss 1:  0.02167799193780453\n",
      "Loss 2:  0.02167746545375077\n",
      "Error:  5.264840537595739e-07\n",
      "\n",
      " 0.6856948366865975 1.1794398325994875\n",
      "\n",
      "Loss 1:  0.02167746545375077\n",
      "Loss 2:  0.021676942523724173\n",
      "Error:  5.229300265967296e-07\n",
      "\n",
      " 0.6856755826595767 1.179509345746302\n",
      "\n",
      "Loss 1:  0.021676942523724173\n",
      "Loss 2:  0.021676423123733152\n",
      "Error:  5.193999910203806e-07\n",
      "\n",
      " 0.6856563937296917 1.1795786238718013\n",
      "\n",
      "Loss 1:  0.021676423123733152\n",
      "Loss 2:  0.02167590722994831\n",
      "Error:  5.158937848408207e-07\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 2.3, 3.4, 3.9, 4.6])\n",
    "\n",
    "n = len(x)\n",
    "\n",
    "## asssumption\n",
    "m = 0.5\n",
    "c = 0.5\n",
    "\n",
    "ypred = m * x + c\n",
    "ypred\n",
    "\n",
    "loss1 = np.sum((y-ypred)**2)/n\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "for i in range(0, 1000):\n",
    "    mgrad = np.sum(-2* x* (y-ypred))/n\n",
    "    cgrad = np.sum(-2 * (y-ypred))/n\n",
    "\n",
    "    mnew = m - alpha * mgrad\n",
    "    cnew = c - alpha * cgrad\n",
    "\n",
    "    print(\"\\n\", mnew, cnew)\n",
    "\n",
    "    ypred = mnew * x + cnew\n",
    "    m = mnew\n",
    "    c = cnew\n",
    "\n",
    "    loss2 = np.sum((y-ypred)**2)/n\n",
    "    print(\"\\nLoss 1: \", loss1)\n",
    "    print(\"Loss 2: \", loss2)\n",
    "    print(\"Error: \", np.abs(loss2 - loss1))\n",
    "    loss1 = loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9025cd08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x21c71b97190>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y)\n",
    "plt.plot(x,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a65e620",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2149328462.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[54], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    mgrad = np.sum(-2  x  (y-ypred))/n\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "loss2 = loss1\n",
    "loss1 = 0\n",
    "while np.abs(loss2 - loss1) >= 0.00001:\n",
    "    loss1 = loss2\n",
    "\n",
    "    mgrad = np.sum(-2  x  (y-ypred))/n\n",
    "    cgrad = np.sum(-2 * (y-ypred))/n\n",
    "\n",
    "    mnew = m - alpha * mgrad\n",
    "    cnew = c - alpha * cgrad\n",
    "\n",
    "    # print(\"\\n\", mnew, cnew)\n",
    "\n",
    "    ypred = mnew * x + cnew\n",
    "    m = mnew\n",
    "    c = cnew\n",
    "\n",
    "    loss2 = np.sum((y-ypred)**2)/n\n",
    "    # print(\"\\nLoss 1: \", loss1)\n",
    "    # print(\"Loss 2: \", loss2)\n",
    "    print(\"Error: \", np.abs(loss2 - loss1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1e4fd70b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2215612119.py, line 33)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[59], line 33\u001b[1;36m\u001b[0m\n\u001b[1;33m    mgrad = np.sum(-2  self.x  (self.y-ypred))/n\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class LinearRegression:\n",
    "    def __init__(self, x, y, m =0.5, c=0.5, alpha = 0.01):\n",
    "        self.x = np.array(x)\n",
    "        self.y = np.array(y)\n",
    "        self.m = m\n",
    "        self.c = c\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def predict(self):\n",
    "        return(self.m*self.x+self.c)\n",
    "\n",
    "    def loss(self):\n",
    "        n = len(self.x)\n",
    "        ypred = self.predict()\n",
    "        return(np.sum((self.y-ypred)**2)/n)\n",
    "\n",
    "\n",
    "    def fit(self):\n",
    "        ypred = self.predict()\n",
    "\n",
    "        loss2 = self.loss()\n",
    "        loss1 = 0\n",
    "\n",
    "        # total number of items\n",
    "        n = len(self.x)\n",
    "\n",
    "        while np.abs(loss2 - loss1) >= 0.00001:\n",
    "            loss1 = loss2\n",
    "\n",
    "            mgrad = np.sum(-2  self.x  (self.y-ypred))/n\n",
    "            cgrad = np.sum(-2 * (self.y-ypred))/n\n",
    "\n",
    "            self.m = self.m - self.alpha * mgrad\n",
    "            self.c = self.c - self.alpha * cgrad\n",
    "\n",
    "            ypred = self.predict() # ypred = mnew * self.x + cnew\n",
    "\n",
    "            loss2 = np.sum((self.y-ypred)**2)/n\n",
    "\n",
    "    def bestParams(self):\n",
    "        return(self.m, self.c)\n",
    "\n",
    "    def plotLine(self):\n",
    "        ypred = self.m * self.x + self.c\n",
    "        plt.scatter(self.x, self.y, color = 'red')\n",
    "        plt.plot(self.x, ypred, color = 'green')\n",
    "        plt.title(f\"y = {self.m:.2f}*x+{self.c:.2f}\")\n",
    "        plt.xlabel('X')\n",
    "        plt.ylabel('Y')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "edc8e299",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LinearRegression' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[0;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2.3\u001b[39m, \u001b[38;5;241m3.4\u001b[39m, \u001b[38;5;241m3.9\u001b[39m, \u001b[38;5;241m4.6\u001b[39m])\n\u001b[1;32m----> 4\u001b[0m lr1\u001b[38;5;241m=\u001b[39mLinearRegression(x,y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LinearRegression' is not defined"
     ]
    }
   ],
   "source": [
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 2.3, 3.4, 3.9, 4.6])\n",
    "\n",
    "lr1=LinearRegression(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5115bcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
